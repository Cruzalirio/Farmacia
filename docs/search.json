[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Matemáticas y Estadística Farmacia",
    "section": "",
    "text": "Presentación\nEsta edición en línea ofrecerá un compendio completo de los apuntes de la asignatura de Matemáticas y Estadística, diseñada específicamente para el grado de Farmacia en la UIB.\nEl contenido combina un enfoque teórico-práctico que facilita la comprensión de los conceptos matemáticos y estadísticos fundamentales, aplicados al ámbito farmacéutico, proporcionando una herramienta esencial para el aprendizaje y la aplicación en situaciones reales de la disciplina.",
    "crumbs": [
      "Presentación"
    ]
  },
  {
    "objectID": "t1_MatesBasicas.html",
    "href": "t1_MatesBasicas.html",
    "title": "1  Matemáticas básicas",
    "section": "",
    "text": "1.1 R y Jamovi\nEs fundamental utilizar un software especializado que simplifique la resolución de problemas y optimice el análisis estadístico de datos. Estas herramientas no solo agilizan los cálculos y procesamientos complejos, sino que también mejoran la precisión y fiabilidad de los resultados obtenidos. Además, permiten una redacción más clara y estructurada de informes, facilitando la presentación de resultados de manera profesional y efectiva.\nEn este curso utilizaremos el software jamovi (interfaz gráfica que emplea como base R). R es un entorno de programación estadística de código abierto que ofrece una amplia gama de funciones y paquetes para el análisis de datos y la generación de gráficos. Jamovi es una herramienta más accesible que nos permitirá centrarnos en el análisis y la interpretación de datos, en lugar de en la sintaxis de programación.\nInstalar R es muy sencillo; pero es conveniente que dispongáis de su versión más reciente y que regularmente lo pongáis al día. Los pasos a realizar en Windows o Mac OS X para instalar su última versión son los siguientes:\nCuando instaláis R para Windows o Mac OS X, con él también se os instala una interfaz gráfica que se abrirá al abrir la aplicación y en la que podréis trabajar.\nLa instalación para Linux no lleva una interfaz por defecto, así que sus usuarios tienen que trabajar con R en la terminal (ejecutando R para iniciar una sesión) o instalar aparte una interfaz. Independientemente de todas estas posibilidades, en este curso usaremos RStudio como interfaz gráfica de usuario de R para todos los sistemas operativos.\nPara que nuestra interfaz con R sea agradable, podemos usar varias aplicaciones disponibles, como Rstudio, Visual Studio Code o Jamovi. Por facilidad usaremos Jamovi",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Matemáticas básicas</span>"
    ]
  },
  {
    "objectID": "t1_MatesBasicas.html#r-y-jamovi",
    "href": "t1_MatesBasicas.html#r-y-jamovi",
    "title": "1  Matemáticas básicas",
    "section": "",
    "text": "Si sois usuarios de Windows, acceded a la página web de la CRAN y pulsad sobre el enlace Download R for Windows. A continuación, entrad en el enlace base, descargad R y seguid las instrucciones de instalación del documento Installation and other instructions que encontraréis en esa misma página.\nSi sois usuarios de Mac OS X, acceded a la página web de la CRAN y pulsad sobre el enlace Download R for Mac OS X. A continuación, descargad el fichero .pkg correspondiente y, una vez descargado, abridlo y seguid las instrucciones del Asistente de Instalación.\nSi trabajáis con Ubuntu o Debian, para instalar la última versión de R basta que ejecutéis en una terminal, estando conectados a Internet, la siguiente instrucción:\n\nsudo aptitude install r-base\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nR version 4.4.1 (2024-06-14 ucrt) – “Race for Your Life” Copyright (C) 2024 The R Foundation for Statistical Computing Platform: x86_64-w64-mingw32/x64\nR es un software libre y viene sin GARANTIA ALGUNA. Usted puede redistribuirlo bajo ciertas circunstancias. Escriba ‘license()’ o ‘licence()’ para detalles de distribucion.\nR es un proyecto colaborativo con muchos contribuyentes. Escriba ‘contributors()’ para obtener más información y ‘citation()’ para saber cómo citar R o paquetes de R en publicaciones.\nEscriba ‘demo()’ para demostraciones, ‘help()’ para el sistema on-line de ayuda, o ‘help.start()’ para abrir el sistema de ayuda HTML con su navegador. Escriba ‘q()’ para salir de R.\n\n\n\n\n\n\n\n\n\n1.1.1 Instalación de Jamovi\nSegún la pagina de Jamovi, y en una traducción al castellano usando Google translate obtenemos:\n\nEstadísticas simplificadas: Jamovi es una nueva hoja de cálculo estadística de “tercera generación”. Diseñada desde cero para que sea fácil de usar, Jamovi es una alternativa atractiva a productos estadísticos costosos como SPSS y SAS.\nIntegración con R: Jamovi está construido sobre el lenguaje estadístico R, lo que le brinda acceso a lo mejor que la comunidad estadística tiene para ofrecer. ¿Le gustaría el código R para sus análisis? Jamovi también puede proporcionárselo.\nGratuito y abierto: Jamovi siempre será gratuito y abierto: ese es uno de nuestros valores fundamentales, porque Jamovi está hecho por la comunidad científica, para la comunidad científica.\n\nAdicional a esto, instalaremos el software, siguiendo las instrucciones que aparecen en el botón Download and install jamovi onto your computer\nLuego de la instalación debe aparecer en su busqueda de windows. \nY nos aparecerá esta interfaz para trabajar.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Matemáticas básicas</span>"
    ]
  },
  {
    "objectID": "t1_MatesBasicas.html#matemáticas-básicas",
    "href": "t1_MatesBasicas.html#matemáticas-básicas",
    "title": "1  Matemáticas básicas",
    "section": "1.2 Matemáticas básicas",
    "text": "1.2 Matemáticas básicas\n\n1.2.1 Funciones lineales\nEn geometría analítica y álgebra elemental, una función lineal es una función polinómica de primer grado, es decir, una función de una variable (normalmente esta variable se denota con \\(x\\), que puede ser escrita como la suma de términos de la forma \\[f(x)=mx+b\\] donde \\(m\\) determina la pendiente o inclinación de la recta, y la constante \\(b\\) determina el punto de corte de la recta con el eje vertical \\(y\\).\nEn Farmacia es útil observar la relación entre dosis y respuesta:\n\nlibrary(tidyverse)\nx = seq(-3,3)\ny = 2-0.5*x\ndatos = data.frame(x, y)\ndatos %&gt;% ggplot(aes(x=x, y=y))+\n  geom_line()+theme_bw()\n\n\n\n\n\n\n\n\n\n\n1.2.2 Funciones exponenciales\nUna función exponencial es una función matemática de la forma \\[f(x) = a \\cdot b^x\\],\ndonde:\n\n\\(a\\) es una constante que representa el valor inicial.\n\\(b\\) es la base de la función exponencial.\n\\(x\\) es la variable independiente.\n\nEstas funciones son comunes en situaciones de crecimiento o decrecimiento rápido, como el crecimiento poblacional, la desintegración radiactiva, y el interés compuesto.\nConsideremos una población de bacterias que se duplica cada hora. Si inicialmente hay 100 bacterias, podemos modelar el crecimiento de la población con la función exponencial:\n\\[P(t) = 100 \\cdot 2^t\\]\nAquí:\n\n\\(P(t)\\) es la población de bacterias en el tiempo \\(t\\) (en horas).\n100 es el valor inicial ( \\(a\\) ).\n2 es la base ( \\(b\\) ), ya que la población se duplica cada hora.\n\n\nx = seq(-3,3, 0.01)\ny = 100*2^x\ndatos = data.frame(x, y)\ndatos %&gt;% ggplot(aes(x=x, y=y))+\n  geom_line()+theme_bw()\n\n\n\n\n\n\n\n\n\nx = seq(-3,3, 0.01)\ny = 100*exp(x)\ndatos = data.frame(x, y)\ndatos %&gt;% ggplot(aes(x=x, y=y))+\n  geom_line()+theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEs muy importante reconocer el número $e$ 2.7182818 como la base más usada para tranajar con funciones exponenciales. Esto se debe a la propiedad siguiente: \\[y = ab^x= e^{ln(ab^x)}=e^{xln b + a}=e^ae^{xln b}=\\tilde{a}e^{\\tilde{b}x}\\]\n\n\n\n\n1.2.3 Funciones logarítmicas\nUna función logarítmica es la inversa de una función exponencial. Si tenemos una función exponencial de la forma \\(y=b^x\\), donde \\(b\\) es la base y \\(x\\) es el exponente, la función logarítmica correspondiente es \\(x=\\log_b(y)\\).\nEl logaritmo de un número \\(y\\) con base \\(b\\) es el exponente al cual hay que elevar la base \\(b\\) para obtener \\(y\\). Matemáticamente, esto se representa como:\n\\[log_b(y) = x \\Leftrightarrow b^x = y\\]\nEn el contexto de la farmacia, las bases más comunes son \\(e\\) (el número de Euler, aproximadamente 2.718) y \\(10\\), dando lugar a los logaritmos naturales (\\(\\ln(x)\\)) y logaritmos en base 10 (\\(\\log_{10}(x)\\)), respectivamente.\nLas propiedades básicas de los logaritmos son especialmente útiles para simplificar y resolver ecuaciones complejas:\n\n\\(\\log_b(1) = 0\\) para cualquier base \\(b\\).\nProducto: \\(\\log_b(xy) = \\log_b(x) + \\log_b(y)\\).\nCociente: \\(\\log_b(x/y) = \\log_b(x) - \\log_b(y)\\).\nPotencias: \\(\\log_b(x^p) = p \\cdot \\log_b(x)\\).\nCambio de base: \\(\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}\\).\n\nLas funciones logarítmicas son ampliamente utilizadas en diversos aspectos de la ciencia farmacéutica:\n\nFarmacocinética: Los logaritmos se utilizan para analizar cómo los medicamentos se distribuyen, metabolizan y eliminan en el cuerpo. Por ejemplo, la fórmula de eliminación de primer orden de un fármaco se representa mediante una función exponencial, y el tiempo de eliminación o la vida media se calculan usando logaritmos naturales.\npH y Química Farmacéutica: En química, los logaritmos son fundamentales para calcular el pH, que se define como el logaritmo negativo de la concentración de iones de hidrógeno: \\[pH = -\\log_{10}([H^+])\\] Este concepto es clave para entender la estabilidad y solubilidad de los fármacos, así como para desarrollar soluciones que mantengan un pH constante en formulaciones farmacéuticas.\nEstudios de bioequivalencia: Se comparan diferentes formulaciones de un mismo medicamento, el uso de logaritmos facilita el análisis de concentraciones plasmáticas a lo largo del tiempo, proporcionando una mejor comprensión de la absorción y distribución de los fármacos.\nEscalas y Dosificación: Los logaritmos se utilizan para interpretar datos que cubren un amplio rango de valores, como las curvas dosis-respuesta, donde la relación entre la concentración de un medicamento y su efecto biológico es no lineal y puede ser mejor representada en una escala logarítmica.\n\nConsideremos un ejemplo práctico en el que se necesita determinar el tiempo necesario para reducir la concentración de un medicamento en sangre a la mitad (vida media). Supongamos que la eliminación del fármaco sigue una cinética de primer orden, es decir, la concentración \\[C(t) = C_0 \\cdot e^{-kt}\\] Donde \\(C_0\\) es la concentración inicial, \\(k\\) es la constante de eliminación y \\(t\\) es el tiempo.\nLa vida media (\\(t_{1/2}\\)) se define como el tiempo necesario para que la concentración del fármaco disminuya a la mitad de su valor inicial. Entonces, para un fármaco con cinética de primer orden, la vida media se calcula como:\n\\[t_{1/2} = \\frac{\\ln(2)}{k}\\]\n\n\n1.2.4 Funciones polinómicas\nUna función polinomial de grado 2, también conocida como función cuadrática, tiene la forma \\(f(x) = ax^2 + bx + c\\), donde:\n\n\\(a\\), \\(b\\) y \\(c\\) son constantes reales.\n\\(a\\) es distinto de 0.\n\nLa gráfica de una función cuadrática es una parábola que puede abrirse hacia arriba (si \\(a\\) es positivo) o hacia abajo (si \\(a\\) es negativo).\n\nx = seq(-3,3, 0.01)\ny = 2+0.5*x-0.4*x^2\ndatos = data.frame(x, y)\ndatos %&gt;% ggplot(aes(x=x, y=y))+\n  geom_line()+theme_bw()\n\n\n\n\n\n\n\n\n\nx = seq(-10,10, 0.01)\ny = 2+0.5*x-0.4*x^2 +0.5*x^3-0.002*x^5\ndatos = data.frame(x, y)\ndatos %&gt;% ggplot(aes(x=x, y=y))+\n  geom_line()+theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nPara recordar factorización, ¿qué sucede si graficamos la siguiente función? \\[y=(x-2)(x+1.5)(x-0.5)(x+3)(x+2)(x-4)\\]\n\n\n\nx = seq(-3,4, 0.01)\ny = (x-2)*(x+1.5)*(x-0.5)*(x+3)*(x+2)*(x-4)\ndatos = data.frame(x, y)\ndatos %&gt;% ggplot(aes(x=x, y=y))+\n  geom_line()+theme_bw()+\n  geom_hline(yintercept = 0)\n\n\n\n\n\n\n\n\n\n\n1.2.5 Práctica 1:\n\nFormad grupos de 1, 2 o 3 integrantes.\nTrabajaréis con los datos que aparecen en el enlace. Abrimos el enlace y con click derecho –&gt; Guardar como y seguimos las instrucciones.\nEstos datos son tomados de la investigación sobre calentamiento global del Global Carbon Project. Allí se encontrará más información por si os interesa. Vamos a introducir los gráficos de dispersión y la visualización de posibles relaciones entre variables cuantitativas.\n\nSeguiremos los siguientes pasos.\n\nCon la opción abrir, importamos la base de datos en JAMOVI.\nVerificamos que todas las variables estén cargadas\nReproduciremos esta gráfica de dispersión. ¿Cómo se realiza la gráfica? ¿De los tipos de funciones, cuál se ajustaria mejor?\n\n\n\n\n\n\n\n\n\n\n\nReproduciremos esta gráfica de dispersión. ¿Cómo se realiza la gráfica? ¿De los tipos de funciones, cuál se ajustaria mejor?\n\n\n\n\n\n\n\n\n\n\n\nReproduciremos esta gráfica de dispersión. ¿Cómo se realiza la gráfica? ¿De los tipos de funciones, cuál se ajustaria mejor?\n\n\n\n\n\n\n\n\n\n\n\nDebéis exportar las gráficas en formato PDF.\nEntregad el reporte en la tarea de Aula Digital disponible. Revisad la fecha en que cierra la tarea.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Matemáticas básicas</span>"
    ]
  },
  {
    "objectID": "t2_intro.html",
    "href": "t2_intro.html",
    "title": "2  Representación gráfica y análisis de Datos",
    "section": "",
    "text": "2.1 La estadística y el método científico\nEn resumen, la estadística es una herramienta esencial que ayuda a garantizar que la investigación científica sea rigurosa, confiable y basada en evidencia sólida.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representación gráfica y análisis de Datos</span>"
    ]
  },
  {
    "objectID": "t2_intro.html#la-estadística-y-el-método-científico",
    "href": "t2_intro.html#la-estadística-y-el-método-científico",
    "title": "2  Representación gráfica y análisis de Datos",
    "section": "",
    "text": "La ciencia avanza definiendo teorías que intentan explicar el mundo.\nLa comunidad científica elabora teorías/hipótesis que intentan explicar hechos que ocurren. Una hipótesis es científica si existe alguna manera de comprobar su veracidad.\nPodemos diseñar experimentos para comprobar si se cumplen las afirmaciones de la teoría.\nComo la naturaleza tiene un comportamiento con “incertidumbre”, es decir, que si repetimos el experimento se obtienen resultados similares pero no idénticos, la estadística permite analizar estos resultados y ver si las desviaciones de la teoría son razonables o no.\nSe ha definido estadística de muchas maneras. La que más nos gusta, y que está relaciona con la situación que acabamos de explicar, es que:\n\n\nLa estadística es la ciencia que permite adquirir conocimiento generalizable a partir de datos.\n\n\nLa estadística ayuda en todas las fases del método científico:\n\nPlanteamiento del problema: Diseño de experimentos y encuestas, determinación del tamaño de la muestra y métodos de muestreo adecuados para garantizar que los datos recopilados sean representativos de la población objetivo.\nRecopilación de datos: Proporciona herramientas para recopilar y organizar datos relevantes sobre el problema.\nAnálisis de datos: Aplicación de técnicas descriptivas (Análisis explorartorio de datos), así como técnicas inferenciales (contrastes de hipótesis, ajustes de modelos,etc) para sacar conclusiones sobre la población en función de la muestra recopilada.\nInterpretación de resultados: Ayuda a los científicos a determinar si los resultados son estadísticamente significativos y si las conclusiones se pueden generalizar a la población más amplia.\nComunicación de hallazgos: La estadística se usa para comunicar los resultados de manera efectiva a través de gráficos, tablas y tests estadísticos. Esto es esencial para que otros investigadores puedan comprender y evaluar los resultados.\nReproducibilidad: Proporciona métodos estadísticos claros y transparentes, se permite que otros repitan los experimentos y análisis para verificar la validez de los hallazgos.\nToma de decisiones: En muchos campos científicos, los resultados estadísticos se utilizan para tomar decisiones importantes. Por ejemplo, en la medicina, la estadística se usa para evaluar la eficacia de tratamientos y tomar decisiones sobre su uso en la práctica clínica.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representación gráfica y análisis de Datos</span>"
    ]
  },
  {
    "objectID": "t2_intro.html#conceptos-básicos",
    "href": "t2_intro.html#conceptos-básicos",
    "title": "2  Representación gráfica y análisis de Datos",
    "section": "2.2 Conceptos básicos",
    "text": "2.2 Conceptos básicos\n\n2.2.1 Estudio clínico\nUn estudio clínico es un proceso cuyo objetivo es obtener evidencia empírica sobre alguna cuestión. En el caso de los estudios que nos ocupan en este curso, esta cuestión es, naturalmente, sobre algún aspecto como la efectividad de un medicamento o algún tema de salud pública.\n\n\n2.2.2 Unidad de observación\nEn un estudio estadístico, la unidad de observación es, para entendernos, el tipo de qué o de quiénes que son objeto de medición durante la investigación. En los estudios médicos normalmente serán personas, pero no siempre. Por ejemplo, pueden ser sucesos que les pasen a personas, de manera que una misma persona pueda ser observada varias veces: embarazos, operaciones quirúrgicas. Por ejemplo, podemos medir en diferentes centros de educación primaria de una ciudad el gasto medio diario en sus máquinas expendedoras de alimentos procesados y la proporción de miopes entre sus alumnos, para estimar si hay alguna relación entre el consumo de alimentos procesados y la miopía. Aquí, la unidad de observación son los centros de educación primaria, no los alumnos.\n\n\n2.2.3 Población y muestra\n\nPoblación: Es el conjunto de todas las unidades de observación sobre los que queremos conocer alguna información. Esta población puede estar perfectamente definida en un lugar y tiempo: por ejemplo, los empadronados en Mallorca a día de hoy. Pero normalmente su definición será difusa. Si, por ejemplo, queremos estimar algo sobre “los españoles diabéticos mayores de 65 años”, ¿de quiénes estamos hablando exactamente? ¿De los que están vivos justo ahora? ¿De todos los que ha habido en España desde su fundación? ¿Incluimos los que aún no han nacido? ¿Qué hacemos con los que son diabéticos pero no han sido diagnosticados, ni lo serán nunca?\nMuestra: Es un subconjunto de la población que se ha seleccionado para ser observado. La idea es que la muestra sea representativa de la población, de manera que los resultados obtenidos de la muestra puedan generalizarse a la población. En el ejemplo anterior, podríamos seleccionar una muestra de españoles diabéticos mayores de 65 años, y a partir de esta muestra intentar estimar alguna característica de la población de españoles diabéticos mayores de 65 años.\n\n\n\n2.2.4 Tipos de estadística\nEn estadística, siempre se empieza obteniendo unos datos sobre una muestra de una población. Bueno, en realidad, no se empieza obteniendo los datos, sino planificando cuidadosamente cómo se van a obtener.\nSe generaliza la información que se ha obtenido sobre este grupo de personas al total de la población. Y no se trata de trucos de magia adivinatoria, sino de una ciencia cuya metodología ha sido validada por medio de demostraciones matemáticas o, en el peor de los casos, mediante simulaciones numéricas (el equivalente en matemáticas de los experimentos en las otras ciencias).\nAsí pues, la situación de partida a la hora de aplicar técnicas estadísticas es que disponemos de un conjunto de datos que describen algunas características de un grupo de individuos. El análisis estadístico de estos datos puede ser entonces de dos tipos básicos:\n\nAnálisis exploratorio de datos, cuando nuestro objetivo sea simplemente resumir, representar y explicar los datos concretos de los que disponemos. La estadística descriptiva es el conjunto de técnicas que se usan con este fin.\nAnálisis inferencial, si nuestro objetivo es deducir (inferir), a partir de estos datos, información significativa sobre el total de la población de interés. Las técnicas que se usan en este caso forman la estadística inferencial.\n\n\n\n\n\n\nAmbos tipos de análisis están relacionados. Por un lado, porque es conveniente (obligatorio, en nuestra opinión) empezar cualquier análisis inferencial dando un vistazo a los datos que se usarán.\nPor otro, porque muchas técnicas descriptivas permiten estimar propiedades de la población de la que se ha extraído la muestra. Por citar un ejemplo, la media aritmética de las alturas de un grupo de individuos nos da un valor más o menos representativo de sus alturas, pero también sirve para estimar la altura media de los individuos de la población total.\nLa estadística inferencial entra en juego cuando se quiere obtener información sobre una población y no se puede acceder a todos sus integrantes. Si por ejemplo queremos conocer la altura media de los estudiantes matriculados en esta asignatura de la UIB en este curso, en principio no necesitamos para nada la estadística inferencial. Sois pocos, os mediríamos a todos y calcularíamos la media. En todo caso, usaríamos técnicas de estadística descriptiva para arropar este valor representando la distribución de vuestras alturas de manera adecuada.\nPero si quisiéramos conocer la altura media de los mallorquines entre 18 y 25 años, sería muy complicado medirlos a todos. Entonces, lo que haríamos sería tomar una muestra representativa de esta población, medirlos y a partir de sus alturas estimar dicha altura media. Naturalmente, lo más seguro es que de esta manera no obtuviéramos el valor exacto de la altura media de los mallorquines de 18 años, nos tendríamos que conformar con obtener una aproximación dentro de un cierto margen de error y determinar la probabilidad de acertar con nuestra estimación y este margen de error. La estadística inferencial es la que nos permite acotar el error que podamos haber cometido y calcular la probabilidad de cometerlo, incluyendo la metodología que tendríamos que haber usado para tomar la muestra en primer lugar.\n\n\n2.2.5 Tipos de estudios\nPodemos clasificar los estudios clínicos de diferentes maneras:\n\nSegún su intención:\n\nDescriptivos: Se limitan a describir las características de los individuos de la muestra.\nAnalíticos: Intentan inferir conclusiones sobre el total de la población.\n\nSegún el papel jugado por el investigador:\n\nObservacionales: El investigador se limita a recoger datos, sin ejercer ninguna influencia planificada sobre los acontecimientos que generan dichos datos.\nIntervencionista: El investigador lleva a cabo una intervención en los participantes (por ejemplo, les administra tratamientos farmacológicos o recomienda cambios de comportamiento) de manera planificada y con el objetivo de generar los datos que permitan evaluar el efecto de dicha intervención.\n\nSegún el lapso de tiempo sobre el que se recoge la información:\n\nTransversales: Se recoge información sobre un solo momento.\nLongitudinales: Se recoge información sobre varios momentos de tiempo y se estudian los cambios producidos entre los mismos.\nA su vez, estos últimos suelen dividirse en:\n\nProspectivos: Se recoge información en un momento concreto (normalmente, al inicio del estudio) y en momentos posteriores.\nRetrospectivos: Se recoge información en un momento concreto (de nuevo, normalmente, al inicio del estudio) y sobre momentos anteriores.\n\n\n\nCombinando los tipos de estudio según el papel jugado por el investigador y según el lapso de tiempo sobre el que se recoge la información, tenemos estudios:\n\nObservacionales transversales\nObservacionales prospectivos\nObservacionales retrospectivos\nIntervencionistas transversales\nIntervencionistas prospectivos\nIntervencionistas retrospectivos\n\nAcabamos de ver que hay estudios intervencionistas prospectivos. ¿Los hay de las otras cinco clases de estudios de esta lista, o hay algún par de características que es imposible que se den simultáneamente?\nUna clasificación básica de los tipos de estudios es la siguiente:\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEl análisis estadístico de los datos depende del tipo de estudio\n\n\n\n2.2.5.1 Estudios descriptivos\n\nInforme de caso: Descripción detallada de un enfermo.\nSerie de casos: Descripción detallada de un conjunto pequeño de personas con algún problema de salud en común. La información se recoge usualmente por medio de sus historias clínicas y entrevistas clínicas.\n\n\nEjemplo:\n\n\n\n\n\n\n\nSurvey: Descripción de un conjunto grande de individuos con alguna característica en común. La información se recoge usualmente por medio de cuestionarios o entrevistas. Sirven para identificar observaciones interesantes que merezcan ser investigadas\n\nEjemplo:\n\n\n\n\n\n\n\n\n\n2.2.5.2 Estudios de casos y controles\n\nSe toma un grupo de individuos con la enfermedad casos y un grupo de individuos sin la enfermedad controles.\nSe les compara retrospectivamente para encontrar diferencias en su exposición a factores de riesgo en el pasado.\nSe determinan qué factores de riesgo fueron más frecuentes entre los casos que entre los controles.\nSe infiere que, en la población general, la exposición a dichos factores está asociada a una mayor probabilidad de sufrir la enfermedad.\n\n\n  \n  R. Doll, A. Bradford Hill. \"Study of the Aetiology of Carcinoma of the Lung''. **British Medical Journal** 2 (1952), pp. 1271--1286.\n\nEjemplo:\n\n \n\nMuestras de casos y controles\n\nMuestra estratificada: Una muestra formada por números prefijados de casos y controles. Si la muestra es estratificada y con composición artificial, no esperamos que la proporción de casos en la muestra sea representativa de la poblacional\nMuestras transversal: Una muestra sin restricciones en su composición, “la que salga”. Si la muestra es transversal, esperamos que la proporción de casos en la muestra sea representativa de la poblacional\n\n¿Qué tipo de muestra es esta?:\n\n \n\nVentajas de los casos y controles:\n\nEl survey adolece de falta de denominadores: un grupo de control con el que comparar los casos\nRelativamente fáciles de llevar a cabo y rápidos y por lo tanto baratos\nAdecuados para estudiar enfermedades raras, poco frecuentes o de desarrollo muy corto\nPermiten estudiar la asociación entre la exposición a muchos factores de riesgo y la enfermedad que nos ocupa.\n\nProblemas: Sesgos\nSesgos: Errores en el diseño o la ejecución de un estudio que afecte a los datos recogidos y esto pueda perjudicar la corrección de las conclusiones obtenidas en la recogida de datos mediante entrevistas/cuestionarios\n\nSesgo de recuerdo: Todo el mundo miente, Olvidos\nSesgo de recuerdo diferencial: Casos y controles pueden recordar datos relevantes de manera diferente\nSesgo de supervivencia: Solo se estudian individuos ``vivos’’\n\nProblemas: Representatividad\nPara poder concluir que hay asociación entre la exposición y la enfermedad, sería necesario que:\n\nLos controles fueran similares a los casos en todos los aspectos salvo en la exposición\nEmparejamiento: Seleccionar controles que sean similares a los casos en todas las características relevantes\nLos controles fueran representativos de la población de sanos\nEs muy difícil conseguir ambas condiciones. Vigiladlo al leer un artículo.\n\nEjemplo:\n\n\nCasos: 160 niños ingresados por salmonellosis.\n\nControles I: 6301 niños sin salmonellosis. Como los Casos sufrieron mucha menos malaria que controles. Concluyeron que la malaria protege de la salmonellosis.\nControles II: 285 niños ingresados con otras infecciones. Casos sufrieron más malaria que controles. Concluyeron que la malaria es factor de riesgo de salmonellosis.\n\n\n\nProblemas: Confundidores\n\nConfundidor: Una característica asociada con la exposición y que puede causar la enfermedad\n\n\n\n\n\n\nEjemplo:\n\n\n  \n   C. Chi-Ling, T. Gilbert, R. Daling. \"Maternal smoking and Down syndrome: the confounding\neffect of maternal age\". American Journal of Epidemiology, 149 (1999), pp. 442--446.\n\n\nProblemas: Falta de causalidad\nUn estudio de casos y controles no puede “demostrar” que la exposición a un riesgo “cause” una enfermedad.\nEn realidad:\n\nNingún tipo de estudio médico puede demostrar con total seguridad que la exposición a un riesgo causa una enfermedad.\n\n\n\n2.2.5.3 Estudios de cohorte\n\nSe toma un grupo de individuos expuestos a un factor de riesgo y un grupo de no expuestos al mismo.\n\n\n  \n   A. Lokke, P. Lange et al. \"Developing COPD: a 25 year follow up study of the general population\". **Thorax** 61 (2006), pp. 935--939.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representación gráfica y análisis de Datos</span>"
    ]
  },
  {
    "objectID": "t2_intro.html#tipos-básicos-de-muestreo",
    "href": "t2_intro.html#tipos-básicos-de-muestreo",
    "title": "2  Representación gráfica y análisis de Datos",
    "section": "2.3 Tipos básicos de muestreo",
    "text": "2.3 Tipos básicos de muestreo\nEn un estudio estadístico inferencial, se toma una muestra de individuos de una población y se estiman algunas características de la población a partir de las de la muestra. Para que esto tenga sentido, es necesario que la muestra sea razonablemente representativa de la población. Pero, claro, sin conocer las características de la población, no podemos saber si una muestra es representativa o no.\nPara salir de este impasse, la solución comúnmente aceptada es tomar una muestra aleatoria, es decir, escogiendo sus sujetos de alguna manera al azar. Al hacerlo así:\n\nSe evitan preferencias en la elección, por lo que es más probable que la muestra sea representativa de la población. Naturalmente, esto no está garantizado: por pura mala suerte nos puede salir una muestra súper rara, es lo que tiene el azar. Pero al menos hemos hecho “lo que todo el mundo considera que es lo que hay que hacer” para intentar que sea representativa.\n\nExisten muchos métodos de muestreo. A continuación describimos algunos de forma breve.\n\n2.3.1 Muestreo aleatorio con y sin reposición\nEl muestreo aleatorio consiste en seleccionar una muestra de la población de manera que todas las muestras del mismo tamaño sean equiprobables; es decir, que si fijamos el número de individuos de la muestra, cualquier conjunto de ese número de individuos tenga la misma probabilidad de ser seleccionado.\nHay que distinguir entre dos tipos de muestreo aleatorio: con y sin reposición, según permitamos o no que se repitan sujetos en la muestra. Para ilustrarlos, supongamos que disponemos de una urna con 100 bolas numeradas del 1 al 100, de la que queremos extraer una muestra de 15 bolas.\nUna manera de hacerlo sería repetir 15 veces el proceso de sacar una bola de la urna, anotar su número y devolverla a la urna. El tipo de muestra obtenida de esta manera recibe el nombre de muestra aleatoria con reposición, o muestra aleatoria simple. Observad que con este procedimiento una misma bola puede aparecer varias veces en una muestra, y que todos los subconjuntos de 15 bolas “con posibles repeticiones” tienen la misma probabilidad de obtenerse. Un posible resultado serían las bolas azules de la Figura de abajo; la bola azul más oscuro ha sido escogida dos veces en la muestra.\n\n\n\n\n\nOtra manera de extraer la muestra sería repetir 15 veces el proceso de sacar una bola de la urna pero ahora sin devolverla. Esto es equivalente a extraer de golpe 15 bolas de la urna. Estas muestras no tienen bolas repetidas, y cualquier selección de 15 bolas diferentes tiene la misma probabilidad de ser la obtenida. En este caso se habla de una muestra aleatoria sin reposición. Un posible resultado serían las bolas azules de la siguiente figura.\n\n\n\n\n\nCuando el tamaño de la población es muy grande en relación al de la muestra, como suele suceder en la investigación clínica, la probabilidad de que haya repeticiones en una muestra aleatoria simple es muy pequeña. Por ejemplo:\n\nSi escogemos 100 individuos de las Baleares (que tiene alrededor de 1,150,000 habitantes) al azar permitiendo repeticiones, la probabilidad de que se escoja más de una vez algún individuo es de de media, solo en 1 de cada 250 muestras de 100 individuos de las Baleares elegidos al azar permitiendo repeticiones nos saldría alguien repetido.\nSi escogemos 100 estudiantes de la UIB (que tiene alrededor de 12000 estudiantes) al azar permitiendo repeticiones, la probabilidad de que se escoja más de una vez algún individuo es de de media, en algo más de 1 de cada 3 muestras de 100 estudiantes de la UIB elegidos al azar permitiendo repeticiones habría alguien repetido.\nSi escogemos 10 estudiantes de la UIB al azar permitiendo repeticiones, la probabilidad de que se escoja más de una vez algún individuo ya es de 0.004.\n\nYa daremos el detalle de cómo se calculan todas estas probabilidades en el tema siguiente.\nEsto nos permite considerar que, cuando la población es mucho más grande que la muestra, los muestreos aleatorios con y sin reposición son equivalentes en el sentido siguiente: puesto que si la población es muy, muy grande, una muestra aleatoria con reposición tendría casi seguro todos los elementos diferentes, podemos tomar directamente la muestra sin reposición y aceptar que permitíamos repeticiones, pero que no se han dado y que por tanto la muestra es simple.\n\nUna muestra aleatoria de 100 individuos diferentes de las Baleares, o de 10 estudiantes diferentes de la UIB, puede pasar perfectamente por una muestra aleatoria simple, porque aunque permitiéramos repeticiones, sería muy raro que las hubiera.\nPero en cambio ya es difícil de creer que una muestra aleatoria de 100 estudiantes diferentes de la UIB haya sido tomada permitiendo repeticiones, porque de media en una de cada tres muestras tomadas permitiendo repeticiones nos saldría alguna repetición.\n\nEl muestreo aleatorio simple es el estándard de excelencia entre los métodos de muestreo, y la mayoría de los resultados que explicaremos en este curso presuponen que la muestra ha sido tomada aleatoria con reposición. Pero casi nunca es factible hacerlo. El motivo es que para poder tomar una muestra aleatoria de una población en el sentido de este apartado, con o sin reposición, es necesario disponer de una lista completa de todos sus individuos para poder sortear a quién vamos a seleccionar. Esto no siempre es posible. ¿Alguien tiene la lista completa de, pongamos, todos los diabéticos de España? ¿Que incluya los que no saben que lo son? Por lo tanto, en la vida real no siempre podemos tomar muestras aleatorias en este sentido.\n\n2.3.1.0.1 Muestras aleatorias con Jamovi\nCualquier paquete estadístico que se precie permite obtener muestras aleatorias de conjuntos. Con R, la función básica es\n\nsample(x, n, replace=...)\n\ndonde:\n\nx es un vector que contiene toda la población o un número natural \\(x\\); en este último caso, R entiende que representa el vector 1,2,…,\\(x\\);\nn es el tamaño de la muestra que deseamos extraer;\nel parámetro replace puede igualarse a TRUE, y será una muestra aleatoria con reposición, es decir, simple, o a FALSE, y será una muestra aleatoria sin reposición. Si no se especifica este parámetro, R entiende que ha de tomar la muestra sin reposición.\n\nPodéis ejecutar las funciones de R que iremos dando en estas notas en la ventana del editor de R de JAMOVI. Para tener acceso a ella, tenéis que instalar el módulo Rj (pulsando en el signo + de la esquina superior derecha de la ventana de JAMOVI y navegando entre las diferentes opciones).\nAsí, por ejemplo, para obtener una muestra aleatoria simple de 15 números elegidos entre 1 y 100, podemos entrar:1\n\nsample(100,15,replace=TRUE)\n\n [1] 75  1 20 35 37 78 33 18 76 16  1 67 70  5 67\n\n\nNaturalmente, cada ejecución de sample con los mismos parámetros puede dar (y seguramente dé) lugar a muestras diferentes, y todas ellas tienen la misma probabilidad de aparecer. Aquí tenéis tres ejecuciones consecutivas de la instrucción anterior en la ventana del editor de R de JAMOVI:\n\n\n\n\n\n\nEjemplos grupos paralelos:\nEn el marco de un estudio experimental, tenemos que asignar al azar 60 pacientes a dos tratamientos, de manera que cada paciente tenga un 50% de probabilidades de caer en uno u otro grupo de tratamiento tratamiento. Si indicamos los dos tratamientos por 1 y 2 (por ejemplo, que 1 sea el tratamiento control y 2 el tratamiento nuevo), podemos numerar los sujetos de 1 a 60 y a continuación tomar una muestra aleatoria simple de tamaño 60 de valores 1 o 2 y a cada sujeto asignarle el tratamiento que le corresponda en esta muestra. Para ello, ejecutamos\n\nsample(2,60,replace=TRUE)\n\n [1] 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 2 2 1 1 1 2 1 1 2 1 2 2 1 1 2 2 1 2 2 1 2\n[39] 1 2 1 1 2 1 2 2 2 2 1 1 1 1 2 1 1 2 1 2 2 2\n\n\nDe esta manera se asignarían 31 pacientes al tratamiento 1 y 29 al tratamiento 2: los tres primeros al tratamiento 1, el cuarto al tratamiento 2, el quinto al tratamiento 1 etc.\nSi hubiéramos querido forzar que cada grupo de tratamiento tuviera 30 pacientes, hubiéramos podido tomar una muestra aleatoria sin reposición de tamaño 30 de los 60 pacientes, asignar a sus miembros uno de los tratamientos y al resto el otro tratamiento. Así, podríamos asignar el tratamiento 1 a los pacientes\n\nsort(sample(60,30,replace=FALSE))\n\n [1]  1  2  5  6  8  9 13 15 16 17 22 23 24 26 27 29 35 36 38 39 41 44 45 48 51\n[26] 52 54 58 59 60\n\n\n(La función sort, como su nombre en inglés indica, sirve para ordenar vectores.)\n\n\n\n\n2.3.2 Muestreo sistemático\nUna manera muy sencilla de obtener una muestra de una población cuando disponemos de una lista ordenada de sus individuos y nos da pereza efectuar un sorteo es tomarlos a intervalos constantes: uno de cada cinco individuos, uno de cada diez… Podemos añadir un componente aleatorio escogiendo al azar el primer individuo que elegimos, y a partir del cual empezamos a contar. A esta técnica se la llama muestreo sistemático o a intervalos, añadiendo el adjetivo aleatorio si además el primer sujeto se escoge de manera aleatoria.\nAsí, por ejemplo, si de una clase de 100 estudiantes quisiéramos escoger una muestra de 10, podríamos elegir un estudiante al azar, y a partir de él, por orden alfabético, elegir el décimo estudiante, el vigésimo, el trigésimo, etc.; si al llegar al final de la lista de clase no hubiéramos completado la muestra, volveríamos al principio de la misma.\nLa Figura que mostramos a continuación describe una muestra aleatoria sistemática de 15 bolas de nuestra urna de 100 bolas: hemos empezado a escoger por la bola roja oscura, que ha sido elegida al azar, y a partir de ella hemos tomado las bolas a intervalos de 7, volviendo al principio cuando hemos llegado al final de la lista numerada.\n\n\n\n\n\nCuando no disponemos de una lista de toda la población pero sí que tenemos una manera de acceder de manera ordenada a sujetos de la misma (por ejemplo, enfermos que acuden a un hospital), podemos realizar un muestreo sistemático tomando los sujetos a intervalos constantes a medida que los encontramos y hasta completar el tamaño deseado de la muestra. Por ejemplo, para escoger una muestra de 10 pacientes que hayan acudido a Urgencias por traumatismos en la cabeza, podríamos escoger pacientes a intervalos regulares de entre los que acudieran a Urgencias por este motivo hasta llegar a los 10.\n\n\n\n\n\n\nNota\n\n\n\nSi la lista de la población está ordenada al azar y la población es muy grande (tanto que con el muestreo sistemático no llegamos al final de la lista para tener que volver a empezar), o si los sujetos que vamos tomando a intervalos regulares nos aparecen al azar, el resultado del muestreo sistemático es equivalente a una muestra aleatoria sin reposición.\n\n\n\n\n2.3.3 Muestreo aleatorio estratificado\nEste método de muestreo se utiliza cuando la población está clasificada en estratos que son de interés para la característica que se estudia. Estos estratos serán grupos de individuos definidos por un atributo concreto, de manera que individuos del mismo estrato tengan ese atributo igual (los estratos sean homogéneos internamente) y individuos de estratos diferentes tengan ese atributo diferente. Por ejemplo, la clasificación en estratos puede venir dada por los sexos, franjas de edad, provincias, casos y controles… En este caso, se toma una muestra de un tamaño prefijado de cada estrato y se unen en una muestra global. Este proceso es llamado muestreo estratificado, aleatorio si la muestra de cada estrato es aleatoria.\nPor lo que refiere a los tamaños de las muestras de cada estrato, se suele optar por una de las estrategias siguientes:\n\nImponer que la composición por estratos de la muestra global mantenga las proporciones de la población original, de manera que el tamaño de la muestra de cada estrato represente el mismo porcentaje del total de la muestra que el estrato correspondiente en la población completa.\nTomar las muestras de los diferentes estratos del mismo tamaño.\nTomar los tamaños de manera que los estratos que representen una fracción muy pequeña de la población (tan pequeña que no esperaríamos que tuvieran representación en una muestra aleatoria transversal de la población, es decir, tomada del total de la población sin tener en cuenta su composición en estratos) tengan una representación en la muestra mucho mayor que la que les tocaría.\n\nPor ejemplo, los estratos podrían ser grupos de edad y podríamos tomar la muestra de cada grupo de edad de tamaño proporcional a la fracción que representa dicho grupo de edad en la población total. O podrían ser los sexos y procuraríamos que nuestra muestra estuviera formada por un 50% de hombres y un 50% de mujeres. O, en las Islas Baleares, los estratos podrían ser las islas, y entonces podríamos imponer que el número de representantes de cada isla en la muestra fuera proporcional a su población relativa dentro del conjunto total de la Comunidad Autónoma, o podríamos tomar la misma cantidad de individuos de cada isla, independientemente de su población.\nPara continuar con nuestra urna de 100 bolas, supongamos que contiene 40 bolas de un color y 60 de otro color según muestra la siguiente figura.\n\n\n\n\n\nPara tomar una muestra aleatoria estratificada de 15 bolas, considerando como estratos los dos colores e imponiendo que la muestra refleje la composición de la urna, tomaríamos una muestra aleatoria de 6 bolas del primer color y una muestra aleatoria de 9 bolas del segundo color. De esta manera, los porcentajes de colores en la muestra serían los mismos que en la urna. La figura de abajo describe una muestra obtenida de esta manera.\n\n\n\n\n\nPara tomar una muestra aleatoria estratificada de 10 bolas, de nuevo considerando como estratos los dos colores pero ahora imponiendo que cada color aporte la misma cantidad de bolas a la muestra, tomaríamos una muestra aleatoria de 5 bolas del primer color y una muestra aleatoria de 5 bolas del segundo color.\nLa ventaja del muestreo aleatorio estratificado respecto del transversal es que, como el investigador escoge una muestra de cada estrato de la población del tamaño que considera adecuado:\n\nPermite estimar la información de interés para cada estrato por separado, como si se tratara de estudios independientes.\nPermite estimar la información sobre subpoblaciones minoritarias que en una muestra aleatoria transversal aparecerían subrepresentadas.\n\nEn todo caso, el muestreo por estratos solo es necesario si esperamos que las características que queremos estudiar varíen según el estrato. Por ejemplo, si queremos tomar una muestra para estimar la altura media de los españoles adultos y no creemos que la altura de un español adulto dependa de su provincia de origen, no hay ninguna necesidad de esforzarse en tomar una muestra de cada provincia de manera que todas estén representadas adecuadamente en la muestra.\nObservad que el muestreo aleatorio por estratos tiene el mismo inconveniente que el muestreo aleatorio: es necesario disponer de una lista completa de los individuos de cada estrato para poder sortearlos.\n\n\n2.3.4 Muestreo por conglomerados\nEl proceso de obtener una muestra aleatoria en el sentido de las secciones anteriores puede ser caro o difícil en algunos casos, incluso aunque dispongamos de la lista completa de la población. Imaginad que quisiéramos estudiar la prevalencia y gravedad de la miopía entre los estudiantes de Primaria de las Baleares. Para ello tendríamos que seleccionar una muestra representativa de esta población de escolares. Seguramente, con algo de esfuerzo, podríamos disponer de su lista completa para este curso y por lo tanto podríamos tomar una muestra aleatoria, pero entonces acceder a las niñas y niños que la formasen seguramente significaría visitar muchos centros de primaria para entrevistar unos pocos alumnos de cada uno. Esto volvería el proceso lento y costoso. Y eso si consiguiéramos la lista global de alumnos.\nUna alternativa posible sería, en vez de elegir una muestra aleatoria de todos los estudiantes de Primaria, escoger primero al azar unas pocas aulas de primaria de colegios de las Baleares, a las que llamamos en este contexto conglomerados o clústers, y formar entonces nuestra muestra con todos los alumnos de estas aulas. Estaréis de acuerdo en que es mucho más fácil disponer de la lista completa de estudiantes de unas pocas aulas que conseguir la lista completa de todos los estudiantes de la Comunidad, y mucho más cómodo ir a unos pocos colegios a entrevistar grupos enteros que ir a muchos colegios a entrevistar a unos pocos estudiantes de cada uno.\nEn un muestreo aleatorio por conglomerados o clústers, tenemos la población repartida en pequeños grupos, los clústers, y lo que hacemos es elegir al azar una muestra de clústers y tomar todos los individuos de los clústers elegidos.\nVolviendo de nuevo a nuestra urna, supongamos que sus 100 bolas se agrupan en 20 conglomerados de 5 bolas cada uno según las franjas verticales de la figura de abajo (donde mantenemos la clasificación en dos colores para poder comparar el resultado del muestreo por conglomerados con el estratificado).\n\n\n\n\n\nPara obtener una muestra aleatoria por conglomerados de tamaño 15, escogeríamos al azar 3 conglomerados y la muestra estaría formada por todas sus bolas. La figura siguiente describe una muestra obtenida de esta manera: los conglomerados escogidos están marcados en azul.\n\n\n\n\n\nA menudo una vez elegidos los clústers no se toman todos los sujetos de los mismos, sino una muestra aleatoria de cada uno. Esto ya sería un ejemplo de muestreo polietápico.\nEl muestreo por conglomerados se suele elegir por ser rápido de realizar, pero puede tener un inconveniente: puede que los sujetos de cada clúster tiendan a parecerse los unos a los otros, lo que puede sesgar la muestra. Este método de muestreo es más efectivo cuando los clústers sean heterogéneos en este sentido. En nuestro ejemplo de los niños de primaria de las Baleares, es más creíble que las clases sean heterogéneas por lo que refiere a la miopía que en lo referente a comportamientos en los que influya la pertenencia a un grupo social, por ejemplo la series de TV preferidas.\n\n\n\n\n\n\nNota\n\n\n\nRevisemos la diferencia entre el muestreo estratificado y el muestreo por conglomerados:\n\nMuestreo estratificado:\n\nLos estratos forman una clasificación de los sujetos de la población en grupos grandes definidos por una propiedad que consideramos relevante en el estudio estadístico. Por ejemplo, el sexo o la franja de edad.\nSe escoge una muestra de cada estrato.\n\nMuestreo por conglomerados:\n\nLos conglomerados forman una clasificación de los sujetos de la población en grupos pequeños definidos por una propiedad que en principio es irrelevante en el estudio estadístico. Por ejemplo, la manzana donde viven o el médico de familia al que están asignados.\nSe escogen algunos conglomerados y se forma la muestra con todos sus miembros.\n\n\n\n\n\n\n2.3.5 Muestreos no aleatorios\nCuando la selección de la muestra no es aleatoria, se habla de muestreo no aleatorio. En realidad es el tipo más frecuente de muestreo porque casi siempre nos tenemos que conformar con los sujetos disponibles. Por ejemplo, en la UIB, para estimar la opinión que de un profesor tienen los alumnos de una clase, solo se tiene en cuenta las respuestas de los estudiantes que voluntariamente rellenan la encuesta de opinión, que de ninguna manera forman una muestra aleatoria: el perfil del estudiante que responde voluntariamente una encuesta de este tipo es muy específico y no viene determinado por el azar. En este caso se trataría de una muestra auto-seleccionada.\nOtro tipo de muestras no aleatorias son las oportunistas. Este es el caso, por ejemplo, si para estimar la opinión que de un profesor tienen los alumnos de una asignatura se visita un día la clase y se pasa la encuesta a los estudiantes presentes ese día. De nuevo, puede que esos alumnos no sean representativos del alumnado de la asignatura (pueden ser los más aplicados, o los menos enfermizos, o los no repetidores).\nLa fgura de abajo describe una muestra oportunista de nuestra urna: sus 15 primeras bolas.\n\n\n\n\n\nLas técnicas de estadística inferencial no se pueden aplicar a muestras no aleatorias. Pero normalmente solo podemos conseguir muestras no aleatorias. En este caso, lo mejor es describir en detalle las características de la muestra para justificar que, pese a no ser aleatoria, podría pasar por aleatoria y es razonablemente representativa de la población. Por ejemplo, la muestra oportunista anterior de nuestra urna no es de ninguna manera representativa de su contenido por lo que refiere al color de las bolas.\n\n\n2.3.6 Muestreo polietápico\nEn el ejemplo de los estudiantes de Primaria, la muestra final de estudiantes estaba formada por todos los de las aulas elegidas. Otra opción podría haber sido, tras seleccionar la muestra aleatoria de aulas, entrevistar solo una muestra aleatoria de estudiantes de cada una (si por ejemplo nuestro presupuesto no da para procesar las entrevistas a todos los estudiantes de las aulas elegidas). Otro ejemplo: algunos estudios poblacionales a nivel estatal se realizan solamente en algunas provincias escogidas aleatoriamente, en las que luego se encuesta una muestra aleatoria de habitantes. Los dos son ejemplos de muestreos polietápicos, en los que la muestra no se obtiene en un solo paso, sino mediante diversas elecciones sucesivas.\nLa siguiente figura muestra un ejemplo sencillo de muestreo polietápico de nuestra urna: hemos elegido al azar 5 conglomerados (marcados en azul) y de cada uno de ellos hemos elegido 3 bolas al azar sin reposición.\n\n\n\n\n\n\n\n2.3.7 Otros tipos de muestreo\nExisten otros tipos de muestreo, solo hemos explicado los más comunes. En cualquier caso, lo importante es recordar que el estudio estadístico que se realice tiene que adaptarse al tipo de muestreo usado. Por ejemplo, no se pueden usar las mismas técnicas para analizar una muestra aleatoria simple que una muestra estratificada o una muestra por conglomerados. En este curso nos ocuparemos casi exclusivamente del muestreo aleatorio simple, es decir, al azar y con reposición, o al azar sin reposición si la población es muy grande comparada con la muestra.\n\n\n2.3.8 Sesgos\nUn sesgo es cualquier tipo de error sistemático en el diseño o la ejecución de un estudio que afecte a los datos recogidos y perjudique la corrección de las conclusiones obtenidas.\nLos errores que pueden dar lugar a sesgos no se han de confundir con el error aleatorio inherente a las mediciones. Por ejemplo, no son sesgos los errores de medición debidos a la imprecisión del instrumento. La estadística nos proporciona herramientas para tratar el error aleatorio, pero las fuentes de sesgo se han de eliminar al diseñar el estudio o detectarlas al leer un estudio para valorar la validez de sus conclusiones.\nMuchos autores han producido listas larguísimas de tipos de sesgos que muestran la creatividad de los humanos a la hora de fastidiarla y de poner nombres a las diferentes maneras de fastidiarla. Aquí solo vamos a introducir algunos de los más comunes. En este url encontraréis una lista algo más larga, aunque tampoco es exhaustiva.\n\nSesgo de selección: Se produce cuando la muestra seleccionada no es representativa de la población objetivo. Por poner un ejemplo exagerado, sería el caso si quisiéramos saber la incidencia del cáncer de ovario en una comunidad y para ello tomáramos una muestra de solo hombres.\nHay varios subtipos que vale la pena distinguir:\n\nSesgo de falta de representatividad: Cuando la muestra no es representativa debido a un defecto en su obtención.\nPor ejemplo, una muestra de hombres para estimar la incidencia del cáncer de ovario; o una muestra de voluntarios que se ofrezcan para que les hagan unas pruebas dolorosas a cambio de una compensación económica.\nUn ejemplo frecuente en medicina y con nombre propio (sesgo de Berkson) se produce cuando para estudiar la influencia de algunos factores de riesgo en una enfermedad, se toman como controles pacientes hospitalizados. Los pacientes hospitalizados tendrán unas patologías más severas que la población en general, y puede que ello se deba a que su exposición a factores de riesgo sea mayor que la de la población en general.\nSesgo de selección diferencial: Cuando el sesgo de selección se da en unos grupos sí y en otros no, o cuando se da de manera diferente en los diferentes grupos.\nSiguiendo con el ejemplo de la influencia de algunos factores de riesgo en una enfermedad que en principio no conlleve hospitalización, se daría si tomáramos los casos entre enfermos hospitalizados (que no tienen por qué ser representativos del global de enfermos) y los controles entre individuos no hospitalizados.\nSesgo de supervivencia: Cuando se toma una muestra de pacientes vivos de una enfermedad con una alta tasa de mortalidad. En este caso, es muy probable que la muestra incluya una proporción muy elevada de enfermos que hayan sobrevivido más de lo normal, y estos no tienen por qué ser representativos del colectivo de enfermos de esta enfermedad.\n\nSesgo de medida: Se produce cuando el método de medición es defectuoso en algún sentido. Incluye, por ejemplo:\n\nSesgo de recuerdo: En estudios en los que recojamos la información sobre exposición por medio de entrevistas o encuestas, existe la posibilidad de que algunos encuestados hayan olvidado información, o simplemente de que mientan en temas delicados.\nSesgo de recuerdo diferencial: Es un caso particular del anterior, y se da cuando diferentes grupos de sujetos tienen diferente probabilidad de cometer errores en sus recuerdos (o de mentir). Por ejemplo, en estudios de casos y controles en los que se recoge la información sobre exposición por medio de entrevistas o encuestas, los casos tienen mayor tendencia a recordar su exposición a circunstancias que ellos asocien a la enfermedad que los controles.\nSesgo de procedimiento: Cuando el clínico analiza de manera diferente un grupo que otro. Se daría, por ejemplo, en un ensayo clínico si se llevara a cabo un seguimiento más frecuente a los que toman un nuevo tratamiento que a los controles, por si presentan efectos secundarios inesperados.\nSesgo de detección: Cuando se usan varios métodos con diferente sensibilidad para detectar una enfermedad o una exposición. Este sesgo también puede ser diferencial si los diferentes métodos se usan sobre grupos diferentes.\nA modo de ejemplo, se daría un sesgo de detección si para saber si los sujetos de una muestra han tomado un medicamento, a algunos se les pasa una encuesta y a otros se les consulta el historial clínico. Sería diferencial si, además, por ejemplo, los primeros fueran los participantes sanos y los segundos los enfermos.\nSesgo de atención: Cuando los participantes en un estudio alteran su comportamiento porque se saben observados o porque participan en el estudio (a veces se lo denomina efecto Hawthorne).\nSe podría dar, por ejemplo, en un estudio sobre el efecto del ejercicio físico en la salud si los sujetos del grupo de intervención (a los que se ha asignado el hacer ejercicio físico) deciden tomar otros nuevos hábitos saludables porque saben que se les ha asignado al grupo “saludable”. Entonces puede que el efecto que se observe en este grupo no se deba al ejercicio físico sino al cambio en otros comportamientos.\nEl “efecto Hawthorne” refiere al nombre de una fábrica en el que se realizó un estudio sobre qué condiciones aumentaban la productividad, y todos los grupos aumentaron su productividad durante el seguimiento. Este aumento se debió al efecto “motivador” de ser observados, porque cuando terminó el estudio volvieron todos a su productividad normal.\nSesgo de error instrumental: Cuando los instrumentos usados para medir alguna característica son defectuosos. Sería el caso, por ejemplo, del esfigmomanómetro del primer párrafo de esta sección.\n\nConfusión. Se da cuando el efecto de la exposición a un riesgo A se confunde con el de la exposición a otro factor B (el confundidor) que está asociado a la exposición a A y que es el verdadero causante del desenlace X que estamos estudiando.\nHemos explicado varios ejemplos de confundidores al hablar de los problemas de los estudios de casos y controles (Sección @ref(sec:cyc)). Por ejemplo, la asociación entre que la madre sea fumadora y una disminución del riesgo de que el hijo tenga síndrome de Down, debida en realidad al factor de confusión dado por la edad de las madres. Por poner otro ejemplo, si en un estudio se observa una asociación entre una patología durante el embarazo y un defecto en los recién nacidos, podría ser que la causa del desenlace no fuera la enfermedad de las madres sino el tratamiento que se les hubiera admninistrado relacionado con la misma.\nHemos incluido la confusión en la lista de sesgos, pero su naturaleza es diferente de los anteriores. Un sesgo es un error sistemático en la recolección de datos, mientras que no tener en cuenta los posibles confundidores es un error que tanto se puede cometer al diseñar el estudio como al interpretar los resultados.\n\nHay muchos otros tipos de sesgos. No es importante en este curso saber sus nombres. Lo importante es aplicar el sentido común al leer la Metodología de un estudio para entender qué procesos podrían haber desviado los datos recogidos y cómo estos sesgos afectan las conclusiones del estudio.\nEjemplo: El caso de una revista del corazón que, para conocer la opinión de sus lectores sobre la familia real española, propuso una encuesta en línea en su web. ¿Qué sesgos se pudieron dar?\n(1.a) ¿Sesgo de falta de representatividad? Sí, claro. Los voluntarios que rellenan encuestas en Internet no tienen por qué ser representativos del total de lectores de la revista.\n(1.b) ¿Sesgo de selección diferencial? No, porque no se eligieron dos grupos.\n(1.c) ¿Sesgo de supervivencia? No, se supone que les interesaba conocer la opinión de sus lectores vivos en ese momento, ¿verdad?\n(2.a) ¿Sesgo de recuerdo? Sí, claro, tenemos que tenerlo en cuenta siempre que se recoja información por medio de cuestionarios o entrevistas. Los participantes podrían haber querido dar una mejor opinión de la familia real española que la que realmente tienen para quedar bien o hacer quedar bien a la revista.\n(2.b) ¿Sesgo de recuerdo diferencial? De nuevo, no, porque no se eligieron dos grupos.\n(2.c,d) ¿Sesgo de procedimiento o de detección? No, por el mismo motivo\n(2.e) ¿Sesgo de atención? No, porque no se hizo un seguimiento a los participantes, por lo que si cambiaron su comportamiento, no afectó al resultado de la encuesta.\n(2.f) ¿Sesgo de error instrumental? Podría ser, si el cuestionario estuviera amañado en algún sentido. A lo mejor recordáis el famoso caso de la encuesta de satisfacción de Ryanair en 2017 en la que en la pregunta sobre el grado de satisfacción con su experiencia de vuelo con ellos, las únicas respuestas que se ofrecían eran “Excelente”, “Muy buena”, “Buena”, “Aceptable” y “OK”.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representación gráfica y análisis de Datos</span>"
    ]
  },
  {
    "objectID": "t2_intro.html#footnotes",
    "href": "t2_intro.html#footnotes",
    "title": "2  Representación gráfica y análisis de Datos",
    "section": "",
    "text": "Cuando damos código de R en el texto y su resultado, este va precedido de ##; si hubiéramos ejecutado la instrucción de R en la ventana del editor de R de JAMOVI, el resultado aparecería en la ventana de resultados a la derecha. Cuando el resultado es un vector, como en este caso, R comienza cada línea del resultado con un número entre corchetes [ ]. No lo tengáis en cuenta. Este número indica la posición de la primera entrada de esa línea dentro del vector que forma el resultado. Así, la primera fila siempre empieza con [1].↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Representación gráfica y análisis de Datos</span>"
    ]
  },
  {
    "objectID": "t3_losDatosTipos.html",
    "href": "t3_losDatosTipos.html",
    "title": "3  Los datos y sus tipos",
    "section": "",
    "text": "Las técnicas básicas de estadística descriptiva consisten en una serie de valores y gráficos que nos permiten resumir y explorar un conjunto de datos, con el objetivo final de entenderlos o describirlos lo mejor posible.\nLos datos de los que disponemos suelen ser multidimensionales, en el sentido de que observamos varias características (variables) de una serie de individuos. Almacenamos estos datos en tablas de datos como la que presentamos abajo, donde cada columna corresponde a una variable y cada fila son los datos de un individuo concreto. Así, en esta tabla, cada fila representa un niño y cada columna recoge una de las características que hemos anotado: su nombre, su altura (en cm), su número de hermanos, el color de sus cabellos, el número semanal de refrescos que suele tomar, y su grado de satisfacción con un juego para móvil (entre 0 y 5).\n\n\n\n\nUna pequeña tabla de datos sobre niños\n\n\n\nNombre\nAltura\nHermanos\nCabello\nRefrescos semanales\nSatisfacción App\n\n\n\n\n1\nMarta\n135\n2\nrubio\n2-3\n4\n\n\n2\nLaura\n132\n1\nnegro\n2-3\n4\n\n\n3\nXavier\n138\n0\nnegro\n0-1\n3\n\n\n4\nJoan\n141\n3\ncastaño\n4-5\n2\n\n\n5\nMaria\n134\n2\nrojo\n0-1\n3\n\n\n6\nMaria\n136\n1\ncastaño\n6 o más\n5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrecaución\n\n\n\nEn este curso vamos a “sobrecargar” el término variable, en el sentido de que tendrá dos significados diferentes que esperamos que podáis distinguir según el contexto:\n\nPor un lado, llamaremos variable a una característica que puede tomar diferentes valores sobre diferentes individuos; cuando tenga este sentido, a veces le añadiremos el adjetivo poblacional. Por ejemplo, la altura de las personas (de todo el mundo, de un país, de una ciudad…) es una variable poblacional.\nPor otro lado, también llamaremos una variable a un vector formado por los valores de una variable poblacional sobre los sujetos de una muestra. Por ejemplo, las alturas de los niños recogidas en la tabla forman una variable en este sentido.\n\n\n\nLos tipos básicos de datos que consideramos en este curso son los siguientes:\n\nDatos cualitativos. Son los que expresan una cualidad del individuo, como por ejemplo el sexo cromosómico (macho, hembra), el género de una persona (hombre, mujer, lesbiana, gay, bisexual, transexual, intersexual, asexual), tipos de cáncer (de mama, de colon, de próstata…)… Si solo pueden tomar dos valores (“Sí” o “No”, “Macho” o “Hembra”…) los llamamos binarios o dicotómicos y si pueden tomar más de dos valores, politómicos o multicotómicos, dependiendo de lo que queramos complicar los adjetivos. A los posibles valores que puede tomar un tipo de datos cualitativo se los suele llamar niveles.\nLos datos cualitativos pueden ser iguales o distintos, y no admiten ningún otro tipo de comparación.\nDatos ordinales. Son datos similares a los cualitativos, en el sentido de que expresan una cualidad del individuo, pero con la diferencia de que se pueden ordenar de manera natural. Por ejemplo, los niveles de gravedad de una enfermedad (sano, leve, grave, muy grave, …) o las calificaciones en un examen (suspenso, aprobado, notable, sobresaliente) son datos ordinales. En cambio, no se pueden ordenar de manera significativa los sexos o los tipos de cáncer de los individuos: por eso son datos cualitativos y no ordinales.\nTambién se suele llamar a los posibles valores que puede tomar un tipo de datos ordinal sus niveles.\nDatos cuantitativos. Son datos que se refieren a medidas que sean números genuinos, con los que tenga sentido operar, tales como edades, longitudes, pesos, tiempos, números de individuos, etc. Distinguimos dos tipos:\n\nDiscretos: Pueden tomar solo valores que avanzan a saltos y que podemos identificar con números naturales: número de hermanos, número de ingresos en un día en un hospital…\nContinuos: Podrían tomar cualquier valor real dentro de un intervalo si se pudieran medir con precisión infinita: altura, temperatura, tiempo…\n\n\n\nEjemplo:\nEn la tabla anterior:\n\nLa variable “Nombre” es cualitativa.\nLa variable “Altura” es cuantitativa continua.\nLa variable “Hermanos” es cuantitativa discreta.\nLa variable “Cabello” es cualitativa.\nLa variable “Refrescos semanales” es ordinal.\nLa variable “Satisfacción App” también es ordinal.\n\n\nDos puntos relevantes a tener en cuenta y que justifican algunas clasificaciones que puede que encontréis dudosas en el ejemplo anterior:\n\nNo todo número es un dato cuantitativo. Solo los consideramos cuantitativos cuando son números genuinos, “de verdad”. Por ejemplo, si pedimos a un paciente que califique su dolor con un número natural de 0 a 10, no es un dato cuantitativo, sino ordinal:\nNo es una medida precisa del dolor; no son números “de verdad”, sino abreviaturas de “Nada”, “Un poquito”,…, “Matadme”.\nTener dolor 6 no significa “tener el doble de dolor” que tener dolor 3 (si lo significara, ¿cuál sería el valor correspondiente “al doble de dolor” que 7?). En cambio, una persona con 6 hermanos sí que tiene el doble de hermanos que si tuviera 3.\nNo tiene sentido sumarlos u operarlos en general. Por ejemplo, si yo tengo dolor de nivel 6 y tú tienes dolor de nivel 5, entre los dos no tenemos dolor de nivel 11. En cambio, si yo tengo 6 hermanos y tú 5, entre los dos sí que tenemos 11 hermanos.\n\nEste es justamente el caso de la variable “Satisfacción App” de la tabla anterior. Pese a que sus valores son números, el único contenido real que tienen es su orden: a la María que toma muchos refrescos le ha gustado la app bastante más que a la María que apenas toma refrescos.\n\nLa distinción discreto-continuo es puramente teórica. En realidad, todo dato es discreto porque no podemos medir nada con precisión infinita, pero las herramientas matemáticas “continuas” (derivadas, integrales, etc.) son mucho más potentes que las discretas, por lo que siempre que tenga sentido, es conveniente considerar una variable como continua.\n\nObservad, por ejemplo, la diferencia entre la altura, pongamos que medida en cm y redondeada a unidades como en la tabla anterior, y el número de hermanos. Ambos se presentan como números naturales, pero los números de hermanos no admiten mayor precisión, mientras que las alturas las podríamos medir, con los aparatos adecuados, en mm, en µm, en nm…. Como además las herramientas para tratar datos continuos son mucho más potentes, vamos a considerar las alturas como datos continuos, mientras que los números de hermanos no hay más remedio que tratarlos como discretos.\nEn concreto, es conveniente considerar en la práctica como datos continuos aquellos que dan lugar a números naturales muy grandes, como por ejemplo los números de glóbulos rojos en un litro de sangre, de bases nucléicas en un genoma, o de personas de un país. La diferencia entre diez millones, diez millones uno, diez millones dos… puede considerarse como continua: de hecho, si tomamos el millón como unidad, la diferencia está en la séptima cifra decimal.\n\n\n\n\n\n\nNota\n\n\n\nHemos dicho que la variable “Cabello” es cualitativa. En principio, el color de los cabellos no tiene ningún orden “natural”. Pero si en un estudio definimos un orden claro para esta variable (por ejemplo, por la longitud de onda correspondiente) y este orden es relevante en nuestro estudio, habrá que considerarla una variable ordinal.\nLa variable “Refrescos semanales” es de un tipo de datos ordinales muy concreto que a veces se califican de cuantitativos agrupados: sus niveles se obtienen agrupando en intervalos los posibles valores de una variable cuantitativa (en este caso, la variable discreta que mide el número preciso de refrescos semanales).\n\n\n\nEl análisis, tanto descriptivo como inferencial, de un conjunto de datos es diferente según su tipo.\n\nAsí, para datos cualitativos sólo tiene interés estudiar y representar las frecuencias con que aparecen sus diferentes valores, mientras que el análisis de datos cuantitativos suele involucrar el cálculo de medidas estadísticas, como la media o la desviación típica, que expresen numéricamente sus propiedades.\n\n3.0.1 Descripción de datos cualitativos\nLos datos cualitativos corresponden a observaciones sobre cualidades de un objeto o individuo, tales como su especie o su sexo, que pueden ser iguales o diferentes y no admiten ningún otro tipo de comparación significativa: por ejemplo, datos para los que no tenga ningún sentido preguntarse si uno es más grande que otro, ni efectuar operaciones aritméticas con ellos, aunque estén representados por números. Llamaremos niveles a los diferentes valores que puede tomar una variable cualitativa; por ejemplo, los dos niveles de una variable “Sexo” serían “Macho” y “Hembra”, o sinónimos.\nLo único que podemos hacer con un conjunto de datos cualitativos es contar cuántas veces aparece cada nivel y presentar estas frecuencias en una tabla o por medio de un gráfico. Distinguiremos entre:\n\nFrecuencia absoluta de un nivel: el número de veces que aparece en la muestra.\nFrecuencia relativa de un nivel: la fracción del total de la muestra que representa este nivel.\n\nAdemás, llamaremos la moda al nivel (o a los niveles, en caso de empate) más frecuente. A veces usaremos adjetivos como unimodal, bimodal, multimodal etc. para referirnos, respectivamente, a una variable con una sola moda, con dos modas, con “varias” modas, etc.\nEjemplo:\n\nHemos recogido información sobre 20 residentes en geriátricos que en el período marzo-mayo de 2020 tuvieron COVID-19. Uno de los datos que hemos recogido sobre estas personas ha sido su sexo. El resultado ha sido una variable cualitativa, que llamaremos “Sexo”, formada por las 20 observaciones siguientes:\n\nMujer,  Mujer,  Hombre,  Mujer,  Mujer,  Mujer,  Mujer,  Mujer,  Hombre, Mujer,\nHombre,  Hombre,  Mujer,  Mujer,  Hombre,  Mujer,  Mujer,  Mujer,  Mujer,  Hombre\n\nSus dos niveles son Hombre y Mujer. En esta variable hay 14 mujeres y 6 hombres. Por lo tanto, éstas son las frecuencias absolutas de estos niveles. Puesto que en total hay 20 individuos, sus frecuencias relativas son:\n\nHombre: 6/20=0.3\nMujer: 14/20=0.7\n\nLa moda de la muestra es el nivel Mujer.\nResumimos estas frecuencias en la tabla de frecuencias siguiente:\n\n\n\n\n\n\nFrecuencia absoluta\nFrecuencia relativa\nPorcentaje\n\n\n\n\nHombre\n6\n0.3\n30%\n\n\nMujer\n14\n0.7\n70%\n\n\nTotal\n20\n1.0\n100%\n\n\n\n\n\n\n\n\nEl término moda y los adjetivos unimodal, bimodal, etc. también se usan en variables poblacionales: dada una variable poblacional cualitativa, su moda es el nivel más frecuente en el total de la población, cuando existe.\nPero en el caso poblacional, decimos que la variable es unimodal cuando hay un nivel que es mucho más frecuente que el resto, no basta con que haya uno más frecuente. De manera similar, bimodal no significa que la mayor frecuencia de un nivel en la población se dé en dos niveles que empaten exactamente, sino que hay dos niveles con frecuencias parecidas y mucho mayores que el resto.\nPor ejemplo, supongamos que tenemos una variable poblacional que puede tomar 4 valores excluyentes: A, B, C, D.\n\nSi en el total de la población los niveles A y B se dan, cada uno, en un 25.1% de los individuos, y los niveles C y D cada uno en un 24.9% de los individuos, no diremos que la variable sea bimodal.\nSi en el total de la población el nivel A se da en un 42% de los individuos, el nivel B en un 41% de los individuos, el nivel C en un 9% y el nivel D en un 8%, sí que diremos que es bimodal, aunque A sea más frecuente que el resto.\n\n\n\n\nCon Jamovi, tras entrar los datos en una variable (importando un fichero de datos o entrándolos a mano en Datos), podéis calcular las tablas de frecuencias absolutas y relativas y el diagrama de barras de frecuencias absolutas de una variable cualitativa usando las casillas adecuadas de la sección Exploración/Descriptivas, tal y como se muestra en la imagen siguiente:\n\n\n\n\n\nAntes de continuar, observad que Jamovi incluye en la tabla de frecuencias una columna “% Acumulado” sin que se la pidamos. Solo la tendremos en cuenta si la variable es ordinal.\nUn tipo muy popular de representación gráfica de variables cualitativas son los diagramas circulares, donde se representan los niveles de una variable cualitativa como porciones circulares de un círculo, de manera que el ángulo de cada porción (o equivalentemente, su área) sea proporcional a la frecuencia del nivel al que corresponde. Así, el diagrama circular de la variable dicotómica “Sexo” sería el siguiente:\n\n\n\n\n\nPese a su popularidad, es poco recomendable usar diagramas circulares cuando se manejan más de dos niveles, porque a veces es difícil, a simple vista, comprender las relaciones entre las frecuencias que representan. Para convencerse, basta comparar los diagramas de barras y los diagramas circulares de la figura siguiente, importada de la entrada sobre diagramas circulares de la Wikipedia:\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nY por este motivo, por favor, nunca uséis diagramas circulares para más de dos niveles.\n\n\nUn gráfico ha de servir más que mil palabras, y tiene que explicar de un vistazo las características más relevantes de los datos que representa. Luego ya se pueden añadir detalles que complementen esta primera comprensión básica. En el caso de un diagrama de barras, su objetivo ha de ser mostrar la relación entre las magnitudes de las frecuencias que representa; si nos interesan sus valores concretos, es mejor dar la tabla. Por ejemplo, en los diagramas de barras de la variable “Sexo” dados más arriba se ve a simple vista que hay aproximadamente el doble de mujeres que de hombres.\nPor ese motivo es un pecado mortal modificar un gráfico para que el primer vistazo sea engañoso. En un diagrama de barras, la adulteración más usual, y ante la que hay que estar atentos, es truncarlo de manera que el eje de coordenadas que indique las frecuencias no arranque en el 0. Mirad, por ejemplo, el diagrama de barras siguiente:\n\n\n\n\n\nEste diagrama sigue indicando que en la muestra hay un 30% de hombres y un 70% de mujeres, pero si le dais un vistazo superficial, sin mirar las marcas del eje vertical, parece que la proporción de mujeres es cinco veces la de los hombres y no un poco más del doble.\nEs muy frecuente encontrar diagramas de barras (u otros tipos de gráficos) truncados en medios de comunicación. Por ejemplo mirad el gráfico siguiente,\n\n\n\n\n\n\n\n3.0.2 Tablas de frecuencias multidimensionales\nCuando medimos más de una variable cualitativa sobre un mismo grupo de individuos, representamos sus frecuencias absolutas o relativas mediante tablas de contingencia multidimensionales.\nEjemplo:\n\nContinuemos con nuestra muestra de 20 pacientes en residencias geriátricas. Además de su sexo, hemos anotado otras dos características: una variable “Demencia” que recoge si en el momento del ingreso en la residencia habían sido diagnosticados con algún tipo de demencia senil, con niveles “No”, “Alzheimer” y “Otros” (para indicar otros diagnósticos de demencia no-Alzheimer), y una variable “Cancer” que indica si en algún momento han sufrido o no cáncer de mama.\nLa tabla de datos es la siguiente:\n\n\n\n\n\nTabla de datos de pacientes de residencias geriátricas\n\n\n\nSexo\nDemencia\nCancer\n\n\n\n\n1\nMujer\nNo\nNo\n\n\n2\nMujer\nAlzheimer\nSí\n\n\n3\nHombre\nAlzheimer\nNo\n\n\n4\nMujer\nOtros\nNo\n\n\n5\nMujer\nAlzheimer\nNo\n\n\n6\nMujer\nOtros\nSí\n\n\n7\nMujer\nNo\nNo\n\n\n8\nMujer\nAlzheimer\nNo\n\n\n9\nHombre\nOtros\nNo\n\n\n10\nMujer\nOtros\nSí\n\n\n11\nHombre\nAlzheimer\nNo\n\n\n12\nHombre\nAlzheimer\nNo\n\n\n13\nMujer\nNo\nNo\n\n\n14\nMujer\nNo\nNo\n\n\n15\nHombre\nAlzheimer\nNo\n\n\n16\nMujer\nNo\nSí\n\n\n17\nMujer\nNo\nNo\n\n\n18\nMujer\nNo\nNo\n\n\n19\nMujer\nAlzheimer\nNo\n\n\n20\nHombre\nNo\nNo\n\n\n\n\n\n\n\n\nLa tabla bidimensional de frecuencias absolutas de las variables “Sexo” y “Demencia”, que nos da la frecuencia absoluta de cada combinación de sexo y tipo de demencia senil, es:\n\n\n\n\n\n\n\nAlzheimer\nOtros\nNo\n\n\n\n\nHombre\n4\n1\n1\n\n\nMujer\n4\n3\n7\n\n\n\n\n\n\n\n\ny la tabla tridimensional de frecuencias absolutas de las tres variables, que nos da la frecuencia absoluta de cada combinación de sexo, tipo de demencia senil y si se ha sufrido o no cáncer de mama, es:\nCon Jamovi, estas tablas se obtienen fácilmente separando una variable por la otra (u otras) y marcando las mismas casillas en Exploración/Descriptivas que en el caso unidimensional:\n\n\n\n\n\n\n\n\n\n\nLas tablas bidimensionales se pueden obtener de manera más adecuada en Frecuencias/Muestras independientes: lo explicaremos dentro de un rato.\nA menudo es conveniente añadir a una tabla de contingencia multidimensional, filas y columnas marginales (en los márgenes) con las frecuencias totales de cada nivel dentro de cada variable. De esta manera, también tenemos las tablas de frecuencias de cada una de las variables. Por ejemplo, si añadimos la fila y la columna marginales a la tabla bidimensional anterior obtenemos:\n\n\n\n\n\n\n\n\n\n\n\n\n \nAlzheimer\nOtros\nNo\nTotal\n\n\n\n\nHombre\n4\n1\n1\n6\n\n\nMujer\n4\n3\n7\n14\n\n\nTotal\n8\n4\n8\n20\n\n\n\n\n\nLas tablas multidimensionales de frecuencias relativas son algo más complicadas porque dichas frecuencias relativas se pueden calcular en el total de la muestra (las llamamos frecuencias relativas globales) o dentro de los niveles de una de las variables (por filas o por columnas, en el caso bidimensional), en función de lo que nos interese medir. Por ejemplo:\n\nSi nos interesa la fracción de pacientes de cada combinación de sexo y tipo de demencia senil en el total de la muestra, usaremos la tabla de frecuencias relativas globales de las variables “Sexo” y “Demencia”:\n\n\n\n\n\n\n\nAlzheimer\nOtros\nNo\n\n\n\n\nHombre\n0.2\n0.05\n0.05\n\n\nMujer\n0.2\n0.15\n0.35\n\n\n\n\n\nObservad que la suma de todas las entradas de la tabla es 1, lo que indica que estas frecuencias indican proporciones del total de la muestra.\nPor ejemplo, la entrada superior izquierda de esta tabla nos dice que los hombres con Alzheimer representan el 20% del total de la muestra. Es decir, si en nuestra muestra \\(A\\) representa el suceso “Tener Alzheimer” y \\(H\\) el suceso “Ser hombre”, esta entrada dice que \\(P(A\\cap H)=0.2\\).\n\nSi nos interesa la fracción de pacientes con cada tipo de demencia senil dentro de cada sexo, usaremos la tabla de frecuencias relativas de la variable “Demencia” dentro de la variable “Sexo”:\n\n\n\n\n\n\n\nAlzheimer\nOtros\nNo\n\n\n\n\nHombre\n0.6667\n0.1667\n0.1667\n\n\nMujer\n0.2857\n0.2143\n0.5000\n\n\n\n\n\nEn esta tabla, la suma de las entradas de cada fila es 1, lo que indica que las frecuencias son proporciones dentro de cada fila.\nPor ejemplo, la entrada superior izquierda de esta tabla nos dice que los hombres con Alzheimer representan el 66.67% de los hombres de la muestra. Es decir, con las notaciones anteriores, que \\(P(A|H)=0.6667\\).\n\nSi nos interesa la fracción de pacientes de cada sexo dentro del grupo de pacientes con cada tipo de demencia senil, usaremos la tabla de frecuencias relativas de la variable “Sexo” dentro de la variable “Demencia”:\n\n\n\n\n\n\n\nAlzheimer\nOtros\nNo\n\n\n\n\nHombre\n0.5\n0.25\n0.125\n\n\nMujer\n0.5\n0.75\n0.875\n\n\n\n\n\nEn esta tabla, la suma de las entradas de cada columna es 1, lo que indica que las frecuencias son proporciones dentro de cada columna.\nPor ejemplo, la entrada superior izquierda de esta tabla nos dice que los hombres con Alzheimer representan el 50% de los enfermos de Alzheimer de la muestra. O sea, de nuevo con las notaciones anteriores, que \\(P(H|A)=0.5\\).\nEn una tabla de contingencia de frecuencias relativas globales, tiene sentido añadir filas y columnas marginales, que nos darán las frecuencias relativas de los niveles de cada variable.\n\n\n\n\n\n\n\n\n\n\n\n\n \nAlzheimer\nOtros\nNo\nTotal\n\n\n\n\nHombre\n0.2\n0.05\n0.05\n0.3\n\n\nMujer\n0.2\n0.15\n0.35\n0.7\n\n\nTotal\n0.4\n0.2\n0.4\n1\n\n\n\n\n\nPero en una tabla de contingencia de frecuencias relativas de una variable respecto de otra no tiene mucho interés. Por ejemplo, añadamos las marginales a la tabla de frecuencias relativas de la variable “Demencia” dentro de la variable “Sexo”:\n\n\n\n\n\n\n\n\n\n\n\n\n \nAlzheimer\nOtros\nNo\nTotal\n\n\n\n\nHombre\n0.6667\n0.1667\n0.1667\n1\n\n\nMujer\n0.2857\n0.2143\n0.5\n1\n\n\nTotal\n0.9524\n0.381\n0.6667\n2\n\n\n\n\n\nComo hemos calculado las frecuencias relativas dentro de cada fila, la suma de las frecuencias relativas de cada fila ha de ser 1. Ahora fijaos en la fila Total. Nos dice por ejemplo que la suma de la proporción de hombres que tienen Alzheimer, 0.6667, y de la proporción de mujeres que tienen Alzheimer, 0.2857, es 0.9523. ¿Qué significado tiene este número? Ninguno, y en todo caso de ninguna manera significa que la proporción de individuos con Alzheimer en la muestra sea 0.9523, ya que esta proporción es del 40%.\n\n\n\n\n\n\nNota\n\n\n\nA la hora de decidir qué variable asignamos a las filas y cuál a las columnas en una tabla de contingencia bidimensional, es conveniente recordar que, en los paises occidentales, solemos leer las tablas por filas y de izquierda a derecha. Por ello, si tenemos interés en la distribución de los niveles de una variable dentro de los niveles de una segunda variable, puede facilitar la lectura de la tabla que esta segunda variable defina las filas.\n\n\nLas tablas de contingencia bidimensionales con frecuencias relativas marginales se obtienen con Jamovi en la sección Frecuencias/Muestras independientes. Por ejemplo, si declaramos la variable “Sexo” como la de las filas y la variable “Demencia” como la de las columnas y marcamos Frecuencias observadas en la pestaña Celdas, entonces podemos pedir en las casillas de la columna Porcentajes que se calculen las frecuencias relativas por filas, por columnas o en el total. Por ejemplo, por filas:\n\n\n\n\n\nOlvidaos por ahora de la tabla “Pruebas de \\(\\chi^2\\)” que aparece en el resultado, ya hablaremos de ella al hablar de contrastes de proporciones. Podéis impedir que aparezca desmarcando la casilla \\(\\chi^2\\) en la pestaña Estadísticas, que sale marcada por defecto.\n\n\n3.0.3 Diagramas de barras bidimensionales\nUna tabla de frecuencias bidimensional se suele representar mediante un diagrama de barras bidimensional, que puede ser:\n\nDe barras apiladas: Se escoge una variable (la llamaremos principal), se dibuja una barra para cada uno de sus niveles de altura la frecuencia total de dicho nivel, y cada una de estas barras se divide verticalmente en sectores que representan las frecuencias de los niveles de la otra variable dentro de ese nivel.\nPor ejemplo, el diagrama de barras apiladas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Sexo” como principal:\n\n\n\n\n\n\n\n\n\n\n\nDe barras yuxtapuestas. Se escoge una variable principal y para cada uno de sus niveles se dibuja un diagrama de barras de las frecuencias de los niveles de la otra variable.\nAsí, el diagrama de barras yuxtapuestas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Sexo” como principal es:\n\n\n\n\n\n\n\n\n\n\nOtros dos ejemplos:\n\nEl diagrama de barras apiladas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Demencia” como principal es:\n\n\n\n\n\n\n\n\n\n\n\nEl diagrama de barras yuxtapuestas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Demencia” como principal:\n\n\n\n\n\n\n\n\n\n\nLos diagramas de barras tienen que mostrar la información de la manera más adecuada posible. Por ejemplo, si lo que nos interesa es la distribución de los tipos de demencia por sexo, la variable principal ha de ser el “Sexo”. Si nos interesan las frecuencias relativas globales, seguramente sea más conveniente dar un diagrama de barras tomando como niveles las combinaciones de niveles de ambas variables, como el siguiente diagrama de barras de frecuencias relativas globales de las variables “Sexo” y “Demencia”:\n\n\n\n\n\n\n\n\n\nEl usar barras apiladas o yuxtapuestas en un diagrama de barras bidimensional ya va más a gusto de cada uno. Como un diagrama de barras yuxtapuestas usa tantas barras como el producto de los números de niveles de las dos variables, si estos dos números son grandes puede necesitar mucho espacio horizontal para ser comprensible. Por otro lado, en los diagramas de barras apiladas es más fácil comparar las frecuencias de los niveles de la variable principal, mientras que en los diagramas de barras yuxtapuestas es más fácil comparar la distribución de los niveles de la variable secundaria dentro de cada nivel de la variable principal.\nLo diagramas de barras bidimensionales se obtienen con las casillas adecuadas de la pestaña Gráficos en Frecuencias/Muestras independientes. Podéis elegir si queréis las barras apiladas (Alineados) o yuxtapuestas (Al lado), si el diagrama de barras ha de ser de frecuencias abolutas o relativas y en este último caso qué tipo de frecuencias relativas (del total, por filas o por columnas) y si la variable principal es la de las filas o las columnas. Por ejemplo, el diagrama de barras yuxtapuestas de frecuencias absolutas de las variables “Sexo” y “Demencia”, tomando la variable “Demencia” como principal, se obtiene de la manera siguiente:\n\n\n\n\n\n\n\n3.0.4 Ejercicio\nEn un estudio transversal en el que se analizó 75 hombres y 70 mujeres, 40 hombres y 20 mujeres presentaron una determinada enfermedad.\n\nRepresentad estos datos en un diagrama de barras bidimensional de frecuencias relativas que muestre las proporciones de enfermos y sanos en cada sexo.\n¿Qué vale la frecuencia relativa de los hombres entre los participantes que no presentaron la enfermedad?\n\n\n\n3.0.5 Diagramas de mosaico\nUna tabla tridimensional se puede representar mediante un diagrama de mosaico. Estos gráficos se obtienen sustituyendo cada entrada de la tabla de frecuencias por una región rectangular de área proporcional a su valor. Por ejemplo, los “Sí” y “No” de la fila superior corresponden a la variable “Cancer”:\n\n\n\n\n\n\n\n\n\n\n\n3.0.6 Descripción de datos ordinales\nLos datos ordinales son parecidos a los cualitativos, en el sentido de que son cualidades de objetos o individuos. Su diferencia con los datos cualitativos está en que las características que expresan los datos ordinales tienen un orden natural que permite acumular observaciones, es decir, contar cuántas hay por debajo de cada nivel. Un caso frecuente son las escalas tipo Likert, que se usan para expresar el nivel de acuerdo o desacuerdo con una afirmación mediante respuestas cerradas.\nEjemplo:\n\nEn una encuesta sobre la actitud de personal sanitario frente al dolor (M. E. Zanolin et al, “A questionnaire to evaluate the knowledge and attitudes of health care providers on pain”, Journal of pain and symptom management 33 (2007), pp. 727-736), se pidió el grado de conformidad con afirmaciones como:\n\nComo los narcóticos pueden causar depresión respiratoria, no se han de usar en pacientes pediátricos.\nEs útil dar de entrada un placebo al paciente que se queja de dolor para saber si realmente siente dolor.\n\nsegún la escala Likert siguiente:\n\n\n\n\n\n\nNivel\nSignificado\n\n\n\n\n1\nMuy en desacuerdo\n\n\n2\nEn desacuerdo\n\n\n3\nNeutral\n\n\n4\nDe acuerdo\n\n\n5\nMuy de acuerdo\n\n\n\n\n\nLas respuestas a este tipo de cuestionarios son números, pero no son datos cuantitativos, sino ordinales: meras abreviaturas de los diferentes grados de conformidad.\nPara más información sobre escalas Likert, podéis consultar la correspondiente entrada de la Wikipedia.\nCuando trabajamos con datos ordinales, el orden de los niveles de los datos permite calcular no sólo las frecuencias absolutas y relativas que veíamos en la lección anterior, y que para variables ordinales se definen del mismo modo, sino también frecuencias acumuladas. Es decir, no sólo podemos contar cuántas veces hemos observado un cierto nivel, sino también cuántas veces hemos observado un nivel menor o igual que él. Por lo tanto, su descripción estadística es la misma que para datos cualitativos, más:\n\nFrecuencias absolutas acumuladas: El número de veces que aparece en la muestra un nivel menor o igual que el considerado.\nFrecuencias relativas acumuladas: La fracción del total de la muestra que representan los niveles menores o iguales que el considerado.\n\nDe nuevo, estas frecuencias acumuladas se pueden recoger en una tabla y representar en forma de diagrama de barras (con los niveles ordenados en orden creciente).\nEjemplo:\n\nTenemos una muestra de 20 estudiantes de quienes sabemos la calificación que han sacado en un examen. Clasificamos estas calificaciones en Suspenso (S), Aprobado (A), Notable (N) y Sobresaliente (E) y consideramos su orden natural S &lt; A &lt; N &lt; E. Las calificaciones que han obtenido son las siguientes:\n\n\nN, A, A, S, S, A, N, E, A, A, S, S, S, A, E, N, N, E, S, A\n\nEn esta lista hay 6 S, 7 A, 4 N y 3 E: éstas serían las frecuencias absolutas de las calificaciones en esta muestra de estudiantes. Por lo que se refiere a sus frecuencias absolutas acumuladas:\n\nHay 6 estudiantes que han obtenido S o menos: la frecuencia acumulada de S es 6.\nHay 13 estudiantes que han obtenido A o menos (6 S y 7 A): la frecuencia acumulada de A es 13.\nHay 17 estudiantes que han obtenido N o menos (6 S, 7 A y 4 N): la frecuencia acumulada de N es 17.\nHay 20 estudiantes que han obtenido E o menos (todos): la frecuencia acumulada de E es 20.\n\nLa frecuencia relativa acumulada de cada calificación es la fracción del total de estudiantes que representa su frecuencia absoluta acumulada. Por ejemplo, la frecuencia relativa acumulada de notables es la proporción de estudiantes que han sacado un notable o menos, y, por lo tanto, es igual a la frecuencia absoluta acumulada de N dividida por el número total de estudiantes: 17/20=0.85. También se puede obtener “acumulando” las frecuencias relativas de las calificaciones menores o iguales que N: como hay un 30% de S (6 de 20), un 35% de A (7 de 20) y un 20% de N (4 de 20), la frecuencia relativa acumulada de N es 0.3+0.35+0.2=0.85, es decir, un 85%.\nAsí pues, las frecuencias relativas acumuladas de las calificaciones en esta muestra son:\n\nFrecuencia relativa acumulada de S: 6/20=0.3.\nFrecuencia relativa acumulada de A: 13/20=0.65.\nFrecuencia relativa acumulada de N: 17/20=0.85.\nFrecuencia relativa acumulada de E: 20/20=1.\n\nResumimos todos estos valores en la tabla siguiente:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrecuencia absoluta\nFrecuencia relativa\nPorcentaje\nFrecuencia absoluta acumulada\nFrecuencia relativa acumulada\nPorcentaje acumulado\n\n\n\n\nSuspenso\n6\n0.30\n30%\n6\n0.30\n30%\n\n\nAprobado\n7\n0.35\n35%\n13\n0.65\n65%\n\n\nNotable\n4\n0.20\n20%\n17\n0.85\n85%\n\n\nSobresaliente\n3\n0.15\n15%\n20\n1.00\n100%\n\n\n\n\n\nEjemplo:\n\nTodos los ancianos recogidos en la tabla de datos del Ejemplo presentado con anterioridad fueron diagnosticados con COVID-19 entre marzo y mayo de 2020. Vamos a ampliar dicha tabla de datos con información sobre la gravedad de su enfermedad, clasificada en cuatro niveles: Asintomática, Leve, Hospitalización (si requirió hospitalización pero no en UCI) y UCI. Consideraremos esta variable como ordinal, con sus niveles ordenados en orden creciente de gravedad.\n\nLa tabla de datos ampliada es la siguiente:\n\n\n\n\nTabla de datos de pacientes de residencias geriátricas\n\n\n\nSexo\nDemencia Senil\nCáncer de mama\nCOVID-19\n\n\n\n\n1\nMujer\nNo\nNo\nLeve\n\n\n2\nMujer\nAlzheimer\nSí\nUCI\n\n\n3\nHombre\nAlzheimer\nNo\nLeve\n\n\n4\nMujer\nOtros\nNo\nAsintomática\n\n\n5\nMujer\nAlzheimer\nNo\nLeve\n\n\n6\nMujer\nOtros\nSí\nHospitalización\n\n\n7\nMujer\nNo\nNo\nUCI\n\n\n8\nMujer\nAlzheimer\nNo\nLeve\n\n\n9\nHombre\nOtros\nNo\nLeve\n\n\n10\nMujer\nOtros\nSí\nLeve\n\n\n11\nHombre\nAlzheimer\nNo\nLeve\n\n\n12\nHombre\nAlzheimer\nNo\nHospitalización\n\n\n13\nMujer\nNo\nNo\nLeve\n\n\n14\nMujer\nNo\nNo\nAsintomática\n\n\n15\nHombre\nAlzheimer\nNo\nLeve\n\n\n16\nMujer\nNo\nSí\nAsintomática\n\n\n17\nMujer\nNo\nNo\nLeve\n\n\n18\nMujer\nNo\nNo\nHospitalización\n\n\n19\nMujer\nAlzheimer\nNo\nHospitalización\n\n\n20\nHombre\nNo\nNo\nLeve\n\n\n\n\n\n\n\n\nEntonces:\n\nLa tabla de frecuencias absolutas de la variable COVID-19 es:\n\n\n\n\n\n\n\nCOVID-19\nFrecs.\n\n\n\n\nAsintomática\n3\n\n\nLeve\n11\n\n\nHospitalización\n4\n\n\nUCI\n2\n\n\n\n\n\n\n\n\n\nSu tabla de frecuencias relativas:\n\n\n\n\n\n\n\nCOVID-19\nFrecs.\n\n\n\n\nAsintomática\n0.15\n\n\nLeve\n0.55\n\n\nHospitalización\n0.20\n\n\nUCI\n0.10\n\n\n\n\n\n\n\n\n\nSu tabla de frecuencias absolutas acumuladas:\n\n\n\n\n\n\n\nCOVID-19\nFrecs. Acum\n\n\n\n\nAsintomática\n3\n\n\nLeve\n14\n\n\nHospitalización\n18\n\n\nUCI\n20\n\n\n\n\n\n\n\n\n\nSu tabla de frecuencias relativas acumuladas:\n\n\n\n\n\n\n\nCOVID-19\nFrecs. Acum\n\n\n\n\nAsintomática\n0.15\n\n\nLeve\n0.70\n\n\nHospitalización\n0.90\n\n\nUCI\n1.00\n\n\n\n\n\n\n\n\n\nSu diagrama de barras de frecuencias absolutas acumuladas:\n\n\n\n\n\n\n\n\n\n\n\nSu diagrama de barras de frecuencias relativas acumuladas:\n\n\n\n\n\n\n\n\n\n\n\nLa tabla bidimensional de frecuencias absolutas de las variables Demencia Senil y COVID-19:\n\n\n\n\n\n\n\nAsintomática\nLeve\nHospitalización\nUCI\n\n\n\n\nAlzheimer\n0\n5\n2\n1\n\n\nOtros\n1\n2\n1\n0\n\n\nNo\n2\n4\n1\n1\n\n\n\n\n\n\nSu tabla de frecuencias relativas acumuladas dentro de cada nivel de demencia senil:\n\n\n\n\n\n\n\nAsintomática\nLeve\nHospitalización\nUCI\n\n\n\n\nAlzheimer\n0.00\n0.625\n0.875\n1\n\n\nOtros\n0.25\n0.750\n1.000\n1\n\n\nNo\n0.25\n0.750\n0.875\n1\n\n\n\n\n\n\nEl diagrama de barras yuxtapuestas de esta última tabla:\n\n\n\n\n\n\n\n\n\n\nComo vimos antes, Jamovi da las frecuencias acumuladas (si hemos especificado correctamente el orden de los niveles) al calcular tablas de contigencia en Exploración/Descriptivas. En las tablas multidimensionales la acumulación se lleva a cabo en el total, lo que no siempre es conveniente. Para calcular bien tablas bidimensionales acumulando frecuencias por filas o columnas hay que usar R en la ventana de edición R. Por ejemplo, para obtener la tabla de frecuencias relativas acumuladas que hemos dado hace un momento de niveles de gravedad de la COVID dentro de cada nivel de demencia senil podemos usar:\n\n\n\n\n\nFijaos en la lógica de la sintaxis de esta instrucción. De dentro a fuera:\n\ntable(data$Demencia, data$COVID) calcula la tabla de frecuencias absolutas de las variables Demencia y COVID, con filas la Demencia.\nprop.table(..., margin=1) calcula la tabla de frecuencias relativas (de proporciones) por filas (margin=1) de la tabla de frecuencias absolutas a la que se aplica en los puntos suspensivos.\napply(..., MARGIN=1, FUN=cumsum) aplica la función cumsum, que calcula las sumas acumuladas, por filas (MARGIN=1) a la tabla entrada en los puntos suspensivos.\n\nEsta última función transpone nuestra tabla (siempre da el resultado de manera que la dimensión en la que se acumulan las frecuencias sea la de las columnas); si quisiérais mantener los tipos de demencia en la filas, se aplicaría t(...) al resultado del apply.\nEjercicio\nCalculad la tabla bidimensional de frecuencias relativas acumuladas de los niveles de gravedad de la COVID-19 en cada sexo, y representad esta tabla por medio de un diagrama de barras yuxtapuestas adecuado.\n\n\n3.0.7 Descripción de datos cuantitativos\nLos datos cuantitativos son los que expresan cantidades que se representan mediante números, tales como los resultados de contar objetos o individuos o de medir pesos, distancias, tiempos o concentraciones.\nComo los números reales están ordenados de manera natural, para estudiar una muestra de datos cuantitativos (una variable cuantitativa) podemos usar las frecuencias y las frecuencias acumuladas de sus diferentes valores, como en las variables ordinales. Esto realmente solo es útil cuando en la muestra tenemos pocos valores diferentes.\nComo los datos cuantitativos son números reales y tienen el significado de números reales, podemos operar con ellos. Esto nos aporta una multitud de estadísticos, expresiones matemáticas que, aplicadas a un vector de datos cuantitativos, producen valores que expresan diferentes características del mismo.\nSupongamos de ahora en adelante que tenemos una muestra formada por \\(n\\) números, que denotaremos \\(x_1,\\ldots,x_n\\).\nEn primer lugar tenemos los estadísticos de tendencia central, que dan un valor representativo del conjunto de datos de la variable; los más importantes son:\n\nLa moda, que es el valor, o los valores, de máxima frecuencia (absoluta o relativa, tanto da). Normalmente, solo se usa para variables discretas.\nLa media aritmética: \\[\n\\overline{x}=\\frac{x_1+\\cdots+x_n}{n}\n\\]\nEn este curso, cuando hablemos de la media de unos datos nos referiremos siempre a su media aritmética. Hay otros tipos de media, como por ejemplo la media geométrica o la armónica, que no estudiaremos.\nLa mediana \\(Q_{0.5}\\), que representa el valor central en la lista ordenada de observaciones. Se define de la manera siguiente. Si denotamos por \\[\nx_{(1)}\\leqslant x_{(2)}\\leqslant \\cdots \\leqslant x_{(n)}\n\\] los datos de la variable cuantitativa ordenados de menor a mayor:\n\nSi \\(n\\) es impar, su mediana es el dato central: \\(x_{(n+1)/2}\\).\nPor ejemplo, si una muestra está formada por 7 números, su mediana es el cuarto tras ordenarlos de menor a mayor.\nSi \\(n\\) es par, su mediana es la media de los dos datos centrales: \\[\n\\frac{x_{(n/2)}+x_{(n/2+1)}}{2}.\n\\]\nPor ejemplo, si una muestra está formada por 8 números, su mediana es la media del cuarto y el quinto tras ordenarlos de menor a mayor.\n\n\nTomemos la variable “Hijos” de la Tabla @ref(tab:tablager4), formada por los números\n\n4, 1, 8, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 3\n\n\nEn su tabla de frecuencias vemos que la moda son los valores 0 y 1, que empatan en la frecuencia máxima.\nSu media es \\[\n\\frac{4+1+8+0+3+\\cdots+0+3+6+3}{20}=2.55\n\\]\nPara calcular su mediana, lo primero que hacemos es ordenar de menor a mayor las observaciones, y marcamos su posición dentro del conjunto ordenado:\n\nComo tenemos 20 datos, la mediana será la media aritmética de sus dos valores centrales, los de las posiciones 10 y 11: \\(Q_{0.5}=(2+2)/2=2\\).\n¿Qué les pasa a estos estadísticos si eliminamos el paciente con 8 hijos de la muestra? Los datos son ahora\n\n4, 1, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 3\n\n\nLa moda siguen siendo los valores 0 y 1, ya que no hemos modificado sus frecuencias y hemos eliminado observaciones\nSu media ahora es \\[\n\\frac{4+1+0+3+\\cdots+0+3+6+3}{19}=2.263\n\\]\nComo ahora tenemos 19 observaciones, su mediana será la observación central, es decir, la décima tras ordenarlas de menor a mayor:\n\nPor lo tanto, \\(Q_{0.5}=2\\).\n¿Y qué les pasaría a estos estadísticos si, en la muestra original, hubiéramos cometido un error y al último paciente le hubiéramos anotado 300 hijos en lugar de 3? Los datos así serían:\n\n4, 1, 8, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 300\n\n\nLa moda no cambia\nLa media ahora sería \\[\n\\frac{4+1+8+0+3+\\cdots+0+3+6+300}{20}=17.4\n\\]\nComo volvemos a tener 20 números, la mediana sería otra vez la media de las observaciones décima y undécima tras ordenarlas de menor a mayor:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosición\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nValor\n0\n0\n0\n0\n1\n1\n1\n1\n2\n2\n2\n3\n3\n4\n4\n4\n6\n6\n8\n300\n\n\n\n\n\n\n\n\n\nDe nuevo, \\(Q_{0.5}=(2+2)/2=2\\).\n\n\n\n\n\n\nNota\n\n\n\nEs importante observar que:\n\nLa moda es el valor más repetido, pero puede ser poco representativa y puede carecer completamente de interés si, por ejemplo, todos los valores de la muestra tienen frecuencias muy parecidas.\nLa media es poco robusta, en el sentido de que los valores extremos pueden afectarla mucho\nLa mediana es muy robusta, en el sentido de que los valores extremos la afectan poco\n\n\n\nPor este motivo, por ejemplo, a la hora de resumir los salarios españoles, se publican los tres valores:\n\n  \n  Gráfico publicado por el INE  (https://www.ine.es/prensa/eces_2018_a.pdf).\n  \nEs interesante copiar un trozo de la nota de prensa de la que hemos extraído el gráfico, donde se comenta la relación entre la moda, la media y la mediana:\n\n“El salario bruto medio anual en España fue de 24.009,12 euros por trabajador en el año 2018, un 1,5% mayor al año anterior. La diferencia entre este salario medio y el salario más frecuente o modal (de 18.468,93 euros) fue de más de 5.500 euros. Esto significa que había pocos trabajadores con salarios muy altos pero que influyeron notablemente en el salario medio.\n\n\n“Por otra parte, el salario mediano (que divide al número de trabajadores en dos partes iguales, los que tienen un salario superior y los que tienen un salario inferior) presentó un valor de 20.078,44 euros en 2018.”\n\nMedidas de posición\nLas medidas de posición dividen la variable en unas determinadas proporciones; estos valores reciben el nombre de cuantiles. En este sentido, la mediana es también una medida de posición, puesto que divide la variable en dos mitades.\nDada una proporción \\(0&lt;p&lt;1\\), el cuantil de orden \\(p\\), o \\(p\\)-cuantil, de una variable cuantitativa, que denotaremos por \\(Q_p\\), es el valor más pequeño del conjunto de datos cuya frecuencia relativa acumulada es mayor o igual que \\(p\\); o sea, el valor más pequeño de la muestra que es mayor o igual que el \\(100p\\%\\) de los valores de la muestra. Dicho de una tercera manera, si tenemos un conjunto de números \\(x_1, \\ldots, x_n\\) y los ordenamos de menor a mayor, \\[\nx_{(1)}\\leqslant x_{(2)}\\leqslant \\cdots \\leqslant x_{(n)},\n\\] entonces \\(Q_p\\) es el primer valor \\(x_{(i)}\\) de esta lista ordenada que deja a su izquierda (incluyéndolo a él) como mínimo la fracción \\(p\\) de los datos, es decir, \\(p\\cdot n\\) datos.\nLa excepción a esta regla es el cuantil \\(Q_{0.5}\\), que es la mediana y se calcula como hemos explicado antes.\nEjemplo:\n\nConsidera la variable “Hijos” que registra el número de hijos vivos en el momento de ingreso de unos pacientes en sus residencias geriátricas. Sus 20 valores, ordenados de menor a mayor son:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosicion\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nValor\n0\n0\n0\n0\n1\n1\n1\n1\n2\n2\n2\n3\n3\n3\n4\n4\n4\n6\n6\n8\n\n\n\n\n\nEntonces:\n\nEl 0.2-cuantil, \\(Q_{0.2}\\), es el primer elemento en esta lista ordenada que es mayor o igual que el 20% de los datos. Como el 20% de 20 es 4, \\(Q_{0.2}\\) es el cuarto elemento de la lista ordenada: 0.\nEl 0.75-cuantil, \\(Q_{0.75}\\), es el primer elemento en esta lista ordenada que es mayor o igual que el 75% de los datos. Como el 75% de 20 es 15, \\(Q_{0.75}\\) es el decimoquinto elemento de la lista ordenada: 4.\nEl cuantil de orden 1/3, \\(Q_{1/3}\\), es el primer elemento en esta lista ordenada que es mayor o igual que un tercio de los datos. Como un tercio de 20 es 6.66 y pico, \\(Q_{1/3}\\) es el séptimo elemento de la lista ordenada: 1. Fijaos en que 6/20=0.3, y por lo tanto el sexto elemento de la lista solo es mayor o igual que el 30% de la muestra, no un tercio. Necesitamos el séptimo elemento para llegar al tercio, aunque entonces nos pasemos.\n\nLos cuantiles se calculan a partir de los valores ordenados de la muestra, teniendo en cuenta los valores repetidos. Es decir, si se han observado un 1, un 2, un 3, un 4 y cinco 5, la mediana no es el valor central de 1, 2, 3, 4, 5, sino el de 1, 2, 3, 4, 5, 5, 5, 5, 5, que es 5.\n\n\n\n\n\n\nNota\n\n\n\nEn realidad, la definición que hemos dado de cuantil es “orientativa”: no hay una regla única para calcular cuantiles de una muestra (salvo la mediana), y se han propuesto varios métodos que pueden dar resultados diferentes; podéis consultar nueve de estos métodos en la entrada sobre cuantiles de la Wikipedia en inglés. La razón de esta diversidad es que a veces el objetivo final del cálculo de un cuantil no es solo descriptivo (dar el menor valor mayor o igual que una fracción \\(p\\) de la muestra) sino que es inferencial (estimar el menor valor que es mayor o igual que una fracción \\(p\\) del total de la población) y esta inferencia se puede hacer de muchas maneras, según las propiedades que tenga (o que supongamos que tenga) la población.\n¿Qué os recomendamos? No os compliquéis la vida:\n\nSi calculáis cuantiles a mano, usad la definición que hemos dado, que es la más sencilla de todas\nSi los calculáis con algún paquete estadístico, usad su método por defecto (que seguramente no sea el que hemos explicado)\n\n\n\nAlgunos cuantiles con nombre propio:\n\nLa mediana es el cuantil \\(Q_{0.5}\\).\nLos cuartiles son los cuantiles \\(Q_{0.25}\\), \\(Q_{0.5}\\) y \\(Q_{0.75}\\), y reciben, respectivamente, los nombres de primer cuartil, segundo cuartil (o mediana) y tercer cuartil. \\(Q_{0.25}\\) será, pues, el menor valor que es mayor o igual que una cuarta parte de los datos, y \\(Q_{0.75}\\), el menor valor que es mayor o igual que tres cuartas partes de los datos.\nLos deciles son los cuantiles \\(Q_{p}\\) con \\(p\\) un múltiplo entero de 0.1: el primer decil es \\(Q_{0.1}\\), el segundo decil es \\(Q_{0.2}\\), y así sucesivamente.\nLos percentiles son los cuantiles \\(Q_{p}\\) con \\(p\\) un múltiplo entero de 0.01: \\(Q_{0.01}\\) es el primer percentil, \\(Q_{0.02}\\) es el segundo percentil, etc.\n\nSe llama intervalo intercuartílico, \\(\\mathit{IQI}\\), al intervalo cerrado \\([Q_{0.25},Q_{0.75}]\\). Fijaos que como un 75% de los datos de la muestra son menores o iguales que \\(Q_{0.75}\\) y, de estos, un 25% son menores o iguales que \\(Q_{0.25}\\), dentro del \\(\\mathit{IQI}\\) caerán más o menos el 50% de los datos de la muestra, a no ser que haya muchas repeticiones en los extremos del intervalo.\nEjemplo:\n\nSeguimos con la variable “Hijos”. Su primer cuartil será su quinto dato tras ordenarlos de menor a mayor; como hay cuatro ceros y cuatro unos, será 1. Su tercer cuartil ya lo hemos calculado antes, es 4. Por lo tanto su intervalo intercuartílico es [1,4]. Este intervalo contiene 14 elementos de la muestra, bastante más de la mitad, porque la muestra contiene muchas repeticiones del 1 y el 4.\n\nLas medidas de posición también se pueden, y se suelen, usar en la descripción de datos ordinales. En este caso, la mediana se define como el primer valor de la muestra mayor o igual que (al menos) la mitad de la muestra. El resto de cuantiles se definen como los hemos definido aquí.\nEjercicio Aquí tenéis una muestra de 14 niveles de glucosa medidos en niños en ayunas:\n\n56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72\n\nCalculad su:\n\nModa\nMedia\nMediana\nPrimer y tercer cuartiles\nPorcentaje de elementos de la muestra que caen dentro del intervalo intercuartílico\n\nMedidas de dispersión\nLas medidas de dispersión evalúan lo desperdigados que están los datos. Las más importantes son (seguimos suponiendo que nuestra muestra está formada por los números \\(x_1,\\ldots,x_n\\)):\n\nEl recorrido, o rango (del inglés range): la diferencia entre el máximo y el mínimo de las observaciones.\nEl recorrido, o rango, intercuartílico: la diferencia \\(\\mathit{IQR}=Q_{0.75}-Q_{0.25}\\). Id con cuidado, porque también se llama a veces rango intercuartílico a lo que nosotros llamamos intervalo intercuartílico, \\([Q_{0.25},Q_{0.75}]\\).\nLa varianza: la media aritmética de las diferencias al cuadrado entre los datos \\(x_i\\) y su media \\(\\overline{x}\\): \\[\ns_x^2=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}\n\\]\nLa desviación típica (o estándard): la raíz cuadrada positiva de la varianza: \\(s_x=+\\sqrt{s_x^2}\\).\nLa varianza muestral: se define como la varianza, pero usando \\(n-1\\) en lugar de \\(n\\) en el denominador: \\[\n\\tilde{s}_x^2 =\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n-1}\n\\]\nLa desviación típica muestral: la raíz cuadrada positiva de la varianza muestral: \\(\\tilde{s}_x=+\\sqrt{\\tilde{s}_x^2}\\).\nEl coeficiente de variación: la proporción de la media que representa la desviación típica (se usa solo para conjuntos de datos positivos): \\(CV_x=s_x/\\overline{x}\\)\nLa desviación media respecto de la mediana: la media aritmética de los valores absolutos de las diferencias entre los datos \\(x_i\\) y su mediana \\(Q_{0.5}\\): \\[\nMDM(x)=\\frac{\\sum_{i=1}^n |x_i-Q_{0.5}|}{n}\n\\]\n\n\nEjemplo: Calculemos todos estos valores para nuestra variable “Hijos”\n\n4, 1, 8, 0, 3, 4, 2, 1, 1, 2, 6, 0, 0, 1, 4, 2, 0, 3, 6, 3\n\n\nSu máximo es 8 y su mínimo 0, por lo tanto su recorrido es 8\nYa hemos calculado en la sección anterior su intervalo intercuartílico, que es [1,4], por lo que su rango intercuartílico es 3.\nComo su media es 2.55, su varianza es \\[\ns^2_x=\\frac{(4-2.55)^2+(1-2.55)^2+(8-2.55)^2+\\cdots+(3-2.55)^2}{20}=4.8475\n\\]\nSu desviación típica es \\[\ns_x=\\sqrt{4.8475}=2.202\n\\]\nSu varianza muestral es \\[\n\\widetilde{s}^2_x=\\frac{(4-2.65)^2+(1-2.65)^2+(8-2.65)^2+\\cdots+(3-2.65)^2}{19}=5.1026\n\\]\nSu desviación típica muestral es \\[\n\\widetilde{s}_x=\\sqrt{5.1026}=2.259\n\\]\nSu coeficiente de variación es \\[\nCV_x=\\frac{2.202}{2.55}=0.8634\n\\]\nComo su mediana es 2, su desviación media respecto de la mediana es \\[\nMDM_x=\\frac{|4-2|+|1-2|+|8-2|+\\cdots+|3-2|}{20}=1.75\n\\]\n\n\n\n\n\n\n\n\nNota\n\n\n\nLa diferencia entre la varianza y la varianza muestral, aparte de la tilde \\(\\widetilde{\\ }\\) en el símbolo de la muestral, es el denominador, que es \\(n\\) para la primera y \\(n-1\\) para la segunda. Por lo tanto, se puede pasar de una a otra simplemente cambiando el denominador: \\[\n\\widetilde{s}^2_x=\\frac{n}{n-1}\\cdot s^2_x.\n\\] Y tomando raíces cuadradas: \\[\n\\widetilde{s}_x=\\sqrt{\\frac{n}{n-1}}\\cdot s_x.\n\\]\n\n\nEl motivo de distinguir entre la varianza y la varianza muestral es su aplicación en la estimación de la varianza de la variable poblacional:\n\nPor un lado, es natural medir la variabilidad de un conjunto de datos cuantitativos mediante su varianza “a secas”, definida como la media de las distancias (al cuadrado) de los datos a su valor promedio.\nPor lo tanto, si nuestro objetivo final es puramente la descripción de nuestro conjunto de datos, usar la varianza verdadera es lo correcto.\nPero, por otro lado, nuestro conjunto de datos será, normalmente, una muestra de una población, y lo más seguro es que, en realidad, la varianza de nuestra muestra nos interese sobre todo como estimación de la varianza de toda la población, es decir, de la varianza poblacional.\nPues bien, como veremos más adelante, resulta que la varianza verdadera de una muestra da valores en promedio más pequeños que la varianza real de la población, mientras que la varianza muestral da valores alrededor de la varianza poblacional. Por lo tanto, si nuestro objetivo es estimar la varianza de la población, lo correcto es usar la varianza muestral.\nDe todas formas, para muestras grandes, la diferencia no es importante: si \\(n\\) es grande, dividir por \\(n\\) o por \\(n-1\\) no significa una gran diferencia, y sobre todo si tenemos en cuenta que se trata de estimar la varianza de la población, no de calcularla exactamente.\n\n\n\n\n\n\n\nNota\n\n\n\n¿Y por qué definimos la varianza y desviación típica, si ambas medidas dan una información equivalente, ya que la segunda es la raíz cuadrada de la primera?\nEl motivo es que si los elementos de una variable cuantitativa tienen unidades (metros, años, individuos por metro cuadrado…), sus varianzas (“a secas” y muestral) tienen estas unidades al cuadrado; por ejemplo, si los \\(x_i\\) son años, los valores de \\(s_x^2\\) y \\(\\tilde{s}_x^2\\) representan años al cuadrado. En cambio, las desviaciones típicas tienen las mismas unidades que los datos, por lo que se pueden comparar con ellos, y de ahí su utilidad.\n\n\n\n\n\n¿Y el coeficiente de variación? ¿Cuándo conviene usarlo?\nSi queremos comparar la dispersión de dos variables con datos de la misma naturaleza, por ejemplo alturas, pero medidos en unidades diferentes, por ejemplo una en metros y la otra en centímetros, no es correcto usar medidas como la varianza o la desviación típica que dependan de las unidades. En este caso es más recomendable usar el coeficiente de variación \\(CV_x\\). Mirad el ejemplo siguiente.\n\n\n\nEjemplo: Considerad las alturas de los niños recogidos en la Tabla de inicio del capítulo, que, medidas en cm, eran\n\n135, 132, 138, 141, 134, 136\n\nSu media es \\[\n\\overline{x}=\\frac{135+ 132+138+141+134+136}{6}=136\\ \\text{cm}\n\\] y desviación típica es \\[\ns_x=\\sqrt{\\frac{(135-136)^2+(132-136)^2+(138-136)^2+(141-136)^2+(134-136)^2}{6}}=2.887\\ \\text{cm}\n\\]\nSi damos estas alturas en metros,\n\n1.35, 1.32, 1.38, 1.41, 1.34, 1.36\n\nsu media es \\[\n\\overline{x}=\\frac{1.35+ 1.32+1.38+1.41+1.34+1.36}{6}=1.36\\ \\text{m}\n\\] y desviación típica es \\[\ns_x=\\sqrt{\\frac{(1.35-1.36)^2+(1.32-1.36)^2+(1.38-1.36)^2+(1.41-1.36)^2+(1.34-1.36)^2}{6}}=0.02887\\ \\text{m}\n\\]\nLa desviación típica de las alturas en centímetros es 100 veces mayor que la de las alturas en metros, pero sería incorrecto decir que las primeras son más dispersas que las segundas, ya que en realidad se trata de los mismos datos. La diferencia se debe simplemente a las unidades en las que las hemos medido.\nEn cambio, en ambos casos el coeficiente de variación es el mismo: \\[\n\\frac{2.887}{136}=\\frac{0.02887\\cdot 100}{1.36\\cdot 100}=\\frac{0.02887}{1.36}=0.0212\n\\]\n\nLa varianza tiene las propiedades matemáticas siguientes:\n\n\\(s_x^2\\geqslant 0\\), porque es una suma de cuadrados de números reales.\nSi \\(s_x^2=0\\), todos los sumandos \\((x_i-\\overline{x})^2\\) son 0 y, por lo tanto, todos los datos son iguales a su media. La implicación al revés también es cierta: si todos los datos son iguales, su media es igual a este mismo valor común, y por lo tanto todos los sumandos \\((x_i-\\overline{x})^2\\) son 0. Así pues, \\(s_x^2=0\\) significa que todos los datos son iguales.\nA partir de la fórmula dada para \\(s_x^2\\) y operando astutamente se obtiene la fórmula siguiente, que os puede ser útil: \\[\ns_x^2= \\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2\n\\] Es decir, la varianza es la media de los cuadrados, menos el cuadrado de la media.\n\nLa mayoría de paquetes estadísticos, Jamovi incluido, llevan funciones para calcular la varianza y la desviación típica (sin más aclaraciones) que, en realidad, calculan sus versiones muestrales. El motivo es que priman su aspecto inferencial sobre el descriptivo.\nEjercicio Seguimos con nuestra muestra de 14 niveles de glucosa medidos en niños en ayunas:\n\n56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72\n\nCalculad su:\n\nRecorrido\nIQR\nVarianza\nDesviación típica\nVarianza muestral\nDesviación típica muestral\nCoeficiente de variación\n\n¿Qué varianza y desviación típica calcula vuestra calculadora?\nDiagramas de puntos y de caja\nEn un diagrama de puntos (stripchart) dibujamos todos los valores de una muestra en una columna. Si hay valores repetidos, los separamos horizontalmente, para poder ver su frecuencia.\n\nEjemplo: Consideremos los 14 niveles de glucosa usados en ejercicios anteriores:\n\n56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72\n\nSu diagrama de puntos es\n\n\n\n\n\n\n\n\n\n\nLos diagramas de puntos solo son útiles cuando tenemos pocos valores en la muestra, de manera que valga la pena verlos todos. Cuando la muestra es grande, pongamos de 20 o más números, se suelen reemplazar por un gráfico que resume algunos estadísticos de la muestra llamado un diagrama de caja (boxplot). La estructura básica de un diagrama de caja es la que muestra la siguiente figura.\n\n\n\n\n\nEn este gráfico:\n\nLa línea gruesa que divide la caja marca la mediana\nLos lados inferior y superior de la caja representan los cuartiles \\(Q_{0.25}\\) y \\(Q_{0.75}\\). Por lo tanto:\n\nla altura de la caja es igual al rango intercuartílico \\(\\mathit{IQR}\\)\nla caja contiene alrededor del 50% de los valores de la muestra\n\nLos valores \\(b_{inf}, b_{sup}\\) son los bigotes (whiskers) del gráfico y se calculan de la manera siguiente:\n\nEl bigote inferior \\(b_{inf}\\) es el menor valor de la muestra que es mayor o igual que \\(Q_{0.25}- 1.5\\cdot \\mathit{IQR}\\)\nEl bigote superior \\(b_{sup}\\) es el mayor valor de la muestra que es menor o igual que \\(Q_{0.75}+1.5\\cdot\\mathit{IQR}\\)\n\nSi hay datos más allá de los bigotes, se llaman valores atípicos o anómalos, outliers en inglés, y se marcan como puntos aislados.\n\n\n\n\n\n\n\nNota\n\n\n\nComo su nombre indica, estos valores atípicos son valores que consideramos “muy raros”. Antes de llevar a cabo un estudio inferencial a partir de una muestra, es conveniente dar un vistazo a sus valores atípicos, si los hay. ¿Son datos legítimos? ¿Son errores? ¿Corresponden a individuos con características especiales que conviene no tener en cuenta en el estudio?\n\n\nEl inventor de los diagramas de caja, John Tukey, tomó el 1.5 en la definición de los bigotes como un compromiso entre 1 (salían demasiados valores atípicos) y 2 (demasiado pocos). Volveremos sobre esto más adelante.\n\nEjemplo:\nVamos a dibujar el diagrama de caja de los 14 niveles de glucosa usados en ejercicios anteriores, y que damos ordenados de menor a mayor:\n\n56, 60, 62, 63, 63, 65, 65, 66, 66, 66, 66, 68, 70, 72\n\n\nTenemos que \\(Q_{0.25}=63\\), \\(Q_{0.5}=65.5\\) y \\(Q_{0.75}=66\\). Esto nos define la caja central.\n\\(b_{inf}\\) será el primer valor de la muestra ordenada que es mayor o igual que \\(63- 1.5\\cdot 3=58.5\\). Es el 60.\n\\(b_{sup}\\) será el último valor de la muestra ordenada que es menor o igual que \\(66+ 1.5\\cdot 3=70.5\\). Es el 70.\nHay dos valores atípicos: el 56, que es menor que \\(b_{inf}\\), y el 72, que es mayor que \\(b_{sup}\\).\n\n\nEl resultado es el siguiente, en el que hemos superpuesto el diagrama de puntos para comprender mejor cómo hemos obtenido el diagrama:\n\n\n\n\n\n\n\n\n\nEjercicio Dibujad el diagrama de puntos de la variable “Hijos” y superponedle su diagrama de caja. El resultado debería ser:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrecaución\n\n\n\nEn los gráficos anteriores hemos superpuesto el diagrama de puntos al diagrama de caja para ayudar a comprender cómo se construye este último, pero en la vida real esto no se hace: se da un gráfico u otro, nunca los dos.\n\n\n\n\n\n\n\n\nNota\n\n\n\nLos bigotes y los valores atípicos son siempre elementos de la muestra. La mediana no siempre (puede obtenerse como la media de dos valores de la muestra y no pertenecer a la muestra), y con nuestra definición los cuartiles pertenecen a la muestra, pero con otras definiciones no tienen por qué.\n\n\nHistogramas\nUn histograma es una representación gráfica de un conjunto de datos cuantitativos continuos, consistente en dividir el intervalo de valores entre el mínimo y el máximo en intervalos contiguos y disjuntos, llamado clases, y dibujar entonces una especie de diagrama de barras de estas clases con las particularidades siguientes:\n\nLas barras se dibujan sin espacios entre ellas (para representar la continuidad de los datos)\nSi se trata de un histograma de frecuencias absolutas (en el que las barras representan las frecuencias absolutas de las clases) y todas las clases tienen la misma amplitud, las alturas de las barras son las frecuencias de las clases\nEn cualquier otro caso (es decir, si se trata de un histograma de frecuencias relativas o si es un histograma de frecuencias absolutas pero no todas las clases tienen la misma longitud), las alturas de las barras han de ser tales que las áreas de las barras sean iguales a las frecuencias de las clases\n\nEn realidad:\n\n\n\n\n\n\nImportante\n\n\n\nEn un histograma lo que representa la frecuencia de la clase es siempre el área de su barra.\n\n\nPero si todas las clases tienen la misma amplitud, las áreas de las barras serán sus alturas por la longitud común de las bases, y por lo tanto proporcionales a las alturas. En este caso, y solo en este caso, podemos interpretar que las alturas representan las frecuencias. Pero en la práctica, y por motivos que se entenderán al hablar de variables aleatorias en el próximo tema, esta representación de las frecuencias por medio de las alturas solo se lleva a cabo para frecuencias absolutas.\n\nEjemplo:\nConsideremos la siguiente muestra de 30 alturas de estudiantes:\n\n1.71,1.62,1.72,1.76,1.78,1.73,1.67,1.64,1.63,1.68,1.68,1.70,1.67,1.56,1.66,\n1.57,1.69,1.68,1.67,1.75,1.61,1.60,1.74,1.70,1.65,1.55,1.82,1.70,1.69,1.81\n\nEl gráfico siguiente muestra el diagrama de barras de sus frecuencias absolutas, tomando como posibles niveles todas las alturas entre su mínimo y su máximo redondeadas a cm. Todas la barras tienen alturas entre 0 y 3, y salvo una mayor presencia de los valores centrales (entre 1.67 y 1.70), no hay mucho más que salte a la vista en este gráfico.\n\n\n\n\n\n\n\n\n\nAhora vamos a agrupar estas alturas en intervalos de 5cm. Como el valor mínimo de la muestra es 1.55 y el máximo es 1.82, vamos a tomar las clases 1.55-1.59, 1.60-1.64, 1.65-1.69,1.70-1.74,1.75-1.79, 1.80-1.84. Dibujando el diagrama de barras de las frecuencias absolutas de estas clases sin dejar espacios entre las barras, obtenemos el histograma siguiente:\n\n\n\n\n\n\n\n\n\nLa distribución de estas alturas es mucho más fácil de entender mediante este gráfico que con el primero.\n\n\n\n\n\n\n\nImportante\n\n\n\nPor sistema, en nuestros histogramas las clases serán siempre cerradas a la izquierda y abiertas a la derecha: es decir, el extremo izquierdo de una barra pertenece a su clase, pero el extremo derecho no. Lo hacemos para que sean consistentes con las distribuciones de variables aleatorias que definiremos en los próximos temas. Pero fuera de estas notas, cada paquete estadístico hace lo que consideraron oportuno sus creadores, y puede que el convenio de sus histogramas sea que el extremo izquierdo de una barra no pertenezca a la clase y el extremo derecho sí. Por ejemplo, así es como los produce Jamovi por defecto.\n\n\nAhora bien, el número de clases ya depende de los intereses del investigador; números de clases diferentes muestran efectos diferentes. Una posible regla general para decidir el número de clases que normalmente da buenos resultados es tomar alrededor de \\(\\sqrt{n}\\) clases (donde \\(n\\) indica el tamaño de la muestra) pero no menos de 5 clases ni más de 15.\n\nEjemplo:\nTenemos una muestra de tensiones arteriales medias de 120 adultos.\n\nSi tomamos 5 clases, con las frecuencias\n\n\n\n\n\n\nClase\nFrecuencia\n\n\n\n\n[80,100)\n6\n\n\n[100,120)\n49\n\n\n[120,140)\n45\n\n\n[140,160)\n18\n\n\n[160,180)\n2\n\n\n\n\n\n\n\n\nobtenemos el histograma\n\n\n\n\n\nSi tomamos 9 clases, con las frecuencias\n\n\n\n\n\n\nClase\nFrecuencia\n\n\n\n\n[80,90)\n3\n\n\n[90,100)\n3\n\n\n[100,110)\n16\n\n\n[110,120)\n33\n\n\n[120,130)\n23\n\n\n[130,140)\n22\n\n\n[140,150)\n13\n\n\n[150,160)\n5\n\n\n[160,170)\n2\n\n\n\n\n\n\n\n\nobtenemos el histograma\n\n\n\n\n\nY si tomamos 15 clases, con las frecuencias\n\n\n\n\n\n\nClase\nFrecuencia\n\n\n\n\n[80,85)\n1\n\n\n[85,90)\n2\n\n\n[90,95)\n1\n\n\n[95,100)\n2\n\n\n[100,105)\n6\n\n\n[105,110)\n10\n\n\n[110,115)\n13\n\n\n[115,120)\n20\n\n\n[120,125)\n9\n\n\n[125,130)\n14\n\n\n[130,135)\n13\n\n\n[135,140)\n9\n\n\n[140,145)\n9\n\n\n[145,150)\n4\n\n\n[150,155)\n3\n\n\n[155,160)\n2\n\n\n[160,165)\n2\n\n\n\n\n\n\n\n\nobtenemos el histograma\n\n\n\n\n\nEn este último histograma, con más resolución, podemos observar dos picos que en los otros no aparecen.\nComo hemos comentado, los histogramas también pueden ser de frecuencias relativas: en este caso, tanto si todas las clases tienen la misma amplitud como si no, las alturas de las cajas han de ser los valores tales que el área de la barra sea la frecuencia relativa de la clase. Estas alturas son las densidades de las clases. Es decir:\n\nLa frecuencia relativa de cada clase es el tamaño de la clase (la base de la barra) por su densidad (la altura de la barra).\n\nDe esta manera, la suma de las áreas de las barras será 1. Como también ya hemos comentado, veremos la justificación de esta convención en el próximo tema, sobre Variables Aleatorias.\nAsí, en el ejemplo anterior para 9 clases, las frecuencias relativas y las densidades serían\n\n\n\n\n\n\nClase\nFrec. absoluta\nFrec. relativa\nDensidad\n\n\n\n\n[80,90)\n3\n0.025\n0.0025\n\n\n[90,100)\n3\n0.025\n0.0025\n\n\n[100,110)\n16\n0.133\n0.0133\n\n\n[110,120)\n33\n0.275\n0.0275\n\n\n[120,130)\n23\n0.192\n0.0192\n\n\n[130,140)\n22\n0.183\n0.0183\n\n\n[140,150)\n13\n0.108\n0.0108\n\n\n[150,160)\n5\n0.042\n0.0042\n\n\n[160,170)\n2\n0.017\n0.0017\n\n\n\n\n\n\n\n\ny el histograma de frecuencias relativas a que dan lugar es\n\n\n\n\n\nAsimetría y curtosis\nTerminamos la descripción de variables cuantitativas con otros dos estadísticos que a veces se usan en la literatura médica, y por tanto conviene que conozcáis, pero que nosotros no usaremos, porque son inútiles: las propiedades que describen se ven mejor con un histograma o un diagrama de barras, y no sirven para estimar la correspondiente propiedad de la variable poblacional (que en todo caso es la interesante).\nDada una muestra de datos numéricos \\(x_1,\\ldots,x_n\\), de media \\(\\overline{x}\\) y desviación típica \\(s_x\\):\n\nEl coeficiente de asimetría (skewness) es \\[\n\\gamma_1=\\frac{1}{s_x^3}\\cdot \\frac{\\sum_{i=1}^n (x_i-\\overline{x})^3}{n}\n\\]\nEl coeficiente de curtosis, o apuntamiento, es \\[\n\\beta_2=\\frac{1}{s_x^4}\\cdot \\frac{\\sum_{i=1}^n (x_i-\\overline{x})^4}{n}-3\n\\]\n\nEmpecemos con el coeficiente de asimetría. Como su nombre indica, cuantifica la asimetría de la variable. Para definir esta característica, lo más práctico es dibujar un histograma o un diagrama de barras de la variable y considerar el eje vertical pasando por la mediana, que divide la muestra en dos partes del mismo tamaño. Llamaremos colas a los trozos del histograma a ambos lados de este eje. Entonces:\n\nLa variable es simétrica si ambas colas son similares, como en los dos gráficos siguientes:\n\n \nEsta última diremos que **tiene forma de U**, por motivos obvios.\n\nLa variable tiene asimetría negativa o a la izquierda cuando la cola de la izquierda es más larga que la de la derecha, en el sentido de que hay más valores más alejados de la mediana por la izquierda que por la derecha. En este caso se suele decir que la variable presenta una cola a la izquierda (aunque con la definición que hemos dado la variable siempre tiene una cola a cada lado).\n\n\n\n\n\n\n\nLa variable tiene asimetría positiva o a la derecha cuando la cola de la derecha es más larga que la de la izquierda, en el sentido de que hay más valores más alejados de la mediana por la derecha que por la izquierda. En este caso también diremos que la variable presenta una cola a la derecha.\n\n\n\n\n\n\nHabréis observado que en los histogramas anteriores hemos dibujado las líneas verticales sobre la media y la mediana.\n\nEn una variable simétrica, la simetría hace que la media y la mediana sean aproximadamente iguales\nEn una variable asimétrica a la izquierda, la existencia de valores relativamente muy pequeños en el extremo de la cola de la izquierda suele desplazar la media hacia la izquierda de la mediana, de manera que la media suele ser más pequeña que la mediana.\nY al revés, en una variable asimétrica a la derecha, la existencia de valores relativamente muy grandes en el extremo de la cola de la derecha suele desplazar la media hacia la derecha de la mediana, de manera que la media suele ser más grande que la mediana.\n\n\n\n\n\n\n\nPrecaución\n\n\n\nEn los puntos anteriores hemos descrito lo que “suele pasar” con la media y la mediana en variables asimétricas, pero no siempre pasa. Así, si la media de un vector de datos es bastante más grande que la mediana, suele ser señal de que la muestra es asimétrica a la derecha, pero solo lo “suele ser”: con un poco de imaginación se puede construir un vector asimétrico a la izquierda con la media a la derecha de la mediana. Pensadlo un poco.\n\n\nPues bien, el coeficiente de asimetría \\(\\gamma_1\\) indica el tipo de asimetría de la variable:\n\nCuando \\(\\gamma_1\\approx 0\\), la distribución de los datos es simétrica\nCuando \\(\\gamma_1&lt; 0\\), la variable es asimétrica negativa, con cola a la izquierda\nCuando \\(\\gamma_1&gt; 0\\), la variable es asimétrica positiva, con cola a la derecha\n\nLa mejor manera de decidir la asimetría de una variable es por medio de un histograma, aunque a menudo también se puede ver en un diagrama de caja, como muestran los gráficos siguientes:\n\nUn histograma y diagrama de caja de una variable simétrica:\nUn histograma y diagrama de caja de una variable asimétrica a la izquierda: \nUn histograma y diagrama de caja de una variable asimétrica a la derecha: \n\n::: {.callout-important} Usar la media y la desviación típica (o la varianza) para describir el “valor central” de una variable y cuantificar su dispersión, respectivamente, es lo adecuado solo cuando la variable es bastante simétrica: más aún, solo cuando es bastante simétrica y su histograma recuerda la forma de una campana de Gauss; es decir, por ejemplo, no cuando tiene forma de U. Cuando el histograma es simétrico y con una forma parecida a una campana de Gauss (lo que llamaremos se ajusta a una variable normal en las próximas lecciones), el intervalo \\(\\overline{x}\\pm s_x\\) suele contener aproximadamente unos 2/3 de los datos de la muestra.\nPero para variables muy asimétricas o simétricas en forma de U es mejor usar la mediana y el intervalo intercuartílico. Recordad que este último contiene más o menos el 50% de la muestra.\n\n\n\n\n\nUna campana de Gauss\n\n\n\n\n\nEjemplo: Considerad la variable (asimétrica a la derecha) que tiene el histograma siguiente:\n\n\n\n\n\n\nResulta que su media es \\(\\overline{x}=3.1\\) y su desviación típica es \\(s_x=2.5\\), y que el intervalo \\([\\overline{x}-s_x,\\overline{x}+s_x]\\) contiene un 84% de la muestra. Su mediana es \\(Q_{0.5}=2.3\\), a la izquierda de la media, y su intervalo intercuartílico \\(IQI\\) es [1.3,4.2]. Por cierto, su coeficiente de asimetría es \\(\\gamma_1=1.7\\), lo que es consistente con su cola a la derecha.\nConsiderad ahora la variable más o menos simétrica siguiente:\n\n\n\n\n\nResulta que su media es \\(\\overline{x}=2.9\\) y su desviación típica es \\(s_x=1.1\\), y que el intervalo \\([\\overline{x}-s_x,\\overline{x}+s_x]\\) contiene un 64% de la muestra. Su mediana es \\(Q_{0.5}=3\\), muy cercana a su media, y su \\(IQI\\) es [2.2, 3.7]. Su coeficiente de asimetría es \\(\\gamma_1=-0.03\\), lo que es consistente con su simetría.\nConsiderad finalmente la variable siguiente, que es simétrica pero en forma de U:\n\n\n\n\n\nResulta que su media es \\(\\overline{x}=3.9\\) y su desviación típica es \\(s_x=2.2\\), pero el intervalo \\([\\overline{x}-s_x,\\overline{x}+s_x]\\) contiene solo el 52% de la muestra. Su mediana es también \\(Q_{0.5}=3.9\\) y su \\(IQI\\) es [1.8,5.9]. Su coeficiente de asimetría es \\(\\gamma_1=0.0007\\).\n\n\n\n\n\n\nNota\n\n\n\nLos tres tipos de simetría/asimetría se generalizan de manera inmediata a variables poblacionales, a partir de alguna representación gráfica de su distribución.\nPor ejemplo, si recordáis el gráfico de la distribución de los salarios anuales españoles (Figura @ref(fig:salaris)), presenta una clara asimetría a la derecha que arrastra el salario medio a la derecha del mediano.\n\n\n\n\n\n\n\n\nNota\n\n\n\nEl 1.5 en la definición de los bigotes en los diagramas de caja es tal que, si la variable “se ajusta a una variable normal” (su histograma se parece a una campana de Gauss), se espere alrededor de un 0.35% de valores atípicos a cada lado de la caja.\n\n\nEjercicio En un examen, un 60% de los estudiantes han sacado una nota superior a la media. ¿Cómo esperáis que sea la muestra de notas: simètrica, con cola a la izquierda, con cola a la derecha?\nNo nos hemos olvidado del coeficiente de curtosis, \\(\\beta_2\\). Este estadístico compara la longitud de las colas de la muestra con las que esperaríamos si su histograma se pareciera al de una campana de Gauss.\n\nCuando el histograma se parece al de una campana de Gauss, \\(\\beta_2\\approx 0\\): se dice que la variable es mesocúrtica.\n\n\n\n\n\n\n\nCuando el histograma tiene colas más largas, y en particular más valores atípicos, de lo esperado si tuviera la forma de una campana de Gauss, \\(\\beta_2&gt; 0\\); se dice que la variable es leptocúrtica.\n\n\n\n\n\n\n\nCuando el histograma tiene colas más cortas, y en particular menos valores atípicos, de lo esperado si tuviera la forma de una campana de Gauss, \\(\\beta_2&lt; 0\\); se dice que la variable es platicúrtica.\n\n\n\n\n\n\n\n\n3.0.8 Estadísticos y gráficos con JAMOVI\nEn la ventana Descriptivas podéis calcular la mayoría de los estadísticos y gráficos explicados hasta ahora. Por ejemplo, los estadísticos que podéis calcular del vector de alturas usado en secciones anteriores son:\n\n\n\n\n\nLa varianza y la desviación típica que calcula son las muestrales y el RIC en la tabla en castellano es el rango intercuartílico, nuestro IQR. Aunque en este caso hayan dado lo mismo, los cuantiles los calcula con una definición diferente de la nuestra.\nPor lo que refiere a gráficos, podéis dibujar, entre otros, histogramas de frecuencias relativas, boxplots y diagramas de puntos.\n\nHistograma:\n\n\n\n\n\n\nComo ya hemos comentado, en este histograma las clases son cerradas a la derecha.\n\nBoxplot:\n\n\n\n\n\n\nLos cuartiles los calcula con una definición diferente de la nuestra.\n\nDiagrama de puntos:\n\n\n\n\n\n\n\n\n3.0.9 Estadísticos sobre datos agrupados\nEn nuestro lenguaje cotidiano, solemos agrupar datos cuantitativos sin que seamos conscientes de ello. Cuando decimos, por ejemplo, que la edad de alguien es de 18 años, no queremos decir que nació justo hoy hace 18 años, sino que ya ha cumplido los 18 años, pero aún no ha cumplido los 19; es decir, que agrupamos todas las edades que caen dentro del intervalo [18,19) en una misma clase, que llamamos “18 años”. Del mismo modo, que alguien mida 1.72 no significa que esta sea su altura exacta, con la precisión del grueso de un cabello, sino que su altura pertenece a un intervalo de valores en torno a 1.72 metros que identificamos con “1.72”. Bajo la calificación de “aprobado” agrupamos todas las notas mayores o iguales que 5 y menores que 7. Y estamos seguros de que se os ocurren otros ejemplos.\nMuy a menudo, los datos cuantitativos se recogen directamente agrupados, como por ejemplo franjas salariales o el número de refrescos semanales como en la tabla de datos del primer ejemplo de este tema. Aunque estas clases definan un conjunto de datos ordinales es muy probable que nos interese interpretarlas como eso: clases resultado de agrupar datos cuantitativos. ¿Cómo podemos calcular los estadísticos? Está claro que de manera exacta es imposible si no conocemos los datos brutos, sin agrupar. Pero podemos intentar aproximarlos.\n\nSubstituimos la moda por la clase modal: la clase de mayor frecuencia.\nPara calcular la media, la varianza, etc., para cada clase tomamos su punto medio, al que en este contexto llamaremos su marca de clase, y consideraremos que nuestra muestra está formada, para cada clase, por tantas copias de su marca como la frecuencia de la clase.\n\n\nEjemplo: Volvamos a la muestra de tensiones arteriales medias de 120 adultos y supongamos que nos han dado directamente los datos agrupados en 9 clases de amplitud 10:\n\n\n\n\n\n\n\nClase\nFrecuencia\n\n\n\n\n[80,90)\n3\n\n\n[90,100)\n3\n\n\n[100,110)\n16\n\n\n[110,120)\n33\n\n\n[120,130)\n23\n\n\n[130,140)\n22\n\n\n[140,150)\n13\n\n\n[150,160)\n5\n\n\n[160,170)\n2\n\n\n\n\n\n\n\n\nLa clase modal es [110,120). Para aproximar la media y la varianza de la muestra original, tomaremos como marcas de clase los puntos medios de las clases, 85,95,…,165, y supondremos que la muestra está formada por 3 copias del valor 85, 3 copias del valor 95, 16 copias del valor 105, …, 2 copias del valor 165. Entonces:\n\nAproximamos la media de la muestra por \\[\n\\frac{3\\times 85+3\\times 95+16\\times 105+\\cdots+2\\times 165}{120}=123.75\n\\]\nAproximamos la varianza de la muestra por \\[\n\\frac{3\\times (85-123.75)^2+3\\times (95-123.75)^2+16\\times (105-123.75)^2+\\cdots+2\\times (165-123.75)^2}{120}=267.6\n\\]\n\nPor lo que refiere a la mediana y los otros cuantiles de una variable cuantitativa agrupada, se han propuesto varios métodos para intentar aproximarlos a partir de las tablas de frecuencias de sus clases. Aquí explicaremos el más sencillo y lo ilustraremos con el ejemplo anterior. Por comodidad, vamos a añadir las frecuencias absolutas y relativas acumuladas de las clases a la tabla de frecuencias:\n\n\n\n\n\n\nClase\nFrecuencia\nFrec. acum.\nFrec. rel. acum.\n\n\n\n\n[80,90)\n3\n3\n0.0250\n\n\n[90,100)\n3\n6\n0.0500\n\n\n[100,110)\n16\n22\n0.1833\n\n\n[110,120)\n33\n55\n0.4583\n\n\n[120,130)\n23\n78\n0.6500\n\n\n[130,140)\n22\n100\n0.8333\n\n\n[140,150)\n13\n113\n0.9417\n\n\n[150,160)\n5\n118\n0.9833\n\n\n[160,170)\n2\n120\n1.0000\n\n\n\n\n\n\n\n\nEn primer lugar buscamos en qué clase cae la mediana, es decir, qué clase contiene el valor que separa las dos mitades de la muestra: la llamaremos el intervalo crítico para la mediana. En nuestro ejemplo, será la primera clase cuya frecuencia relativa acumulada sea mayor o igual que 0.5. Se trata del intervalo [120,130). La mediana sería la media de los valores en las posiciones 60 y 61 tras ordenarlos. Como hasta justo antes de 120 hay 55 valores, es la media de los valores quinto y sexto de la clase [120,130), en la que hay 23.\nLo que haremos será suponer que estos 23 valores están igualmente distribuidos empezando por 120 y sin llegar a 130 (porque nuestras clases son cerradas por la izquierda y abiertas a la derecha). Por lo tanto suponemos que son \\[\n120, 120+\\frac{1}{23}\\cdot 10, 120+\\frac{2}{23}\\cdot 10, 120+\\frac{3}{23}\\cdot 10,\\ldots, 120+\\frac{21}{23}\\cdot 10, 120+\\frac{22}{23}\\cdot 10\n\\]\nLos valores quinto y sexto son \\(120+40/23=121.74\\) y \\(120+50/23=122.17\\) y su media 121.96. Esta es nuestra aproximación de la mediana.\n\n\n\n\n\n\nNota\n\n\n\nSi las clases fueran cerradas a la derecha, tomaríamos los valores \\[\n120+\\frac{1}{23}\\cdot 10, 120+\\frac{2}{23}\\cdot 10, 120+\\frac{3}{23}\\cdot 10,\\ldots, 120+\\frac{21}{23}\\cdot 10, 120+\\frac{22}{23}\\cdot 10, 130\n\\] Y si los extremos no pueden pertenecer a las clases, entonces tomaríamos los valores \\[\n120+\\frac{1}{24}\\cdot 10, 120+\\frac{2}{24}\\cdot 10, 120+\\frac{3}{24}\\cdot 10,\\ldots,  120+\\frac{22}{24}\\cdot 10, 120+\\frac{23}{24}\\cdot 10\n\\] En cada caso, luego tomaríamos la media del quinto y el sexto.\n\n\nUn procedimiento similar se puede usar para aproximar cualquier cuantil \\(Q_{p}\\) de orden \\(p\\). Por ejemplo, busquemos el primer cuartil. Es el trigésimo valor de la muestra ordenada, y por lo tanto el octavo de la clase [110,120), que contiene 33 valores. Tomamos estos 33 valores igualmente distribuidos y empezando con 110: \\[\n110, 110+\\frac{1}{33}\\cdot 10, 110+\\frac{2}{33}\\cdot 10, 110+\\frac{3}{33}\\cdot 10,\\ldots, 110+\\frac{31}{33}\\cdot 10, 110+\\frac{32}{33}\\cdot 10\n\\] El octavo es \\(110+70/33=112.12\\). Esta es nuestra aproximación del segundo cuartil.\nEjercicios\n\nConsiderad el agrupamiento en 15 clases de la muestra de tensiones arteriales medias de 120 adultos. A partir de este agrupamiento, estimad los valores de la media, la varianza y la mediana de la muestra, y comparadlos con los obtenidos a partir de 9 clases. ¿Cuáles creéis que estiman mejor los estadísticos de la muestra original?\nConsiderad el diagrama de la siguiente figura, que muestra los perímetros braquiales derechos de 120 mujeres.\n\n\n\n\n\n\n\n¿Qué tipo de gráfico es?\n¿De qué tipo de datos es el perímetro braquial?\n¿Cuál es la clase modal?\n¿Cómo describiríais la asimetría de la muestra?\n¿En qué clase cae la mediana de la muestra?\n¿Qué estimáis que vale la mediana?\n¿En qué clase cae el primer cuartil de la muestra?\n¿Qué estimáis que vale el primer cuartil?\n¿Qué estimáis que vale la media?\n\n\n\n3.0.10 Datos cuantitativos bivariantes\nSi tenemos observaciones de dos variables cuantitativas medidas sobre una misma muestra de \\(n\\) individuos, las recogemos en una tabla de datos bivariante, con las filas representando los individuos y las columnas representando las dos variables:\n\\[\n\\begin{array}{c|c|c}\n\\textbf{Individuo} &\\textbf{Variable 1} &\\textbf{Variable 2}\\\\ \\hline\n1 & x_{1} & y_{1} \\cr\n2 & x_{2} & y_{2} \\cr\n3 & x_{3} & y_{3} \\cr\n\\vdots &\\vdots & \\vdots \\cr\nn & x_{n} & y_{n}\n\\end{array}\n\\]\nPodemos representar esta tabla por medio de un gráfico de dispersión (scatter plot): el gráfico de los puntos \\((x_k,y_k)\\).\n\nEjemplo:\nHemos medido la tensión arterial media (en mmHg) y el nivel de colesterol (en mg/dl) de 10 individuos y recogido estos valores en la tabla siguiente:\n\n\n\n\n\n\n\n\nTensión\nColesterol\n\n\n\n\n1\n105.7\n169.3\n\n\n2\n117.4\n191.7\n\n\n3\n131.9\n202.6\n\n\n4\n117.8\n218.2\n\n\n5\n133.0\n223.2\n\n\n6\n107.9\n180.0\n\n\n7\n118.6\n230.4\n\n\n8\n123.4\n211.8\n\n\n9\n124.1\n202.3\n\n\n10\n113.4\n185.3\n\n\n\n\n\n\n\n\nSu diagrama de dispersión es\n\n\n\n\n\n\n\n\n\nUna serie temporal es un caso particular de tabla de datos cuantitativos bivariante en la que la primera variable representa el paso del tiempo. En este caso, es conveniente unir con segmentos los puntos consecutivos en el tiempo para ayudar a visualizar la evolución de los datos en el tiempo.\n\nEjemplo:\nConsideremos la siguiente tabla de los números diarios de defunciones por COVID-19 en la Baleares entre día 16 y día 31 de marzo de 2019:\n\n\n\n\n\n\n\nDía\nDefunciones\n\n\n\n\n16\n0\n\n\n17\n0\n\n\n18\n1\n\n\n19\n0\n\n\n20\n2\n\n\n21\n0\n\n\n22\n6\n\n\n23\n0\n\n\n24\n3\n\n\n25\n4\n\n\n26\n5\n\n\n27\n4\n\n\n28\n3\n\n\n29\n8\n\n\n30\n5\n\n\n31\n4\n\n\n\n\n\n\n\n\nSe trata de una serie temporal. Su gráfico de dispersión es\n\n\n\n\n\n\n\n\n\nA menudo nos interesará medir la asociación (propensión a variar conjuntamente) de dos variables cuantitativas medidas sobre una misma muestra de individuos: por ejemplo, valorar la tendencia del nivel de colesterol a crecer con la tensión arterial media en la tabla del Ejemplo que venimos trabajando.\nUno de los estadísticos más usados con este fin es la covarianza. Su definición, para los vectores \\(x=(x_1,\\ldots,x_n)\\) e \\(y=(y_1,\\ldots,y_n)\\), de medias \\(\\overline{x}\\) y \\(\\overline{y}\\), respectivamente, es \\[\ns_{x,y}=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})}{n}\n\\]\n\n\n\n\n\n\nPrecaución\n\n\n\nTambién hay una versión muestral, dividiendo por \\(n-1\\) en lugar de \\(n\\), que es la que calculan la mayoría de los paquetes estadísticos. El motivo es el mismo que ya explicamos con ocasión de la varianza: la covarianza muestral estima mejor la covarianza de las variables poblacionales que la versión “a secas”.\n\n\n\n\n\n\n\n\nImportante\n\n\n\nLa covarianza de un vector consigo mismo es su varianza: \\[\ns_{x,x}=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})(x_i-\\overline{x})}{n}=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\overline{x})^2=s_x^2\n\\]\n\n\nEl signo de la covarianza mide el signo de la asociación entre los dos vectores:\n\nLa covarianza es positiva cuando \\(x\\) e \\(y\\) satisfacen la condición siguiente: si una de las dos variables crece, la otra también tiende a crecer; es decir, si \\(x_i&lt;x_j\\), \\(y_j\\) tiende a ser mayor que \\(y_i\\).\n\n\n\n\n\n\n\nLa covarianza es negativa cuando \\(x\\) e \\(y\\) satisfacen la condición siguiente: si una de las dos variables crece, la otra tiende a decrecer; es decir, si \\(x_i&lt;x_j\\), \\(y_j\\) tiende a ser menor que \\(y_i\\).\n\n\n\n\n\n\n\nSi la covarianza es muy cercana a 0, es porque no hay una tendencia clara al crecimiento o decrecimiento de \\(y_i\\) en función del de \\(x_i\\).\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEn particular, si las variables \\(x\\) e \\(y\\) son independientes, en el sentido de que el valor de \\(x\\) no influye para nada en el valor de \\(y\\), la covarianza de \\(x\\) e \\(y\\) es 0.\n\n\n\nEjemplo:\nVolvamos a la tabla de tensiones arteriales medias y niveles de colesterol del ejemplo . Las medias de las variables son\n\\[\n\\begin{array}{l}\n\\overline{\\text{Tensión}}=\\dfrac{105.7+117.4+131.9+\\cdots+113.4}{10}=119.32\\\\\n\\overline{\\text{Colesterol}}=\\dfrac{169.3+191.7+202.6+\\cdots+185.3}{10}=201.48\n\\end{array}\n\\] y su covarianza es \\[\n\\begin{array}{l}\ns_{\\text{Tensión},\\text{Colesterol}}\\\\\n\\quad =\\dfrac{(105.7-119.32)(169.3-201.48)+(117.4-119.32)(191.7-201.48)+\\cdots}{10}\\\\\n\\quad=110.9164\n\\end{array}\n\\] Como esta covarianza es positiva, deducimos que los valores de la tensión media y el nivel de colesterol en esta muestra tienden a crecer juntos, como ya observamos en el diagrama de dispersión .\n\nEn general, la magnitud de la covarianza mide cuánto varían conjuntamente las variables. Por ejemplo, una covarianza positiva y muy grande no solo indica que cuando la \\(x\\) crece, la \\(y\\) tiende a crecer, sino que también nos indica que cuando la \\(x\\) es mucho más grande que la media, la \\(y\\) tiende a ser mucho más grande que la media. Esto hace que, por ejemplo, la covarianza dependa de las unidades de medida. Si por ejemplo hubiéramos medido los niveles de colesterol del ejemplo anterior en mg/cl, de manera que sus valores se dividieran por 10, la covarianza resultante quedaría dividida por 10.\nPor ello a menudo se usa una versión normalizada de la covarianza, la correlación de Pearson, cuyo valor no depende de cambios de escala y tiene una interpretación sencilla (aunque no siempre corresponde con lo que queremos saber de nuestra muestra).\nLa correlación de Pearson de dos vectores de datos \\(x\\) e \\(y\\) de la misma longitud se define como su covarianza dividida por el producto de sus desviaciones típicas: \\[\nr_{x,y}=\\frac{s_{x,y}}{s_xs_y}\n\\]\nComo el signo de \\(r_{x,y}\\) es el mismo que el de \\(s_{x,y}\\) y es 0 exactamente cuando \\(s_{x,y}=0\\), el signo de la correlación de Pearson tiene el mismo significado que el de la covarianza:\n\n\\(r_{x,y}&gt;0\\) cuando \\(y\\) tiende a crecer si \\(x\\) crece\n\\(r_{x,y}&lt;0\\) cuando \\(y\\) tiende a decrecer si \\(x\\) crece\n\\(r_{x,y}\\approx 0\\) cuando no hay ninguna tendencia en este sentido; decimos entonces que \\(x\\) e \\(y\\) están incorreladas\nEn particular, si \\(x\\) e \\(y\\) son independientes, \\(r_{x,y}=0\\)\n\nPero la correlación de Pearson lleva más información que la covarianza, porque mide la relación lineal entre los dos vectores, en el sentido de las propiedades siguientes:\n\n\\(r_{x,y}\\) está siempre entre -1 y 1.\nCuanto más cerca está \\(r_{x,y}\\) de -1 o 1, más se aproximan los puntos \\((x_i,y_i)\\) a estar sobre una recta, que será creciente si \\(r_{x,y}&gt;0\\) y decreciente si \\(r_{x,y}&lt;0\\).\nY en concreto,\n\nLos puntos \\((x_i,y_i)\\) están sobre una recta creciente exactamente si, y solo si, \\(r_{x,y}=1\\).\nLos puntos \\((x_i,y_i)\\) están sobre una recta decreciente si, y solo si, \\(r_{x,y}=-1\\).\n\n\n\nEjemplo:\nSeguimos con la tabla de tensiones arteriales medias y niveles de colesterol. Ya hemos obtenido su covarianza, \\(s_{\\text{Tensión},\\text{Colesterol}}=110.9164\\). Sus desviaciones típicas son \\[\n\\begin{array}{l}\ns_{\\text{Tensión}}=\\sqrt{\\dfrac{(105.7-119.32)^2+(117.4-119.32)^2+\\cdots+(113.4-119.32)^2}{10}}=8.616\\\\\ns_{\\text{Colesterol}}=\\sqrt{\\dfrac{(169.3-201.48)^2+(191.7-201.48)^2+\\cdots+(185.3-201.48)^2}{10}}=18.84\n\\end{array}\n\\] por lo que su correlación de Pearson es \\[\nr_{\\text{Tensión},\\text{Colesterol}}=\\frac{110.9164}{8.616\\cdot 18.84}=0.683\n\\] Los pares de valores de tensión arterial media y el nivel de colesterol de los individuos de la muestra presentan una tendencia acusada a crecer conjuntamente siguiendo una recta.\n\n\n\n\n\n\n\nNota\n\n\n\nSi una de las dos variables tiene desviación típica 0, en la fórmula de la correlación aparece un 0 en el denominador y no la podemos calcular. En este caso, se toma \\(r_{x,y}=0\\). El motivo es el siguiente. Supongamos que \\(s_x=0\\). Como ya hemos visto, esto quiere decir que todos los valores de \\(x\\) son iguales, y por lo tanto iguales al valor medio \\(\\overline{x}\\). Pero entonces \\(s_{x,y}=0\\): el numerador de \\(r_{x,y}\\) también es 0.\nPor lo tanto, si los puntos están sobre una recta horizontal o una recta vertical, la correlación es 0, por mucho que estén sobre una recta. Esto es consistente con el propiedad de que independencia implica correlación nula: si una de las variables es constante, los valores que toma son claramente independientes de los que toma la otra.\n\n\nGráficamente podemos visualizar la tendencia de los puntos de una tabla bivariante a estar sobre una recta añadiendo a su gráfico de dispersión su recta de regresión (para ser precisos, de regresión lineal por mínimos cuadrados, pero normalmente omitiremos esta apostilla). Se trata de la recta que más se aproxima a los puntos \\((x_i,y_i)\\) en el sentido siguiente.\nDada una recta \\(y=ax+b\\), el error que se comete al estimar con esta recta el valor \\(y_i\\) sobre el sujeto correspondiente al par \\((x_i,y_i)\\) es \\(y_i-(ax_i+b)\\). La recta de regresión es la que tiene coeficientes \\(a,b\\) que hacen mínima la suma de los cuadrados de estos errores, \\[\n\\sum_{i=1}^n (y_i-(ax_i+b))^2\n\\]\nResulta que los coeficientes de esta recta de regresión son \\[\na=\\frac{s_{x,y}}{s_x^2},\\quad b = \\overline{y}-a\\cdot \\overline{x}.\n\\]\n\nEjemplo:\nSiguiendo con nuestro ejemplo de tensiones y niveles de colesterol, la recta de regresión del nivel de colesterol en función de la tensión media tiene pendiente \\[\n  a=\\frac{s_{\\text{Tensión},\\text{Colesterol}}}{s_{\\text{Colesterol}}^2}=\\frac{123.2}{19.86^2}=0.3124\n\\] y término independiente \\[\nb=  \\overline{\\text{Tensión}}-a\\cdot\\overline{\\text{Colesterol}} =119.32-0.3124\\cdot201.48 = 56.378\n\\]\n\nEl gráfico de dispersión de los puntos junto a esta recta de regresión es el siguiente:\n\n\n\n\n\n\n\n\n\nCon Jamovi podéis calcular la correlación de Pearson y dibujar un gráfico de dispersión con la recta de regresión en Regresión/Matriz de correlaciones:\n\n\n\n\n\nOtra posibilidad para dibujar el gráfico de dispersión es instalar el módulo scatr que añade al menú Dispersión un gráfico de dispersión con más opciones:\n\n\n\n\n\nPor el momento Jamovi no ofrece la posibilidad de calcular covarianzas si no es a través del editor. La función que calcula la covarianza muestral es cov y se aplica a los dos vectores.\n\n\n\n\n\nEn el módulo Demonstration de JAMOVI tenéis la opción de generar muestras aleatorias de pares de valores y correlación (aproximadamente) la deseada, para haceros una idea de qué representan los diferentes valores de la correlación. Por ejemplo, un conjunto de 100 pares de valores con correlación aproximadamente 0.5:\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEl valor de la correlación de Pearson no siempre es suficiente para valorar el ajuste de los puntos a una recta. Es siempre conveniente dibujar los puntos y la recta de regresión lineal y darles un vistazo.\n\n\n\nEjemplo:\nF. Anscombe produjo los cuatro conjuntos de puntos descritos en la figura que sigue. Como podéis, ver, tienen ajustes muy diferentes a una recta, y en cambio resulta que tienen el mismo valor de \\(r\\): 0.816. Para más detalles, consultad la correspondiente entrada de la Wikipedia.\n\n\n\n\n\n\nEl cuarteto de Anscombe\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nSer incorrelados no es sinónimo de que no haya ninguna dependencia entre las dos variables. Por ejemplo, los conjuntos de puntos de la Figura @ref(fig:datasaurus) tienen correlación casi 0 (en concreto -0.004), y es claro que en cada caso hay una fuerte dependencia entre los valores de \\(x\\) y de \\(y\\). Lo que significa que la covarianza, o la correlación, sea 0 es que no hay relación entre el crecimiento de una variable y el de la otra.\n\n\n\n\n\n\n\nDos conjuntos de datos incorrelados\n\n\n\n\nComo hemos visto, la correlación de Pearson mide la dependencia lineal entre dos variables cuantitativas. Otras medidas de correlación miden otros tipos de dependencia. La alternativa más popular a la correlación de Pearson es la correlación de Spearman, \\(r_S\\), que mide la concordancia en el orden de los individuos según sus valores en las dos variables medidas. Se calcula, grosso modo, de la manera siguiente:\n\nA cada individuo de la muestra le asignamos su posición (su rango) según el orden creciente de los valores \\(x_i\\).\nA cada individuo de la muestra le asignamos su rango según el orden creciente de los valores \\(y_i\\).\nCalculamos la correlación de Pearson de los vectores de rangos.\n\n\n\n\n\n\n\nImportante\n\n\n\nLa correlación de Spearman también se puede usar para variables ordinales. ¡La de Pearson no!\n\n\n\nEjemplo:\nVolvemos a nuestro ejemplo de tensiones y niveles de colesterol. Ampliamos la tabla de datos con los rangos de los individuos recogidos en la misma para cada variable:\n\n\n\n\n\n\n\n\nTensión\nRango\nColesterol\nRango\n\n\n\n\n1\n105.7\n1\n169.3\n1\n\n\n2\n117.4\n4\n191.7\n4\n\n\n3\n131.9\n9\n202.6\n6\n\n\n4\n117.8\n5\n218.2\n8\n\n\n5\n133.0\n10\n223.2\n9\n\n\n6\n107.9\n2\n180.0\n2\n\n\n7\n118.6\n6\n230.4\n10\n\n\n8\n123.4\n7\n211.8\n7\n\n\n9\n124.1\n8\n202.3\n5\n\n\n10\n113.4\n3\n185.3\n3\n\n\n\n\n\n\n\n\nLa correlación de Spearman de las dos variables será la correlación de Pearson de sus vectores de rangos. Si la calculáis, da \\({r_S}=0.73333\\).\n\n\n\n\n\n\nNota\n\n\n\nUna nota técnica, para los completistas. ¿Qué pasa si, al calcular los rangos, hay valores repetidos? Pues que se les asigna el mismo rango calculado de la manera siguiente:\n\nEn primer lugar, a cada individuo de la muestra le asignamos un “rango provisional”: su posición según el orden creciente de los valores \\(x_i\\) y, en caso de igualdad de estos valores, según su orden de aparición en la tabla de datos.\nEntonces, para cada valor del vector, se asigna como rango “definitivo” a todos los individuos cuyo valor \\(x\\) es ese valor la media de sus posiciones.\n\n\n\nVeamos un ejemplo.\n\nEjemplo:\nVamos a calcular los rangos de los individuos de la tabla de datos siguiente según su valor de la variable \\(x\\).\n\n\n\n\n\n\n\nIndividuo\nx\n\n\n\n\n1\n1\n\n\n2\n2\n\n\n3\n1\n\n\n4\n1\n\n\n5\n2\n\n\n6\n4\n\n\n7\n4\n\n\n8\n3\n\n\n\n\n\n\n\n\nEmpezamos asignando rangos provisionales a los individuos, ordenándolos según su valor de \\(x\\) y en caso de empate de arriba abajo:\n\n\n\n\n\n\nIndividuo\nx\nPosición\n\n\n\n\n1\n1\n1\n\n\n2\n2\n4\n\n\n3\n1\n2\n\n\n4\n1\n3\n\n\n5\n2\n5\n\n\n6\n4\n7\n\n\n7\n4\n8\n\n\n8\n3\n6\n\n\n\n\n\n\n\n\nPasamos a asignar los rangos definitivos:\n\nA los tres individuos cuya \\(x\\) es 1 les asignamos como rango (1+2+3)/3=2.\nA los dos individuos cuya \\(x\\) es 2 les asignamos como rango (4+5)/2=4.5.\nAl único individuo cuya \\(x\\) es 3 le asignamos como rango definitivo su rango provisional: 6.\nA los dos individuos cuya \\(x\\) es 4 les asignamos como rango (7+8)/2=7.5.\n\n\n\n\n\n\n\nIndividuo\nx\nPosición\nRango\n\n\n\n\n1\n1\n1\n2.0\n\n\n2\n2\n4\n4.5\n\n\n3\n1\n2\n2.0\n\n\n4\n1\n3\n2.0\n\n\n5\n2\n5\n4.5\n\n\n6\n4\n7\n7.5\n\n\n7\n4\n8\n7.5\n\n\n8\n3\n6\n6.0\n\n\n\n\n\n\n\n\nLa correlación de Spearman se calcula con JAMOVI marcando Spearman en vez de Pearson en Regresión/Matriz de correlaciones.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Los datos y sus tipos</span>"
    ]
  },
  {
    "objectID": "t4_probabilidades.html",
    "href": "t4_probabilidades.html",
    "title": "4  Probabilidades",
    "section": "",
    "text": "4.1 Probabilidades elementales: Las mates\nLa probabilidad de un suceso es, básicamente, un número entre 0 y 1 (o, si lo preferís, un porcentaje entre 0% y 100%) que mide la expectativa de que se dé este suceso.\nEn este curso vamos a definir la probabilidad de un suceso como la proporción (la fracción, el porcentaje) de sujetos de una población (o a veces de una muestra, dependerá del contexto) en los que se da el suceso. Esta proporción mide la “probabilidad” de que si escogemos al azar un sujeto de la población, se dé en él el suceso.\nEn casos MUY sencillos, cuando todos los resultados posibles tienen la misma probabilidad, esta proporción coincide con la fracción de veces en que se da este suceso en el conjunto de resultados posibles y por lo tanto se puede calcular con la famosa regla de Laplace: \\[\n\\text{Probabilidad}=\\frac{\\text{Casos favorables}}{\\text{Casos posibles}}\n\\]\nPor ejemplo:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "t4_probabilidades.html#probabilidades-elementales-las-mates",
    "href": "t4_probabilidades.html#probabilidades-elementales-las-mates",
    "title": "4  Probabilidades",
    "section": "",
    "text": "Ejemplo:\n\nLa probabilidad de que al lanzar una moneda al aire salga cara es la proporción de la población de lanzamientos de esta moneda en los que sale cara.\n\n\n\n\nLa probabilidad de que salga cara al lanzar una moneda equilibrada al aire es 1/2 (casos favorables, 1; casos posibles, 2; los dos resultados tienen la misma probabilidad por definición de moneda equilibrada).\nPero la probabilidad de que un hijo sea varón no es 1/2, aunque solo haya dos sexos cromosómicos Es la proporción de hijos varones en el total de todos los hijos, que se estima en alrededor del 51.22%.\nO más exageradamente, la probabilidad de que una mujer de entre 17 y 27 años sea miope no es 1/2, aunque solo haya dos resultados posibles: ser miope y no serlo. Esta probabilidad es la proporción de miopes en la población formada por todas las mujeres de esa franja de edad, que, en España en 2018, se estimaba en un 65.4% según un informe de la Asociación Visión y Vida.\n\n\n4.1.1 Álgebra de conjuntos\nVamos a repasar muy rápidamente las notaciones y las propiedades de las operaciones de conjuntos, para poder usar este lenguaje en lo que sigue.\nSean \\(A\\) y \\(B\\) subconjuntos (en el contexto de la teoría de probabilidades, se los llama sucesos) de un conjunto \\(\\Omega\\) (nuestra población o, en el lenguaje de la teoría de probabilidades, el espacio muestral).\n\n\\(A\\cup B\\) es la unión de \\(A\\) y \\(B\\): el conjunto formado por los elementos de \\(\\Omega\\) que pertenecen a \\(A\\) o a \\(B\\) (o a ambos).\n\\(A \\cap B\\) es la intersección de \\(A\\) y \\(B\\): el conjunto formado por los elementos que pertenecen simultáneamente a \\(A\\) y a \\(B\\).\nCorresponde a la conjunción del lenguaje natural.\n\\(A^c\\) es el complementario de \\(A\\): el conjunto formado por los elementos de \\(\\Omega\\) que no pertenecen a \\(A\\).\nCorresponde a la negación del lenguaje natural.\n\\(A-B=A \\cap B^c\\) es la diferencia “\\(A\\) menos \\(B\\)”: el conjunto formado por los elementos de \\(A\\) que no pertenecen a \\(B\\).\nPor lo tanto, \\(A^c=\\Omega-A\\).\nDiremos que \\(A\\) y \\(B\\) son disjuntos, o incompatibles, cuando \\(A\\cap B=\\emptyset\\), donde \\(\\emptyset\\) es el conjunto vacío, el conjunto que no tiene elementos.\nDiremos que \\(A\\) está contenido, o incluido, en \\(B\\), y lo denotaremos por \\(A\\subseteq B\\), cuando todo elemento de \\(A\\) pertenece a \\(B\\). Para recalcar que \\(A\\) está estrictamente contenido en \\(B\\) (que está contenido en \\(B\\) pero no es igual a \\(B\\)) usaremos \\(A\\subsetneq B\\).\n\nEjemplo:\n\nConsideremos la población \\(\\Omega\\) formada por los estudiantes de una clase, y sean \\(A\\) el subconjunto formado por la mujeres de esa clase y \\(B\\) el subconjunto formado por los estudiantes de esa clase que llevan gafas.\n\n\\(A\\cup B\\) es el conjunto formado por las mujeres de la clase o los estudiantes de la clase que llevan gafas (o ambos).\n\\(A \\cap B\\) es el conjunto formado por las mujeres de la clase que llevan gafas.\n\\(A^c\\) es el conjunto formado por los hombres de la clase.\n\\(A-B\\) es el conjunto formado por las mujeres de la clase que no llevan gafas.\n\\(A\\subseteq B\\) significa que todas las mujeres de la clase llevan gafas.\n\n\n\n\n4.1.2 Algunas fórmulas básicas\nHemos definido la probabilidad \\(P(A)\\) de un subconjunto (suceso) \\(A\\) de una población (espacio muestral) \\(\\Omega\\) como la fracción de los sujetos de \\(\\Omega\\) que pertenecen a \\(A\\). A partir de esta definición se deducen, las propiedades siguientes:\n\nPara todo suceso \\(A\\), \\(0\\leqslant P(A)\\leqslant 1\\).\n\nUn subconjunto \\(A\\) de \\(\\Omega\\) no puede representar ni una fracción negativa ni una fracción mayor que 1 de los sujetos de \\(\\Omega\\).\n\n\\(P(\\Omega)=1\\) y \\(P(\\emptyset)=0\\) (recordad que \\(\\emptyset\\) es el conjunto vacío).\nSi \\(A\\) y \\(B\\) son dos sucesos disjuntos, entonces \\(P(A\\cup B)=P(A)+P(B)\\).\n\nSi no hay ningún sujeto que pertenezca simultáneamente a \\(A\\) y a \\(B\\), entonces el número de sujetos que pertenecen a \\(A\\) o a \\(B\\) es la suma de los que pertenecen a \\(A\\) y de los que pertenecen a \\(B\\). Entonces, dividiendo por el número total de individuos de la población \\(\\Omega\\) (su cardinal), obtenemos que la fracción de los sujetos que pertenecen a \\(A\\) o a \\(B\\) es la suma de las fracciones de los que pertenecen a \\(A\\) y de los que pertenecen a \\(B\\).\n\nMás en general, si \\(A_1,A_2,\\ldots,A_n\\) son sucesos disjuntos dos a dos, entonces \\[\nP(A_1\\cup A_2\\cup \\cdots \\cup A_n)=P(A_1)+P(A_2)+\\cdots +P(A_n).\n\\]\n\\(P(A-B)=P(A)-P(A\\cap B)\\).\n\\(P(A^c)=1-P(A)\\).\n\nEs decir, la fracción de los sujetos que no pertenecen a \\(A\\) es 1 menos la fracción de los que sí pertenecen a \\(A\\).\n\nSi \\(A\\subseteq B\\), entonces \\(P(A)\\leqslant P(B)\\).\n\nSi \\(A\\) está contenido en \\(B\\), la fracción de los sujetos que pertenecen a \\(A\\) es menor o igual que la de los que pertenecen a \\(B\\).\n\n\\(P(A\\cup B)=P(A)+P(B)-P(A \\cap B)\\).\n\nSi queréis contar cuántos sujetos hay en \\(A\\cup B\\), tenéis que añadir a los de \\(A\\) los de \\(B-A\\). Dividiendo por el total de la población para pasar a proporciones, esto nos dice que \\[\nP(A\\cup B)=P(A)+P(B-A)=P(A)+P(B)-P(A \\cap B)\n\\] donde la segunda igualdad se debe a (5).\nPor ejemplo, si en una población hay un 50% de mujeres y un 60% de miopes, y un 35% del total son mujeres miopes, las personas que son mujeres o miopes (recordad, o ambas cosas) forman un 75% de la población: al 50% de mujeres hay que sumarle el 25% de miopes que no son mujeres.\nEl número de sujetos que pertenecen a \\(A\\) pero no a \\(B\\) se obtiene restando del total de sujetos de \\(A\\) los que pertenecen simultáneamente a \\(A\\) y a \\(B\\), es decir, a \\(A\\cap B\\). Dividiendo por el número total de individuos de la población, obtenemos la correspondiente igualdad de proporciones.\nEjemplo:\n\nSupongamos que el 0.1% de los donantes de sangre dan positivo en el test de VIH, que el 1% dan positivo en el test de herpes simple (VHS) y que el 0.05% dan positivo en ambos tests.\n¿Cuál es la probabilidad de que un donante escogido al azar dé positivo en al menos uno de los dos tests? ¿Y la de que un donante escogido al azar dé positivo en VHS pero no en VIH?\nVamos a poner nombres a los sucesos involucrados en estas preguntas:\n\n\\(A\\): Dar positivo en VIH. Sabemos que \\(P(A)=0.001\\).\n\\(B\\): Dar positivo en VHS. Sabemos que \\(P(B)=0.01\\).\n\\(A\\cap B\\): Dar positivo en los dos. Sabemos que \\(P(A\\cap B)=0.0005\\).\n\\(A\\cup B\\): Dar positivo en al menos uno de los dos. Es lo que queremos calcular en la primera pregunta.\nPor la propiedad (8): \\[\nP(A \\cup B) =P(A)+P(B)-P(A\\cap B)=0.001+0.01-0.0005=0.0105\n\\] La probabilidad de que un donante escogido al azar dé positivo en al menos uno de los dos tests es del 1.05%.\n\\(B-A\\): Dar positivo en VHS pero no en VIH. Es lo que queremos calcular en la segunda pregunta.\nPor la propiedad (5), \\[\nP(B-A)=P(B)-P(A\\cap B)=0.01-0.0005=0.0095\n\\]\n\nLa probabilidad de que un donante escogido al azar dé positivo en VHS pero no en VIH es del 0.95%.\n\nOtra manera de calcular estas probabilidades sin necesidad de recordar fórmulas sería:\n\nTomar como referencia una población de un tamaño concreto.\nCalcular en esta población cuántos individuos pertenecen a \\(A\\cap B\\) (dan positivo en ambos tests), cuántos a \\(A-B\\) (positivos en VIH pero no en VHS), cuántos a \\(B-A\\) (positivos en VHS pero no en VIH) y cuántos a \\(A^c\\cap B^c\\) (negativo en ambos tests) y a partir de ahí calcular todo lo que queramos.\n\nA este método se le suele llamar método de frecuencias naturales (“la cuenta de la vieja” no suena lo bastante científico), y así lo llamaremos nosotros. Pongámoslo en práctica en nuestro caso:\n\nVamos a tomar una población de referencia de 10,000 donantes\n¿Por qué este número? Veamos, fijaos en que la proporción de sujetos en \\(A\\cap B\\) es del 0.05%, es decir, 0.0005, y para facilitar los cálculos nos gustaría que todos los números que nos salieran fueran enteros, para no liarnos con decimales. Como 0.0005·10000=5, parece que 10,000 nos va a valer.\nLos sujetos de \\(A\\) son el 0.1% de la población: 10\nLos sujetos de \\(B\\) son el 1% de la población: 100\nLos sujetos de \\(A\\cap B\\) son el 0.05% de la población: 5\nEn resumen: \\[\n\\begin{array}{r|c|c|c}\n& A\\ (\\text{VIH}+) & A^c \\ (\\text{VIH}-)  & \\text{Total} \\\\ \\hline\nB\\ (\\text{VHS}+) &  5  &     &   100 \\\\ \\hline\nB^c\\ (\\text{VHS}-) &     &      &   9900 \\\\ \\hline\n\\text{Total} & 10& 9990 & 10000  \\\\\n\\end{array}\n\\]\nEntonces, los sujetos de \\(A-B\\) serán los de \\(A\\) menos los de \\(A\\cap B\\): 5\nY los sujetos de \\(B-A\\) serán los de \\(B\\) menos los de \\(A\\cap B\\): 95\nPor ahora ya tenemos: 5 sujetos positivos en VIH y en VHS; 5 positivos en VIH y negativos en VHS; y 95 positivos en VHS y negativos en VIH. En total, 105 sujetos. El resto serán negativos tanto en VIH como en VHS.\nPor lo tanto, los sujetos de \\(A^c\\cap B^c\\) serán 10000-105=9895.\n\nObtenemos la tabla de frecuencias siguiente: \\[\n\\begin{array}{r|c|c|c}\n& A\\ (\\text{VIH}+) & A^c \\ (\\text{VIH}-)  & \\text{Total} \\\\ \\hline\nB\\ (\\text{VHS}+) &  5  &  95  &   100 \\\\ \\hline\nB^c\\ (\\text{VHS}-) &  5  &   9895  &   9900 \\\\ \\hline\n\\text{Total} & 10& 9990 & 10000  \\\\\n\\end{array}\n\\]\nY ahora, cambiando “probabilidad” por “proporción”, ya podemos calcular lo que queramos.\n\n¿Cuál es la proporción de sujetos que dan positivo en algún test?\nHay 105 sujetos en la tabla que dan positivo en algún test: los 10 positivos en VIH y los 95 positivos en VHS y negativos en VIH. Por lo tanto, su proporción es de 105/10000=0.0105.\n¿Cuál es la proporción de sujetos que dan positivo en VHS pero no en VIH?\nHay 95 sujetos en la tabla que dan positivo en VHS y negativo en VIH, por lo que su proporción es de 95/10000=0.0095.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "t5_variables_aleatorias.html",
    "href": "t5_variables_aleatorias.html",
    "title": "5  Variables aleatorias",
    "section": "",
    "text": "5.1 Variables aleatorias discretas",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "t5_variables_aleatorias.html#variables-aleatorias-discretas",
    "href": "t5_variables_aleatorias.html#variables-aleatorias-discretas",
    "title": "5  Variables aleatorias",
    "section": "",
    "text": "5.1.1 Densidad y distribución\nSea \\(X: \\Omega\\to \\mathbb{R}\\) una variable aleatoria discreta.\n\nSu dominio \\(D_X\\) es el conjunto de los valores que puede tomar: más concretamente, el conjunto de los \\(x\\in \\mathbb{R}\\) tales que \\(P(X=x)&gt;0\\).\nSu función de densidad es la función \\(f_X:\\mathbb{R}\\to [0,1]\\) definida por \\[\nf_X(x)=P(X=x)\n\\] Es decir, la función que asigna a cada \\(x\\in \\mathbb{R}\\) la probabilidad de que \\(X\\) valga \\(x\\) (la proporción de sujetos de la población en los que \\(X\\) vale \\(x\\), la frecuencia relativa del valor \\(x\\) en el total de la población…).\nSu función de distribución es la función \\(F_X:\\mathbb{R}\\to  [0,1]\\) definida por \\[\nF_X(x)=P(X\\leqslant x)\n\\] Es decir, la función que asigna a cada \\(x\\in \\mathbb{R}\\) la probabilidad de que el valor de \\(X\\) sea \\(\\leqslant x\\) (la proporción de sujetos de la población en los que \\(X\\) vale \\(\\leqslant x\\), la frecuencia relativa acumulada de \\(x\\) en el total de la población… También se la suele llamar función de probabilidad acumulada para poner énfasis en esta última interpretación).\n\nEjemplo:\n\nSea \\(X\\) la variable aleatoria “Lanzamos 3 veces una moneda equilibrada y contamos las caras”. Entonces\n\nSu dominio es el conjunto de sus posibles valores: \\(D_X=\\{0,1,2,3\\}\\).\nSu función de densidad viene definida por \\(f_X(x)=P(X=x)\\):\n\n\\(f_X(0)=P(X=0)=1/8\\) (la probabilidad de sacar 0 caras)\n\\(f_X(1)=P(X=1)=3/8\\) (la probabilidad de sacar 1 cara)\n\\(f_X(2)=P(X=2)=3/8\\) (la probabilidad de sacar 2 caras)\n\\(f_X(3)=P(X=3)=1/8\\) (la probabilidad de sacar 3 caras)\n\\(f_X(x)=P(X=x)=0\\) para cualquier otro valor de \\(x\\) (la probabilidad de sacar \\(x\\) caras es 0 si \\(x\\notin\\{0,1,2,3\\}\\))\n\nEn resumen, la función de densidad de \\(X\\) es \\[\nf_X(x) =\\left\\{\n\\begin{array}{ll}\n1/8 & \\text{ si $x=0$}\\\\\n3/8 & \\text{ si $x=1$}\\\\\n3/8 & \\text{ si $x=2$}\\\\\n1/8 & \\text{ si $x=3$}\\\\\n0 & \\text{ si $x\\neq 0,1,2,3$}\n\\end{array}\\right.\n\\]\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nSi \\(X\\) es una variable aleatoria discreta, \\(P(X\\in A)=0\\) para cualquier subconjunto \\(A\\) disjunto de \\(D_X\\), porque \\(X\\) no puede tomar ningún valor de \\(A\\). Por ejemplo, ¿cuál es la probabilidad de sacar entre 2.5 y 2.7 caras al lanzar 3 veces una moneda? 0 ¿Y la de sacar \\(\\pi\\) caras? 0 de nuevo.\n\n\n\nVeamos su función de distribución \\(F_X\\). Recordad que \\(F_X(x)=P(X\\leqslant x)\\) y que nuestra variable solo puede tomar los valores 0, 1, 2 y 3.\n\nSi \\(x&lt;0\\), \\(F_X(x)=P(X\\leqslant x)=0\\) porque \\(X\\) no puede tomar ningún valor estrictamente negativo.\nSi \\(0\\leqslant x&lt;1\\), el único valor \\(\\leqslant x\\) que puede tomar \\(X\\) es el 0 y por lo tanto \\[\n  F_X(x)=P(X\\leqslant x)=P(X=0)=f_X(0)=1/8\n  \\]\nSi \\(1\\leqslant x&lt;2\\), los únicos valores \\(\\leqslant x\\) que puede tomar \\(X\\) son 0 y 1 y por lo tanto \\[\n  \\begin{array}{rl}\n  F_X(x)\\!\\!\\!\\!\\! & =P(X\\leqslant x)=P(X=0\\text{ o }X=1)\\\\ & =f_X(0)+f_X(1)=4/8=1/2\n  \\end{array}\n  \\]\nSi \\(2\\leqslant x&lt;3\\), los únicos valores \\(\\leqslant x\\) que puede tomar \\(X\\) son 0, 1 y 2 y por lo tanto \\[\n  \\begin{array}{rl}\nF_X(x)\\!\\!\\!\\!\\! & =P(X\\leqslant x)=P(X=0\\text{ o }X=1\\text{ o }X=2)\\\\ &  =f_X(0)+f_X(1)+f_X(2)=7/8\n  \\end{array}\n  \\]\nSi \\(x\\geqslant 3\\), seguro que obtenemos un número de caras \\(\\leqslant x\\) y por lo tanto \\(F_X(x)=P(X\\leqslant x)=1\\).\n\nAsí pues, la función \\(F_X\\) es la función \\[\nF_X(x) =\\left\\{\n\\begin{array}{ll}\n0 & \\text{ si $x&lt;0$}\\\\\n1/8 & \\text{ si $0\\leqslant x&lt; 1$}\\\\\n4/8 & \\text{ si $1\\leqslant x&lt; 2$}\\\\\n7/8 & \\text{ si $2\\leqslant x&lt; 3$}\\\\\n1 & \\text{ si $3\\leqslant x$}\n\\end{array}\\right.\n\\] Su gráfico es el siguiente:\n\n\nObservad en este gráfico que esta función de distribución \\(F_X\\) es creciente y escalonada, y el valor en los puntos de escalón es el superior. Esto es general. Si \\(X\\) es una variable aleatoria discreta:\n\n\\(F_X\\) es una función escalonada, con saltos en los valores de \\(D_X\\), que son los únicos con probabilidad estrictamente mayor que 0 y por lo tanto los únicos que “suman” probabilidad.\n\\(F_X\\) es creciente, porque si \\(x\\leqslant y\\), todos los sujetos tales que \\(X\\leqslant x\\) también cumplen que \\(X\\leqslant y\\), y por lo tanto \\[\nP(X\\leqslant x)\\leqslant P(X\\leqslant y).\n\\]\nSi \\(x_0,y_0\\in D_X\\) y \\(x_0&lt;y_0\\), entonces \\(F_X(x_0)&lt; F_X(y_0)\\), porque \\[\n\\begin{array}{rl}\nF_X(x_0)\\!\\!\\!\\!\\! & =P(X\\leqslant x_0)&lt;P(X\\leqslant x_0)+P(X=y_0)\\\\\n& =P(X\\leqslant x_0\\text{ o }X=y_0)\\leqslant P(X\\leqslant y_0)=F_X(y_0)\n\\end{array}\n\\]\nComo los valores que toma \\(F_X\\) son probabilidades, no pueden ser ni menores que 0 ni mayores que 1.\n\nEl conocimiento de \\(f_X\\), más las reglas del cálculo de probabilidades, permite calcular la probabilidad de cualquier suceso relacionado con \\(X\\): \\[\nP(X\\in A) =\\sum_{x\\in A} P(X=x) = \\sum_{x\\in A} f_X(x)\n\\] En particular \\[\nF_X(x_0)=P(X\\leqslant x_0)=\\sum_{x\\leqslant x_0} f_X(x)\n\\]\nLa moda de una variable aleatoria discreta \\(X\\) es el valor (o los valores) \\(x_0\\) tal que \\(f_X(x_0)=P(X=x_0)\\) es máximo. Se trata por lo tanto del “valor más frecuente de \\(X\\)” en la población. Por ejemplo, para nuestra variable aleatoria que cuenta el número de caras en 3 lanzamientos de una moneda equilibrada, la moda son los valores 1 y 2.\nHay un aspecto de las variables aleatorias discretas sobre el que queremos llamar la atención, sobre todo por comparación con las variables continuas:\n\n\n\n\n\n\nAdvertencia\n\n\n\nLos valores de \\(P(X\\leqslant x)\\) y \\(P(X&lt;x)\\) pueden ser diferentes.\n\n\nDe hecho, como \\[\nP(X\\leqslant x)=P(X&lt;x)+P(X=x),\n\\] se tiene que \\(P(X&lt; x)\\neq P(X\\leqslant x)\\) exactamente cuando \\(x\\in D_X\\).\nPor ejemplo, con la variable \\(X\\) “Lanzamos una moneda equilibrada 3 veces y contamos las caras”:\n\nLa probabilidad de sacar 2 caras o menos ya la hemos calculado, y es \\(P(X\\leqslant 2)=7/8\\)\nPero la probabilidad de sacar menos de 2 caras, \\(P(X&lt;2)\\), es la de sacar 1 cara o menos, por lo tanto \\(P(X&lt;2)=P(X\\leqslant 1)=4/8\\).\n\nEjercicio Considerad la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada al aire tantas veces como sea necesario hasta que salga una cara por primera vez, y contamos cuántas veces la hemos tenido que lanzar”.\n\n¿Cuál es su dominio?\n¿Cuál es su función de densidad?\n¿Cuál es su moda? ¿Qué significa?\n¿Cuál es su función de distribución?\n\n\n\n5.1.2 Esperanza\nCuando tomamos una muestra de una variable aleatoria \\(X\\) definida sobre una población, podemos calcular la media y la desviación típica de sus valores para obtener una idea de cuál es su valor central y de la variabilidad de sus valores. También nos podemos preguntar por este tipo de información para el total de la población: ¿cuál es el “valor medio” de \\(X\\) sobre toda la población? ¿\\(X\\) toma valores muy dispersos, o más bien concentrados alrededor de este valor medio? Lo primero lo medimos con la media, o esperanza, de \\(X\\), y lo segundo con su desviación típica. Empecemos con la primera.\nLa media, o esperanza (o valor esperado, valor medio, valor promedio…), de una variable aleatoria discreta \\(X\\) con densidad \\(f_X:D_X\\to  [0,1]\\) es \\[\nE(X)=\\sum_{x\\in D_X} x\\cdot f_X(x)\n\\] A veces también la denotaremos por \\(\\mu_X\\).\nLa interpretación natural de \\(E(X)\\) es que es la media de los valores de la variable \\(X\\) en el total de la población \\(\\Omega\\). En efecto, como \\(f_X(x)=P(X=x)\\) es la proporción de los sujetos de \\(\\Omega\\) en los que \\(X\\) vale \\(x\\), entonces \\[\nE(X)=\\sum_{x\\in D_X} x\\cdot f_X(x)\n\\] es el promedio del valor de \\(X\\) sobre todos los elementos de \\(\\Omega\\). Comparadlo con el ejemplo siguiente.\n\n\n\n\n\n\nNota\n\n\n\nSi, en una clase, un 10% de los estudiantes han sacado un 4 en un examen, un 20% un 6, un 50% un 8 y un 20% un 10, ¿cuál ha sido la nota media del examen?\n\n\nSuponemos que calcularíais esta media como \\[\n4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6\n\\] Pues este valor es la media de la variable aleatoria \\(X\\) “Tomo un estudiante de esta clase y miro qué nota ha sacado en este examen”: \\[\n\\begin{array}{rl}\nE(X)\\!\\!\\!\\!\\! &=4\\cdot P(X=4)+6\\cdot P(X=6)+8\\cdot P(X=8)+10\\cdot P(X=10)\\\\\n& = 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6\n\\end{array}\n\\]\nAparte de su interpretación como “el promedio de \\(X\\) en el total de la población”, \\(E(X)\\) es también el valor esperado de \\(X\\), en el sentido siguiente:\n\nSuponed que tomamos una muestra aleatoria de \\(n\\) sujetos de la población, medimos \\(X\\) sobre ellos y calculamos la media aritmética de los \\(n\\) valores obtenidos. Entonces, cuando el tamaño \\(n\\) de la muestra tiende a \\(\\infty\\), esta media aritmética tiende a valer \\(E(X)\\) “casi seguro” (en el sentido de que la probabilidad de que su límite sea \\(E(X)\\) es 1).\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nAquí probabilidad 1 no significa “total y absolutamente seguro”, porque este límite va a ser una variable aleatoria continua, donde, como veremos en la próxima lección, probabiilidad 0 no significa imposible ni probabilidad 1 significa 100% seguro. Por ejemplo, si repetís muchas veces el proceso de lanzar una moneda equilibrada 3 veces, por pura mala suerte puede pasar que en todas las ocasiones saquéis tres caras. Casi seguro que no pasa, pero no podemos estar 100% seguros de que no pase, no es imposible.\n\n\nEs decir: si midiéramos \\(X\\) sobre muchos sujetos elegidos al azar, de media casi seguro que obtendríamos un valor muy próximo a \\(E(X)\\).\nEjemplo:\n\nSeguimos con la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada al aire 3 veces y contamos las caras”. Su esperanza es \\[\nE(X)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2\\cdot \\frac{3}{8}+3\\cdot \\frac{1}{8}=1.5\n\\]\n\nEsto nos dice que:\n\nLa media de \\(X\\) es 1.5: El valor medio de la variable \\(X\\) sobre toda la población de secuencias de 3 lanzamientos de una moneda equilibrada es 1.5.\nEl valor esperado de \\(X\\) es 1.5: Si repitiésemos muchas veces el experimento de lanzar la moneda 3 veces y contar las caras, la media de los resultados obtenidos daría, muy probablemente, un valor muy cercano a 1.5. Abreviamos esto diciendo que si lanzamos la moneda 3 veces, de media esperamos sacar 1.5 caras.\n\nMás en general, si \\(g:\\mathbb{R}\\to  \\mathbb{R}\\) es una aplicación, el valor esperado de la composición \\(\\Omega \\stackrel{X}{\\longrightarrow} \\mathbb{R}\\stackrel{g}{\\longrightarrow}\\mathbb{R}\\) es \\[\nE(g(X))=\\sum_{x\\in D_X} g(x)\\cdot f_X(x)  \n\\] De nuevo, su interpretación natural es que es el promedio de \\(g(X)\\) sobre la población en la que medimos \\(X\\), y también es el valor “esperado” de \\(g(X)\\) en el sentido anterior.\nEjemplo:\n\nSi lanzamos una moneda equilibrada al aire 3 veces, contamos las caras y elevamos este número de caras al cuadrado, ¿qué valor esperamos obtener, de media? Será la esperanza de \\(X^2\\), siendo \\(X\\) la variable aleatoria “Lanzamos una moneda equilibrada al aire 3 veces y contamos las caras” (o sea, \\(X^2\\) es la variable aleatoria “Lanzamos una moneda equilibrada al aire 3 veces, contamos las caras y elevamos este número al cuadrado”):\n\\[\nE(X^2)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2^2\\cdot \\frac{3}{8}+3^2\\cdot \\frac{1}{8}=3\n\\]\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEn los dos últimos ejemplos hemos visto que si \\(X\\) es la variable aleatoria que cuenta el número de caras en 3 lanzamientos de una moneda equilibrada, \\(E(X^2)=3\\) pero \\(E(X)^2=1.5^2=2.25\\). Por lo tanto, puede pasar que \\(E(X^2) \\neq E(X)^2\\). De hecho, es lo más común.\nMás en general, dada una aplicación \\(g:\\mathbb{R}\\to  \\mathbb{R}\\), lo usual es que \\(E(g(X))\\neq g(E(X))\\).\n\n\nLa esperanza de las variables aleatorias discretas tiene las propiedades siguientes, todas razonables si las interpretáis en términos del valor promedio de \\(X\\) sobre la población:\n\nSea \\(b\\) una variable aleatoria constante, que sobre todos los individuos de la población toma el mismo valor \\(b\\in \\mathbb{R}\\). Entonces \\(E(b)=b\\).\nSi en una clase todo el mundo saca un 8 de un examen, la nota media es 8, ¿no?\nLa esperanza es lineal:\n\nSi \\(a,b\\in \\mathbb{R}\\), \\(E(aX+b)=aE(X)+b\\)\nSi en una clase la media de un examen ha sido un 6 y decidimos multiplicar por 1.2 todas las notas y sumarles 1 punto, la nueva nota media será 1.2·6+1=8.2, ¿no?\nSi \\(Y\\) es otra variable aleatoria, \\(E(X+Y)=E(X)+E(Y)\\).\nSi en una clase la media de la parte de cuestiones de un examen ha sido un 3.5 (sobre 5) y la de la parte de ejercicios ha sido un 3 (sobre 5) y la nota del examen es la suma sus dos partes, la nota media del examen será un 3.5+3=6.5, ¿no?\nMás en general, si \\(X_1,\\ldots,X_n\\) son variables aleatorias y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[\nE(a_1X_1+\\cdots +a_nX_n+b)=a_1E(X_1)+\\cdots +a_nE(X_n)+b\n\\]\n\nLa esperanza es monótona creciente: Si \\(X\\leqslant Y\\) (en el sentido de que, para cada sujeto de la población \\(\\Omega\\), su valor de \\(X\\) es menor o igual que su valor de \\(Y\\)), entonces \\(E(X)\\leqslant E(Y)\\).\nSi todos sacáis mejor nota de Anatomía que de Bioestadística, la nota media de Anatomía será mayor que la de Bioestadística, ¿no?\n\n\n\n5.1.3 Varianza y desviación típica\nLa varianza de una variable aleatoria discreta \\(X\\) es \\[\n\\sigma^2(X) =E((X-\\mu_X)^2) =\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x)\n\\] Es decir, es el valor medio del cuadrado de la diferencia entre \\(X\\) y su media \\(\\mu_X\\). También la denotaremos \\(\\sigma_X^2\\).\nFijaos en que se trata de la traducción “poblacional” de la definición de varianza para una muestra, y por lo tanto sirve para medir lo mismo que aquella: la dispersión de los resultados de \\(X\\) respecto de la media. Solo que ahora para toda la población.\nLa identidad siguiente os puede ser útil para calcular varianzas “a mano”. Ya vimos en la lección anterior esta igualdad para la varianza de una muestra.\n\n\n\n\n\n\nTip\n\n\n\n\\[\\sigma^2(X)=E(X^2)-\\mu_X^2\\].\n\n\nOperemos (y recordad que \\(E(X)=\\mu_X\\)) \\[\n\\begin{array}{rl}\n\\sigma^2(X)\\!\\!\\!\\!\\! & =E((X-\\mu_X)^2)=E(X^2-2\\mu_X\\cdot X+\\mu_X^2)\\\\\n& = E(X^2)-2\\mu_X\\cdot E(X)+\\mu_X^2\\\\\n& \\text{(por la linealidad de $E$)}\\\\\n& = E(X^2)-2\\mu_X^2+\\mu_X^2=E(X^2)-\\mu_X^2\n\\end{array}\n\\]\n:::{.callout note} En particular, si \\(X\\) no es una variable constante, \\(\\sigma^2(X)\\) es una suma de cuadrados, algunos de los cuales va a ser diferente de 0 y por lo tanto estrictamente positivo, en cuyo caso \\(E(X^2)-\\mu_X^2=\\sigma^2(X)&gt;0\\): el valor esperado de \\(X^2\\) es mayor que el cuadrado del valor esperado de \\(X\\). :::\nLa desviación típica (o desviación estándar) de una variable aleatoria discreta \\(X\\) es la raíz cuadrada positiva de su varianza: \\[\n\\sigma(X)=+\\sqrt{\\sigma^2(X)}\n\\] También mide la dispersión de los valores de \\(X\\) respecto de la media. La denotaremos a veces por \\(\\sigma_X\\).\nEl motivo para introducir la varianza y la desviación típica para medir la dispersión de los valores de \\(X\\) es la misma que en estadística descriptiva: la varianza es más fácil de manejar (no involucra raíces cuadradas) pero sus unidades son las de \\(X\\) al cuadrado, mientras que las unidades de la desviación típica son las de \\(X\\), y por lo tanto su valor es más fácil de interpretar.\nEjemplo:\n\nSeguimos con la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada 3 veces y contamos las caras”. Su varianza es:\n\\[\n\\begin{array}{rl}\n\\sigma^2(X) \\!\\!\\!\\!\\! & \\displaystyle=(0-1.5)^2\\cdot \\frac{1}{8}+(1-1.5)^2\\cdot \\frac{3}{8}\\\\ &\\displaystyle\\qquad +(2-1.5)^2\\cdot \\frac{3}{8}+(3-1.5)^2\\cdot \\frac{1}{8}=0.75\n\\end{array}\n\\] Si recordamos que \\(\\mu_X=E(X)=1.5\\) y \\(E(X^2)=3\\), podemos ver que \\[\nE(X^2)-\\mu_X^2=3-1.5^2=0.75=\\sigma^2(X)\n\\] Su desviación típica es \\[\n\\sigma(X) =\\sqrt{\\sigma^2(X)}=\\sqrt{0.75}= 0.866\n\\]\n\nVeamos algunas propiedades de la varianza y la desviación típica:\n\nSi \\(b\\) es una variable aleatoria constante que sobre todos los individuos de la población toma el valor \\(b\\in \\mathbb{R}\\), es decir, tal que \\(D_b=\\{b\\}\\), entonces \\(\\mu_b=b\\) y \\(\\sigma(b)^2=(b-b)f_b(b)=0\\)..\n\nUna variable aleatoria constante tiene cero dispersión, ¿no?\nEl recíproco también es cierto:\nSi \\(0=\\sigma^2(X)=\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x)\\), entonces todos los sumandos son 0, y como \\(f_X(x)\\neq 0\\) si \\(x\\in D_X\\), concluimos que, para todo \\(x\\in D_X\\), \\(x=\\mu_X\\): es decir, que el dominio está formado por un solo número y la variable aleatoria es constante.\n\n\\(\\sigma(aX+b)^2=a^2\\cdot \\sigma^2(X)\\).\n\nEn efecto \\[\n\\begin{array}{l}\n\\sigma(aX+b)^2 =E((aX+b)^2)-E(aX+b)^2\\\\\n\\quad = E(a^2X^2+2abX+b^2)-(aE(X)+b)^2\\\\\n\\quad \\text{(por la linealidad de $E$)}\\\\\n\\quad = a^2E(X^2)+2abE(X)+b^2-a^2E(X)^2-2abE(X)-b^2\\\\\n\\quad \\text{(de nuevo, por la linealidad de $E$)}\\\\\n\\quad = a^2(E(X^2)-E(X)^2)=a^2\\sigma^2(X)\n\\end{array}\n\\]\n\n\n\n\n\n\nNota\n\n\n\nSumar un valor constante \\(b\\) a una variable aleatoria no modifica su dispersión: si en un examen a todos los estudiantes les sumamos 1 punto, la media va a subir 1 punto pero la dispersión de las notas alrededor de esta media va a ser la misma que antes de sumarlo.\n\n\n\n\\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\) (recordad que la desviación típica es positiva y que \\(+\\sqrt{a^2}=|a|\\)).\nSi \\(X,Y\\) son variables aleatorias independientes, \\[\n\\sigma(X+Y)^2=\\sigma^2(X)+\\sigma(Y)^2\n\\] y por lo tanto \\[\n\\sigma(X+Y)=\\sqrt{\\sigma^2(X)+\\sigma(Y)^2}\n\\] Si no son independientes, en general esta igualdad es falsa. Por poner un ejemplo extremo, \\[\n\\sigma(X+X)^2=4\\sigma^2(X)\\neq \\sigma^2(X)+\\sigma^2(X).\n\\]\nMás en general, si \\(X_1,\\ldots,X_n\\) son variables aleatorias independientes y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[\n   \\sigma(a_1X_1+\\cdots +a_nX_n+b)^2=a_1^2\\sigma(X_1)^2+\\cdots +a_n^2\\sigma(X_n)^2\n    \\]\n\n\n\n5.1.4 Cuantiles\nSea \\(p\\) tal que \\(0&lt;p&lt;1\\). El cuantil de orden \\(p\\) (o \\(p\\)-cuantil) de una variable aleatoria \\(X\\) discreta es el menor valor \\(x_p\\) de su dominio \\(D_X\\) tal que \\(P(X\\leqslant x_p)\\geqslant p\\); es decir, es el valor \\(x_p\\in D_X\\) tal que \\(P(X\\leqslant x_p)\\geqslant p\\) pero \\(P(X&lt; x_p)&lt;p\\).\nPor ejemplo, que el 0.25-cuantil de una variable aleatoria discreta \\(X\\) sea, pongamos, 8, significa que 8 es el menor valor del dominio de \\(X\\) tal que su probabilidad acumulada llega a (o pasa de) 0.25. En otras palabras, que al menos una cuarta parte de la población tiene un valor de \\(X\\) menor o igual que 8, pero estrictamente menos de un 25% de la población tiene un valor de \\(X\\) estrictamente menor que 8.\n\n\n\n\n\n\nNota\n\n\n\nSi existe algún \\(x_p\\in D_X\\) tal que \\(F_X(x_p)(=P(X\\leqslant x_p))=p\\), entonces el \\(p\\)-cuantil es ese \\(x_p\\), porque si \\(x&lt;x_p\\), \\(P(X\\leqslant x)&lt;P(X\\leqslant x_p)=F_X(x_p)=p\\) y por lo tanto es el menor elemento del dominio con probabilidad acumulada al menos (en este caso, exactamente) \\(p\\).\n\n\nComo en estadística descriptiva, algunos cuantiles de variables aleatorias tienen nombres propios. Por ejemplo:\n\nLa mediana de \\(X\\) es su 0.5-cuantil\nEl primer y el tercer cuartiles de \\(X\\) son sus \\(0.25\\)-cuantil y \\(0.75\\)-cuantil, respectivamente.\nEtc.\n\nEjemplo:\n\nSeguimos con la variable aleatoria \\(X\\) “Lanzamos una moneda equilibrada 3 veces y contamos las caras”. Recordemos que su función de distribución es\n\\[\nF_X(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ si $x&lt;0$}\\\\\n0.125 & \\text{ si $0\\leqslant x&lt;1$}\\\\\n0.5 & \\text{ si $1\\leqslant x&lt;2$}\\\\\n0.875 & \\text{ si $2\\leqslant x&lt;3$}\\\\\n1 & \\text{ si $3\\leqslant x $}\n\\end{array}\n\\right.\n\\]\n\n\n\n\n\n\n\n\n\n\nEntonces, por ejemplo:\n\nSu 0.1-cuantil es 0\nSu 0.25-cuantil es 1\nSu mediana es 1\nSu 0.75-cuantil es 2\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nAunque usamos “media”, “varianza”, “cuantiles”, etc. tanto para muestras como para variables aleatorias, no debéis confundirlas.\n\nUna variable aleatoria representa una característica númerica de los sujetos de una población. Por ejemplo:\n\n“Tomamos un estudiante de farmacia y medimos su altura en m.”\nLa media y la varianza de esta variable son las de toda la población de estudiantes de farmacia.\n\nUna muestra de una variable aleatoria son los valores de la misma sobre un subconjunto (relativamente pequeño) de la población. Por ejemplo:\n\nMedimos las alturas (en m) de 50 estudiantes de farmacia de este curso.\nLa media y la varianza de esta muestra son solo las de esas 50 alturas.\n\n\n\n\nCuando queramos destacar que una media, una varianza etc. son las de una variable aleatoria y por lo tanto refieren a toda una población, los calificaremos de poblacionales.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "t5_variables_aleatorias.html#familias-importantes-de-variables-aleatorias-discretas",
    "href": "t5_variables_aleatorias.html#familias-importantes-de-variables-aleatorias-discretas",
    "title": "5  Variables aleatorias",
    "section": "5.2 Familias importantes de variables aleatorias discretas",
    "text": "5.2 Familias importantes de variables aleatorias discretas\nVamos a describir tres familias de variables aleatorias “distinguidas” que tenéis que conocer:\n\nBinomial\nHipergeométrica\nPoisson\n\nCada una de estas familias tienen un tipo específico de función de densidad, que depende de uno o varios parámetros.\nDe estas familias de variables tenéis que saber:\n\nDistinguirlas: saber cuando una variable aleatoria es de una de estas familias.\nSus propiedades más básicas, como por ejemplo cuáles son sus parámetros, cuál es su valor esperado y si su densidad es simétrica o presenta una cola a algún lado.\nUsar algún programa o alguna aplicación para calcular cosas con ellas cuando sea necesario.\n\n\n5.2.1 Variables aleatorias binomiales\nUn experimento de Bernoulli es una acción con solo dos posibles resultados, que identificamos con “Éxito” (\\(E\\)) y “Fracaso” (\\(F\\)). Por ejemplo, lanzar un dado cúbico y mirar si ha salido un 6 (\\(E\\): sacar un 6; \\(F\\): cualquier otro resultado). La probabilidad de éxito \\(p\\) de un experimento de Bernoulli es la probabilidad de obtener \\(E\\). Es decir, \\(P(E)=p\\). Naturalmente, entonces, \\(P(F)=1-p\\). En el ejemplo del dado, donde \\(E\\) es sacar un 6, \\(p=1/6\\).\nOtros ejemplos de experimentos de Bernoulli:\n\nLanzar una moneda equilibrada y mirar si da cara:\n\n\\(E\\): Sacar cara\n\\(p=1/2\\)\n\nRealizar un test PCR de COVID-19 a una persona y mirar si da positivo:\n\n\\(E\\): Dar positivo\n\\(p\\): La proporción de personas que dan positivo en el test (su tasa de positividad).\n\n\nUna variable aleatoria de Bernoulli de parámetro \\(p\\) (abreviadamente, \\(Be(p)\\)) es una variable aleatoria \\(X\\) consistente en efectuar un experimento de Bernoulli y dar 1 si se ha obtenido un éxito y 0 si se ha obtenido un fracaso.\nUna variable aleatoria binomial de parámetros \\(n\\) y \\(p\\) (abreviadamente, \\(B(n,p)\\)) es una variable aleatoria \\(X\\) que cuenta el número de éxitos \\(E\\) en una secuencia de \\(n\\) repeticiones independientes de un mismo experimento de Bernoulli de probabilidad de éxito \\(p\\). Independientes significa que las \\(n\\) variables aleatorias de Bernoulli, una para cada repetición del experimento de Bernoulli, son independientes; intuitivamente, que el resultado de cada repetición en la secuencia no depende de los resultados de las otras.\nLlamaremos a \\(n\\) el tamaño de las muestras y a \\(p\\) la probabilidad (poblacional) de éxito. A veces también diremos de una variable \\(X\\) de tipo \\(B(n,p)\\) que tiene distribución binomial de parámetros \\(n\\) y \\(p\\).\nPor ejemplo:\n\nUna variable de Bernoulli \\(Be(p)\\) es una variable binomial \\(B(1,p)\\).\nLanzar una moneda equilibrada 10 veces y contar las caras es una variable binomial \\(B(10,0.5)\\)\nElegir 20 personas al azar, una tras otra, permitiendo repeticiones y de manera independiente las unas de las otras, realizar sobre ellas un test PCR de COVID-19 y contar cuántos dan positivo, es una variable binomial \\(B(20,p)\\) con \\(p\\) la tasa de positividad del test.\n\nTenemos el resultado siguiente.\nTeorema: Si \\(X\\) es una variable \\(B(n,p)\\):\n\nSu dominio es \\(D_X=\\{0,1,\\ldots,n\\}\\)\nSu función de densidad es \\[\nf_X(k)=\\left\\{\\begin{array}{ll}\n\\displaystyle\\binom{n}{k}p^k(1-p)^{n-k} & \\text{ si $k\\in D_X$}\\\\\n0 & \\text{ si $k\\notin D_X$}\n\\end{array}\\right.\n\\]\nSu valor esperado es \\(E(X)=np\\)\nSu varianza es \\(\\sigma^2(X)=np(1-p)\\)\n\n\n\n\n\n\n\nImportante\n\n\n\nRecordad que:\n\nEl factorial \\(m!\\) de un número natural \\(m\\) se define como \\(m!=m(m-1)\\cdots 2\\cdot 1\\) si \\(m\\geqslant 1\\). Si \\(m=0\\), se toma \\(0!=1\\).\nEl número combinatorio \\(\\binom{n}{k}\\) se define como \\[\n\\binom{n}{k}=\\frac{\\overbrace{n\\cdot (n-1)\\cdots (n-k+1)}^k}{k\\cdot (k-1)\\cdots 2\\cdot 1}=\\frac{n!}{k!(n-k)!}\n\\] y nos da el número de subconjuntos de \\(k\\) elementos de \\(\\{1,\\ldots,n\\}\\).\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nSi lo pensáis, veréis que el valor de \\(E(X)\\) es el “esperado”. Si tomáis una muestra aleatoria de \\(n\\) sujetos de una población en la que la proporción de sujetos \\(E\\) es \\(p\\), ¿cuántos sujetos \\(E\\) “esperáis” obtener en vuestra muestra? Pues una fracción \\(p\\) de la muestra, es decir \\(p\\cdot n\\), ¿no?\n\n\nPara calcular el valor esperado y la varianza se suman \\[\n\\begin{array}{l}\n\\displaystyle E(X)=\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k}\\\\\n\\displaystyle \\sigma^2(X)=\\sum_{k=0}^n k^2\\cdot \\binom{n}{k}p^k(1-p)^{n-k}-\\Big(\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k}\\Big)^2\n\\end{array}\n\\] Os podéis fiar de nosotros, dan \\(np\\) y \\(np(1-p)\\), respectivamente.\nEl tipo de teorema anterior es el que hace que nos interese conocer algunas familias distinguidas frecuentes de variables aleatorias. Si, por ejemplo, reconocemos que una variable aleatoria es binomial y conocemos sus valores de \\(n\\) y \\(p\\) y sabemos el teorema anterior (o sabemos dónde consultarlo), automáticamente sabemos su función de densidad, y con ella su función de distribución, su valor esperado, su varianza etc., sin necesidad de deducir toda esta información cada vez que encontremos una variable de estas.\n\n\n\n\n\n\nNota\n\n\n\nEl conocimiento ahorra tiempo.\n\n\nConocer las propiedades de las variables aleatorias binomiales solo es útil si sabemos reconocer cuándo estamos ante una de ellas. Fijaos en que en una variable aleatoria binomial \\(B(n,p)\\):\n\nContamos cuántas veces ocurre un suceso (el éxito \\(E\\)) en una secuencia de intentos.\nEn cada intento, el suceso que nos interesa pasa o no pasa, sin términos medios.\nEl número de intentos es fijo, \\(n\\).\nCada intento es independiente de los otros.\nEn cada intento, la probabilidad de que pase el suceso que nos interesa es siempre la misma, \\(p\\).\n\nVeamos algunos gráficos de la función densidad de variables aleatorias binomiales. Primero, para \\(n=10\\) y diferentes valores de \\(p\\).\n\n\n\n\n\n\n\n\n\nAhora para \\(n=100\\):\n\n\n\n\n\n\n\n\n\nPodréis observar que si \\(p&lt;0.5\\), la distribución \\(B(n,p)\\) presenta una cola a la derecha, y si \\(p&gt;0.5\\), la cola es a la izquierda. Es razonable. Por ejemplo, si \\(p&lt;0.5\\), el valor esperado será \\(pn&lt;n/2\\) y hay más valores posibles a la derecha de \\(pn\\) que a su izquierda (porque una binomial \\(B(n,p)\\) puede llegar a tomar el valor \\(n\\), pero no puede tomar valores negativos).\nSi \\(p=0.5\\), es simétrica: como \\(E\\) y \\(F\\) tienen la misma probabilidad, 0.5, la probabilidad de sacar \\(k\\) \\(E\\)’s es la misma que la de sacar \\(k\\) \\(F\\)’s, es decir, la de sacar \\(n-k\\) \\(E\\)’s.\n\n\n\n\n\n\n\n\n\n\n¿Cómo efectuar cálculos con una variable aleatoria de una familia dada?\nUna posibilidad es usar una aplicación de móvil o tablet. Nuestra favorita es Probability distributions, disponible tanto para Android como para iOS.\n\nOtra posibilidad es usar JAMOVI. El módulo distrACTION permite calcular probabilidades y cuantiles de todas las distribuciones que usaremos en este curso salvo una, la hipergeométrica. Ya hablaremos de ella en la próxima sección.\n\nPor ejemplo:\n\nSi lanzamos 20 veces un dado equilibrado (de 6 caras), ¿cuál es la probabilidad de sacar exactamente 5 unos?\nSi llamamos \\(X\\) a la variable aleatoria que cuenta el número de unos en secuencias de 20 lanzamientos de un dado equilibrado, se trata de una variable binomial \\(B(20,1/6)=B(20,0.166667)\\). Nos piden \\(P(X=5)\\). Da 0.129:\n\n\n\nSi lanzamos 20 veces un dado equilibrado, ¿cuál es la probabilidad de sacar como máximo 5 unos?\nCon las notaciones anteriores, nos piden \\(P(X\\leqslant 5)\\). Da 0.898:\n\n\n\nSi lanzamos 20 veces un dado equilibrado, ¿cuál es la probabilidad de sacar menos de 5 unos?\nCon las notaciones anteriores, nos piden \\(P(X&lt; 5)\\), es decir, \\(P(X\\leqslant 4)\\). Da 0.769:\n\n\n\nSi lanzamos 20 veces un dado equilibrado, ¿cuál es el menor número \\(N\\) de unos para el que la probabilidad de sacar como máximo \\(N\\) unos llega al 25%?\nNos piden el menor valor \\(N\\) tal que \\(P(X\\leqslant N)\\geqslant 0.25\\), y esto por definición es el 0.25-cuantil de \\(X\\). Da 2:\n\n\nPodéis comprobar que en efecto \\(N=2\\) cumple lo pedido: si las calculáis, veréis que la probabilidad de sacar como máximo 2 unos es \\(P(X\\leqslant 2)=0.329\\) y la probabilidad de sacar como máximo 1 uno es \\(P(X\\leqslant 1)=0.13\\). Por lo tanto, con 1 uno no llegamos al 25% de probabilidad y con 2 sí.\n\n\n\n5.2.2 Variables aleatorias hipergeométricas\nRecordad que el paradigma de variable aleatoria binomial es: tengo una población con una proporción \\(p\\) de sujetos que satisfacen una condición \\(E\\), tomo una muestra aleatoria simple de tamaño \\(n\\) y cuento el número de sujetos \\(E\\) en mi muestra. Si cambiamos “muestra aleatoria simple” por “muestra aleatoria sin reposición”, la distribución de la variable aleatoria que obtenemos es otra: la hipergeométrica.\nUna variable aleatoria hipergeométrica (o tiene distribución hipergeométrica) de parámetros \\(K\\), \\(M\\) y \\(n\\) (para abreviar, \\(H(K,M,n)\\)) es cualquier variable aleatoria \\(X\\) que podáis identificar con el proceso siguiente: Tenemos una población formada por \\(K\\) sujetos que satisfacen una condición \\(E\\) y \\(M\\) sujetos que no la satisfacen (por lo tanto, en total, \\(K+M=N\\) sujetos en la población), tomamos una muestra aleatoria sin reposición de tamaño \\(n\\) y contamos el número de sujetos \\(E\\) en esta muestra.\nLlamaremos a \\(K\\) el número poblacional de éxitos, a \\(M\\) el número poblacional de fracasos y a \\(n\\) el tamaño de las muestras. Fijaos entonces que \\(K+M=N\\) es el tamaño total de la población y que \\(K/(K+M)\\) es la probabilidad poblacional de éxito (la fracción de sujetos que satisfacen \\(E\\) en el total de la población), que llamaremos \\(p\\).\nEjemplo:\n\nEn una aula hay 5 chicos y 45 chicas. Escogemos 10 estudiantes, uno tras otro y sin repetirlos, para hacerles una pregunta. Contamos cuántos chicos hemos interrogado. Se trata de una variable hipergeométrica \\(H(5,45,10)\\).\n\nTeorema: Si \\(X\\) es una variable \\(H(K,M,n)\\):\n\nSu dominio es \\(D_X=\\{0,1,\\ldots,\\text{min}(N,n)\\}\\)\nSu función de densidad es \\[\nf_X(k)=\\left\\{\\begin{array}{ll}\n\\displaystyle\\dfrac{\\binom{K}{k}\\cdot \\binom{M}{n-k}}{\\binom{N}{n}} & \\text{ si $k\\in D_X$}\\\\\n0 & \\text{ si $k\\notin D_X$}\n\\end{array}\\right.\n\\]\nSu valor esperado es \\(E(X)=\\dfrac{nK}{N}\\)\nSu varianza es \\(\\sigma^2(X)=\\dfrac{nKM(N-n)}{N^2(N-1)}\\)\n\nFijaos en que si llamamos \\(p\\) a la probabilidad poblacional de éxito, \\(p=K/N\\), entonces \\[\nE(X)=np.\n\\] Es la misma fórmula que para las variables binomiales \\(B(n,p)\\) (y si lo pensáis un rato veréis que, de nuevo y por el mismo argumento, es lo razonable). Por otro lado, \\[\n\\sigma^2(X)=n\\cdot\\dfrac{K}{N}\\cdot\\dfrac{M}{N}\\cdot\\frac{N-n}{N-1}=np(1-p)\\cdot\\dfrac{\\mathbf{N}-n}{\\mathbf{N}-1}\n\\] que es la varianza de una variable \\(B(n,p)\\) multiplicada por un factor de corrección debido a que ahora tomamos muestras sin repeticiones, lo que hace que la dispersión de resultados sea más pequeña que si permitiéramos repeticiones (yendo a un caso extremo, de tamaño \\(N\\) hay una sola muestra posible sin repetición, pero muchísimas si permitimos repeticiones). A la raíz cuadrada de este factor, \\[\n\\sqrt{\\dfrac{N-n}{N-1}}\n\\] se la llama factor (corrector) de población finita.\nFijaos en que si \\(N\\) es muchísimo mayor que \\(n\\), tendremos que \\(N-n \\approx N-1\\) y por lo tanto \\((N-n)/(N-1)\\approx 1\\) y la varianza de la hipergeométrica será aproximadamente la de la binomial. Esto es consistente con lo que ya hemos comentado varias veces: si la población es mucho mayor que la muestra, tomar las muestras con o sin reposición no afecta demasiado a las muestra obtenidas, por lo que la distribución de probabilidad ha de ser muy parecida. Recordad los ejemplos siguientes:\n\nEn España hay 46,700,000 personas, de las cuales un 11.7% son diabéticos. Escogemos 100 españoles y contamos cuántos son diabéticos.\nEsta variable es, en realidad, hipergeométrica con \\(K=0.117\\cdot 46700000=5463900\\), \\(M=46700000-N=41236100\\) y \\(n=100\\), pero en la práctica la consideramos binomial \\(B(100,0.117)\\). El factor de población finita es \\[\n\\frac{46700000-100}{46700000-1}=0.9999979\n\\]\n\n\n\n\n\n\n\nNota\n\n\n\nHay otro motivo para considerarla binomial en este ejemplo, y es que, en realidad, no sabemos los valores exactos de \\(K\\) y \\(M\\). Estamos seguros de que no es verdad que el tamaño de la población española sea exactamente de 46,700,000 personas, tan redondo, ni que los diabéticos representen exactamente un 11.7%, sin más cifras decimales. Así que ya puestos a aproximar, tomamos la aproximación binomial, que es más sencilla.\nPero cuidado: si la muestra fuera, pongamos, de 10,000 personas, entonces la aproximación binomial sería teóricamente incorrecta, aunque el factor corrector de población finita es de 0.999786: de media, un poco menos de 2 de cada 3 muestras aleatorias simples de 10,000 personas tomadas de una población de 46,700,000 personas contienes alguna repetición, como muestra el cálculo siguiente.\n\n\nPara hacer cálculos de la hipergeométrica en Jamovi:\nEjemplo:\n\nEn una clase de 50 estudiantes, 5 son hombres (y 45 mujeres). Escogemos una muestra aleatoria sin reposiciòn de 10 estudiantes. ¿Cuál es la probabilidad de que exactamente dos de los estudiantes elegidos sean hombres?\n\nLa variable \\(X\\) que cuenta el número de hombres en estas muestras es hipergeométrica \\(H(5,45,10)\\). Nos piden \\(P(X=2)\\), y esta probabilidad nos la da la función de densidad de \\(X\\). Es \\(f_X(2)\\):\n\ndhyper(2,5,45,10)\n\n[1] 0.2098397\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nFijaos en el orden de los argumentos de la función entre los paréntesis. Para calcular \\(f_X(x)\\), aplicamos dhyper a \\((x,K,M,n)\\).\n\n\nEn la situación anterior, ¿cuál es la probabilidad de la muestra contenga como máximo 2 hombres?, ¿cuál es la probabilidad de la muestra contenga al menos 2 hombres?\n\n\n5.2.3 Variables aleatorias de Poisson\nUna variable aleatoria \\(X\\) es de Poisson (o tiene distribución de Poisson) con parámetro \\(\\lambda&gt;0\\) (para abreviar, \\(Po(\\lambda)\\)) cuando:\n\nSu dominio es \\(D_X=\\mathbb{N}\\), el conjunto de todos los números naturales (es decir, teóricamente puede tomar como valor cualquier número natural).\nSu función de densidad es \\[\nf_X(k)=\\left\\{\\begin{array}{ll}\ne^{-\\lambda}\\cdot \\dfrac{\\lambda^k}{k!} &  \\text{ si $k\\in \\mathbb{N}$}\\\\\n0 & \\text{ si $k\\notin \\mathbb{N}$}\n\\end{array}\\right.\n\\]\n\nTeorema: Si \\(X\\) es una variable \\(Po(\\lambda)\\), entonces \\(E(X)= \\sigma^2(X)= \\lambda\\).\nEs decir, el “parámetro” \\(\\lambda\\) de una variable de Poisson es su valor esperado, y coincide con su varianza.\nLa familia de Poisson incluye un tipo de variables aleatorias muy común en epidemiología.\nSupongamos que tenemos un tipo de objetos o acontecimientos que pueden darse en una región continua de tiempo o espacio. Por ejemplo, defunciones de personas por una determinada enfermedad en el curso del tiempo, casos de un tipo de cáncer en diferentes zonas geográficas de un país, o bacterias en una superficie. Para simplificar el lenguaje, vamos a suponer que observamos apariciones de objetos en el tiempo.\nSi las apariciones de estos objetos satisfacen las propiedades siguientes:\n\nLas apariciones de los objetos son aleatorias: en cada instante, un objeto se da, o no, al azar, con una probabilidad fija y constante\nLas apariciones de los objetos son independientes: que se dé un objeto en un instante concreto, no depende para nada de que se haya dado o no un objeto en otro instante\nLas apariciones de los objetos no son simultáneas: es prácticamente imposible que dos objetos de estos se den en el mismo instante exacto, medido con precisión infinita\n\nentonces, la variable \\(X_t\\) que toma un intervalo de tiempo de duración \\(t\\) y cuenta el número de objetos que se dan en él es de Poisson: \\(Po(\\lambda_t)\\), con \\(\\lambda_t\\) el número esperado de objetos en este intervalo de tiempo (es decir, el número medio de objetos en intervalos de tiempo de este tamaño).\nPor ejemplo, cuando lo que cuentan ocurre al azar, son variables de Poisson:\n\nEl número de enfermos admitidos en urgencias en un día (o en 12 horas, o en una semana…)\nEl número de defunciones por una enfermedad concreta en un día (o en una semana, o en un año…)\nEl número de bacterias en un cuadrado de 1 cm de lado (o de 1 m de lado…)\n\n\n\n\n\n\n\nNota\n\n\n\nMás en concreto, si \\(X\\) es una variable binomial \\(B(n,p)\\) con \\(n\\) MUY grande y \\(p\\) MUY pequeño, entonces \\(X\\) es aproximadamente \\(Po(\\lambda)\\) con \\(\\lambda=p\\cdot n\\). Aquí \\(n\\) es, para entendernos, el número de instantes en un día, o el número de puntos del cuadrado de 1 cm de lado: MUY grande.\nPara que os hagáis una idea, la instrucción siguiente calcula el máximo (max) de los valores absolutos (abs) de las diferencias entre la densidad de una \\(B(10^6,10^{-5})\\) y una \\(Po(10)\\): esta diferencia máxima es del orden de 0.0000006.\n\n\n\nmax(abs(dbinom(0:10^6,10^6,10^-5)-dpois(0:10^6,10)))\n\n[1] 6.255548e-07\n\n\nPodemos aplicar esta información de dos maneras:\n\nSi sabemos que una variable es (aproximadamente) de Poisson, conocemos su densidad y por lo tanto podemos calcular lo que queramos para ella.\nSi los datos que observamos tocarían seguir una distribución de Poisson pero parece que no (por ejemplo, porque su varianza sea muy diferente de su media, tan diferente que sea difícil de creer que la media y la varianza poblacionales sean iguales), entonces es señal de que algo “raro” está pasando en realidad.\n\nEjemplo:\n\nObservad la diferencia entre las dos variables siguientes:\n\nNúmero semanal de defunciones por un tipo de cáncer en un país. El momento exacto de las defunciones se produce al azar, podemos entender que no se dan dos defunciones exactamente en el mismo instante, con precisión infinita, y las defunciones se producen de manera independiente. Es de Poisson.\nNúmero semanal de defunciones en accidentes de tráfico en un país. De nuevo, el momento exacto de las defunciones se produce al azar y podemos entender que no se dan dos defunciones exactamente en el mismo instante, con precisión infinita. Pero las muertes en accidentes de tráfico no son independientes: en un mismo accidente mortal se pueden producir varias muertes casi simultáneas. No es buena idea modelarla mediante una distribución de Poisson. En cambio, el número de accidentes de tráfico sí.\n\n\n\n\n\n\n\n\nNota\n\n\n\nComo las apariciones de los objetos que cuenta una variable de Poisson son aleatorias e independientes, el número medio de objetos es lineal en el tamaño de la región. Es decir, por ejemplo, en un intervalo de dos días esperamos ver el doble de objetos que en un día. O por ejemplo, si se diagnostican de media 32,240 casos de cáncer de colon anuales en España (y siguen una ley de Poisson), esperamos que de media se diagnostiquen 32240/52=620 casos semanales.\n\n\nVeamos algunos gráficos de funciones de densidad de variables de Poisson.\n\n\n\n\n\n\n\n\n\nComo podéis ver, la densidad de una variable de Poisson es asimétrica, con un máximo alrededor de \\(\\lambda\\) y una cola a la derecha, pero a medida que \\(\\lambda\\) crece, la asimetría se va atenuando.\nEjemplo:\n\nLa incidencia anual de un cierto accidente laboral sigue una distribución de Poisson. A lo largo del tiempo se ha observado que el 55% de los años no se produce ningún accidente. ¿Cuántos accidentes esperas que ocurran en un año?\n\nSea \\(X\\) la variable que cuenta estos accidentes laborales anuales. Nos dicen que es \\(Po(\\lambda)\\), donde \\(\\lambda\\) es su valor esperado, y por lo tanto lo que nos piden. Nos dicen también que \\(P(X=0)=0.55\\). Por la fórmula de la densidad de una variable de Poisson: \\[\n0.55=e^{-\\lambda}\\cdot \\dfrac{\\lambda^0}{0!}=e^{-\\lambda}\\Longrightarrow\n\\lambda=-\\ln(0.55)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "t5_variables_aleatorias.html#variables-aleatorias-continuas",
    "href": "t5_variables_aleatorias.html#variables-aleatorias-continuas",
    "title": "5  Variables aleatorias",
    "section": "5.3 Variables aleatorias continuas",
    "text": "5.3 Variables aleatorias continuas\nRecordad que una variable aleatoria continua toma valores continuos. Por ejemplo:\n\nPeso de una persona\nNivel de colesterol en sangre\nDiámetro de un tumor\n\nEn este curso vamos a restringirnos a variables aleatorias continuas \\(X: \\Omega\\to \\mathbb{R}\\) que cumplen la siguiente propiedad extra: su función de distribución \\[\n\\begin{array}{rcl}\nF_X: \\mathbb{R} & \\to & [0,1]\\\\\nx &\\mapsto &P(X\\leqslant x)\n\\end{array}\n\\] es continua. Todas las variables aleatorias continuas que os puedan interesar en algún momento van a tener esta propiedad, así que no perdemos nada imponiéndola. ¿Y qué ganamos? Pues que podemos usar todas las técnicas matemáticas aplicables a funciones continuas para estudiar \\(F_X\\).\nPor ejemplo, nuestras variables continuas verifican la propiedad siguientes:\nTeorema: Si \\(X\\) es una variable aleatoria continua, la probabilidad de que tome un valor concreto siempre es 0: \\[\nP(X=a)=0 \\text{ para todo $a\\in \\mathbb{R}$}.\n\\]\nPor si pasa por aquí alguien que necesite una demostración: \\[\n\\begin{array}{l}\n\\displaystyle P(X=a) = P(X\\leqslant a)-P(X&lt;a)=P(X\\leqslant a)-P\\Big(\\bigcup_{n\\geqslant 1} \\Big(X\\leqslant a-\\frac{1}{n}\\Big)\\Big)\\\\\n\\displaystyle \\qquad= P(X\\leqslant a)-\\lim_{n\\geqslant 1}P\\Big(X\\leqslant a-\\frac{1}{n}\\Big)\\\\\n\\displaystyle \\qquad= F_X(a)-\\lim_{n\\geqslant 1}F_X\\Big(a-\\frac{1}{n}\\Big)=0\n\\end{array}\n\\] porque \\(F_X\\) es continua.\nEn particular, para una variable aleatoria continua:\n\nProbabilidad 0 no significa imposible.\n\nCada valor de \\(X\\) tiene probabilidad 0, pero cuando tomamos un sujeto, tendrá algún valor de \\(X\\), ¿no?. Por lo tanto, su valor de \\(X\\) es posible, aunque tenga probabilidad 0.\nDe \\(P(X=a)=0\\) se deduce que la probabilidad de un suceso definido con una desigualdad es la misma que la del suceso correspondiente definido con una desigualdad estricta. Por ejemplo, y contrariamente a lo que pasaba en las variables aleatorias discretas, para una variable aleatoria continua siempre tenemos que \\[\nP(X\\leqslant a)=P(X&lt;a)\n\\] porque \\[\nP(X\\leqslant a)=P(X&lt;a)+P(X=a)=P(X&lt;a)+0=P(X&lt;a).\n\\]\nDe manera similar:\n\n\\(P(X\\geqslant a)=P(X&gt; a)+P(X=a)=P(X&gt; a)\\)\n\\(P(a\\leqslant X\\leqslant b)=P(a&lt;X&lt;b)+P(X=a)+P(X=b)\\) \\(=P(a&lt;X&lt;b)\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "t5_variables_aleatorias.html#densidad-y-distribución-1",
    "href": "t5_variables_aleatorias.html#densidad-y-distribución-1",
    "title": "5  Variables aleatorias",
    "section": "5.4 Densidad y distribución",
    "text": "5.4 Densidad y distribución\nSea \\(X\\) una variable aleatoria continua. Como ya hemos dicho, su función de distribución \\(F_X\\) se sigue definiendo como \\[\nx\\mapsto F_X(x)=P(X\\leqslant x)\n\\] recordando además que, ahora, también \\[\nF_X(x)=P(X&lt; x)\n\\]\nPero puesto que tenemos que \\(P(X=x)=0\\), ahora no podemos definir la función de densidad de \\(X\\) como \\(f_X(x)=P(X=x)\\). ¿Qué podemos hacer?\nRecordad que, en las variables aleatorias discretas \\[\nF_X(a)=\\sum_{x\\leqslant a} f_X(x)\n\\]\nEn el contexto de matemáticas “continuas”, la suma \\(\\sum\\) se traduce en la integral \\(\\int\\). Se define entonces la función de densidad de una variable aleatoria continua \\(X\\) como la función \\(f_X:\\mathbb{R}\\to \\mathbb{R}\\) tal que:\n\n\\(f_X(x)\\geqslant 0\\), para todo \\(x\\in \\mathbb{R}\\)\n\\(\\displaystyle F_X(a)=\\int_{-\\infty}^a f_{X}(x)\\, dx\\) para todo \\(a\\in \\mathbb{R}\\).\n\n\n\n\n\nRecordad (o aprended por primera vez) que la integral tiene una interpretación sencilla en términos de áreas. En concreto, dados \\(a\\in \\mathbb{R}\\) y una función \\(f(x)\\), la integral \\[\n\\int_{-\\infty}^a f(x)\\, dx\n\\] es igual al área de la región a la izquierda de la recta vertical \\(x=a\\) comprendida entre la curva \\(y=f(x)\\) y el eje de abscisas \\(y=0\\). Por lo tanto, la función de densidad \\(f_X\\) de \\(X\\) es la función positiva tal que para todo \\(a\\in \\mathbb{R}\\), \\(F_X(a)\\) es igual al área bajo la curva \\(y=f_X(x)\\) (entre esta curva y el eje de abscisas) a la izquierda de \\(x=a\\).\n\n\n\n¿Cuál es la idea intuitiva que hay detrás de esta definición de densidad? Suponed que dibujamos histogramas de frecuencias relativas de los valores de \\(X\\) sobre toda la población. Como estamos hablando de toda la población, la frecuencia relativa de cada clase es la proporción de individuos de la población cuyo valor de \\(X\\) pertenece a esta clase: es decir, la probabilidad de que \\(X\\) caiga dentro de la clase.\nRecordad que, en un histograma de frecuencias relativas:\n\nLa frecuencia relativa (ahora, la probabilidad) de cada clase es el área de su barra, es decir, el ancho de la clase por la altura de la barra.\nLlamamos a la altura de una barra la densidad de la clase.\nSi \\(a\\) es un extremo de una clase, la frecuencia relativa acumulada (la probabilidad) de que \\(X&lt;a\\) es la suma de las áreas de las barras a la izquierda de \\(a\\).\n\nSi dibujamos los histogramas de \\(X\\) tomando clases cada vez más estrechas, sus polígonos de frecuencias (en rojo) tienden a dibujar una curva:\n\n\n\n\n\n\n\n\n\nCuando el ancho de las clases tiende a 0, obtenemos una curva que es el límite de estos polígonos de frecuencias:\n\n\n\n\n\n\n\n\n\nEn el límite, la probabilidad de que \\(X&lt; a\\) (o sea, de que \\(X\\leqslant a\\)) será el límite de las sumas de las áreas de las barras a la izquierda de \\(a\\), y por tanto el área a la izquierda de \\(a\\) bajo esta curva límite. Esto nos dice que esta curva es precisamente la función de densidad \\(y=f_X(x)\\).\n\n\n\n\n\n\nImportante\n\n\n\nLa función de densidad \\(f_X\\) de una variable aleatoria continua \\(X\\) es la función límite de los polígonos de frecuencias de histogramas de \\(X\\) cuando el ancho de las clases tiende a 0.\n\n\nVeamos algunas propiedades que se deducen de que \\(F_X(a)=P(X\\leqslant a)\\) sea igual al área bajo la curva \\(y=f_X(x)\\) a la izquierda de \\(x=a\\):\n\nComo \\(P(X&lt;\\infty)=P(\\Omega)=1\\), el área total bajo la curva \\(y=f_X(x)\\) es 1.\n\n\n\n\n\n\n\n\n\n\n\n\\(P(a\\leqslant X\\leqslant b)=P(X\\leqslant b)-P(X&lt;a)\\) es el área bajo la curva \\(y=f_X(x)\\) a la izquierda de \\(x=b\\) menos el área bajo la curva \\(y=f_X(x)\\) a la izquierda de \\(x=a\\), es decir, \\(P(a\\leqslant X\\leqslant b)\\) es igual al área bajo la curva \\(y=f_X(x)\\) entre \\(x=a\\) y \\(x=b\\).\n\n\n\nSi \\(\\varepsilon&gt;0\\) es muy, muy pequeño, el área bajo \\(y=f_X(x)\\) entre \\(a-\\varepsilon\\) y \\(a+\\varepsilon\\) es aproximadamente igual a la del rectángulo de base el intervalo \\([a-\\varepsilon,a+\\varepsilon]\\) y altura \\(f_X(a)\\), que vale \\(2\\varepsilon\\cdot f_X(a)\\) (ved la Figura @ref(fig:epsilon)). Es decir, \\[\nP(a-\\varepsilon\\leqslant X\\leqslant a+\\varepsilon)\\approx 2\\varepsilon\\cdot f_X(a).\n\\]\n\nPor lo tanto \\(f_X(a)\\) nos da una indicación de la probabilidad de que \\(X\\) valga aproximadamente \\(a\\) (pero no es \\(P(X=a)\\), que vale 0). Es decir, por ejemplo, si \\(f_X(a)=0.1\\) y \\(f_X(b)=0.5\\), la probabilidad de que \\(X\\) tome un valor muy cercano a \\(b\\) es 5 veces mayor que la probabilidad de que tome un valor muy cercano a \\(a\\).\n\n\n\n\n\n\nAdvertencia\n\n\n\nPero \\(P(X=a)=P(X=b)=0\\), así que, por favor, evitad decir que “la probabilidad de que \\(X\\) valga \\(b\\) es 5 veces mayor que la probabilidad de que valga \\(a\\)”. Sí, ya sabemos que \\(5\\cdot 0=0\\), pero la frase es engañosa.\n\n\nUnas consideraciones finales:\n\nLo hemos dicho en la definición, y lo hemos usado implícitamente en toda la sección, pero lo volvemos a repetir: \\(f_X(x)\\geqslant 0\\) para todo \\(x\\in \\mathbb{R}\\).\n\\(f_X(x)\\) no es una probabilidad, y por lo tanto puede ser mayor que 1. Por ejemplo, el gráfico siguiente muestra la densidad de una variable normal \\(N(0,0.01)\\), que llega a valer casi 40. Pero el área bajo toda la curva densidad es 1: a partir de \\(\\pm 0.06\\) la densidad vale prácticamente 0.\n\n\n\nLa función de densidad \\(f_X\\) no tiene por qué ser continua, aunque la función de distribución \\(F_X\\) lo sea.\n\nEjemplo:\n\nSea \\(X\\) una variable aleatoria continua con función de distribución \\[\nF_X(x)=P(X\\leqslant x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ si $x\\leqslant 0$}\\\\\nx &  \\text{ si $x\\in [0,1]$}\\\\\n1 &  \\text{ si $x\\geqslant 1$}\n\\end{array}\\right.\n\\]\n\n\n\n\n\n\n\n\n\nSu función de densidad es \\[\nf_X(x)\\left\\{\n\\begin{array}{ll}\n0 & \\text{ si $x&lt; 0$}\\\\\n1 &  \\text{ si $x\\in [0,1]$}\\\\\n0 &  \\text{ si $x&gt; 1$}\n\\end{array}\\right.\n\\] porque la integral de \\(-\\infty\\) hasta \\(a\\) de esta función es (calculadlo como áreas si os cuesta recordar cómo calcular integrales definidas) \\[\n\\int_{-\\infty}^a  f_X(x)\\,dx=\\left\\{\n  \\begin{array}{ll}\n\\int_{-\\infty}^a  0\\,dx =0 & \\text{ si $a&lt; 0$}\\\\\n\\int_{-\\infty}^0  0\\,dx+ \\int_{0}^a  1\\,dx=0 + a=a &  \\text{ si $a\\in [0,1]$}\\\\\n\\int_{-\\infty}^0  0\\,dx+ \\int_{0}^1  1\\,dx+ \\int_{1}^a  0\\,dx=0 + 1+0=1 &  \\text{ si $x&gt; 1$}\n\\end{array}\\right.\n\\]\n\n\n\n\n\n\n\n\n\nObservad que \\(f_X(x)\\) es discontinua, con saltos en 0 y 1. Esta densidad representa que \\(X\\) solo puede tomar valores entre 0 y 1 y que entre estos dos valores los toma todos “con la misma probabilidad”. Diremos que \\(X\\) tiene distribución uniforme entre 0 y 1.\n\nEjercicio: Más en general, una variable con distribución uniforme entre \\(a\\) y \\(b\\) (con \\(a&lt;b\\)) solo puede tomar valores entre \\(a\\) y \\(b\\) y entre estos dos valores los toma todos “con la misma probabilidad”. ¿Cuál sería su densidad? ¿Cuál sería su distribución? Comprobad que el área bajo la curva de la densidad que hayáis dado es la distribución que hayáis dado.\n\n5.4.1 Esperanza, varianza, cuantiles…\nLa esperanza y la varianza de una variable aleatoria continua \\(X\\), con función de densidad \\(f_X\\), se definen como en el caso discreto, substituyendo la suma \\(\\sum_{x\\in D_x}\\) por una integral \\(\\int_{-\\infty}^{\\infty}\\).\nLa media, o esperanza (valor medio, valor esperado…), de \\(X\\) es \\[\nE(X)=\\int_{-\\infty}^{\\infty}x \\cdot f_{X}(x)\\, dx\n\\] Es decir, es el área comprendida entre el eje de abscisas y la curva \\(y=xf_X(x)\\). Como en el caso discreto, también la denotaremos a veces por \\(\\mu_X\\).\nEste valor tiene la misma interpretación que en el caso discreto:\n\nRepresenta el valor medio de \\(X\\) sobre el total de la población.\nEs (con probabilidad 1) el límite de la media aritmética de los valores de \\(X\\) sobre muestras aleatorias simples de tamaño \\(n\\), cuando \\(n\\to \\infty\\).\n\nEjemplo:\n\nVolvamos a la variable aleatoria \\(X\\) con distribución uniforme entre 0 y 1 del Ejemplo @ref(exm:unif), que toma todos los valores entre 0 y 1 con la misma probabilidad. ¿Cuál tendría que ser su valor medio? El valor medio del intervalo, 1/2, ¿no?. Veamos: como \\(f_X(x)=1\\) entre 0 y 1 y \\(f_X(x)=0\\) fuera de este intervalo, \\[\n\\int_{-\\infty}^{\\infty}x \\cdot f_{X}(x)\\, dx  =\\int_{0}^1 x\\,dx=\\left[\\frac{x^2}{2}\\right]^1_0=\\frac{1}{2}-0=\\frac{1}{2}\n\\] Nuestra intuición era correcta.\n\n\n\n\nSi os da pereza calcular la integral del ejemplo anterior, fijaos en que el área bajo la curva \\(y=x\\) entre 0 y 1 es la del triángulo de base (0,0)-(1,0) y altura (1,0)-(1,1), que es la mitad del cuadrado unidad y por lo tanto su área es 1/2\n\n\nSi \\(g:\\mathbb{R}\\to \\mathbb{R}\\) es una función continua, la esperanza de la composición \\(\\Omega \\stackrel{X}{\\longrightarrow} \\mathbb{R}\\stackrel{g}{\\longrightarrow}\\mathbb{R}\\) es \\[\nE(g(X))=\\int_{-\\infty}^{+\\infty} g(x) \\cdot f_X(x)dx\n\\]\nLa varianza de \\(X\\) es \\[\n\\sigma^2(X)=E((X-\\mu_X)^2)\n\\] y se puede demostrar que es igual a \\[\n\\sigma^2(X)=E(X^2)-\\mu_X^2\n\\] También se escribe \\(\\sigma_X^2\\).\nLa desviación típica de \\(X\\) es \\[\n\\sigma(X)=+\\sqrt{\\sigma^2(X)}\n\\] y también se escribe \\(\\sigma_X\\).\nComo en el caso discreto, la varianza y la desviación típica miden la variabilidad de los resultados de \\(X\\) respecto de su valor medio.\nEstos parámetros de \\(X\\) tienen las mismas propiedades en el caso continuo que en el discreto. Las recordamos:\n\nSi \\(b\\) es una variable aleatoria constante, \\(E(b)=b\\) y \\(\\sigma(b)^2=0\\).\nSi \\(\\sigma^2X)=0\\), \\(X\\) es constante.\n\n\n\n\n\n\n\nNota\n\n\n\nY por supuesto, si \\(X\\) solo puede tomar un valor, ya no es continua, sino discreta. Por lo tanto, por convenio, de ahora en adelante supondremos que nuestras variables aleatorias continuas siempre tienen varianza no nula.\n\n\n\nSi \\(X_1,\\ldots,X_n\\) son variables aleatorias y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[\nE(a_1X_1+\\cdots+a_nX_n+b)=a_1E(X_1)+\\cdots+a_nE(X_n)+b\n\\] En particular:\n\n\\(E(a X+b)=a E(X)+b\\).\n\\(E(X+Y)=E(X)+E(Y)\\).\n\nSi \\(X\\leqslant Y\\), entonces \\(E(X)\\leqslant E(Y)\\).\nSi \\(a,b\\in \\mathbb{R}\\), \\(\\sigma(aX+b)^2=a^2 \\sigma^2(X)\\) y \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\).\nSi \\(X,Y\\) son independientes, \\(\\sigma^2(X+Y)=\\sigma^2(X)+\\sigma^2(Y)\\). Si no, en principio no.\nSi \\(X_1,\\ldots,X_n\\) son variables aleatorias independientes y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[\n\\begin{array}{l}\n\\sigma^2(a_1X_1+\\cdots+a_nX_n+b)=a_1^2\\cdot\\sigma^2(X_1)+\\cdots+a_n^2\\cdot\\sigma^2(X_n)\\\\\n\\sigma(a_1X_1+\\cdots+a_nX_n+b)=\\sqrt{a_1^2\\cdot\\sigma^2(X_1)+\\cdots+a_n^2\\cdot\\sigma^2(X_n)}\n\\end{array}\n\\] Si no son independientes, estas igualdades pueden ser falsas.\n\nDado \\(p\\) entre 0 y 1, el cuantil de orden \\(p\\) (o \\(p\\)-cuantil) de una variable aleatoria continua \\(X\\) es el menor valor \\(x_p\\in \\mathbb{R}\\) tal que \\[\nF_X(x_p)=P(X\\leqslant x_p)=p\n\\]\nLa mediana de \\(X\\) es su 0.5-cuantil, los primer y tercer cuartiles son su 0.25-cuantil y su 0.75-cuantil, etc.\nLos coeficientes de asimetría y de curtosis se definen de manera similar a los de una muestra: \\[\n\\begin{array}{l}\n\\displaystyle \\gamma_1=E\\Big(\\Big(\\frac{X-\\mu_X}{\\sigma}\\Big)^3\\Big)\\\\\n\\displaystyle \\beta_2=E\\Big(\\Big(\\frac{X-\\mu_X}{\\sigma}\\Big)^4\\Big)-3\n\\end{array}\n\\] Miden para la densidad de la variable lo que medían los de la muestra: el coeficiente de asimetría, si es simétrica o si tiene cola a algún lado; el coeficiente de curtosis, si sus colas son más largas o más cortas que las de una campana de Gauss.\n\n\n5.4.2 Variables aleatorias normales\nUna variable aleatoria continua \\(X\\) es normal (o tiene distribución normal) de parámetros \\(\\mu\\) y \\(\\sigma\\) (es \\(N(\\mu,\\sigma)\\), para abreviar) cuando su función de densidad es \\[\nf_{X}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{{-(x-\\mu)^2}/{2\\sigma^{2}}} \\mbox{\npara todo } x\\in \\mathbb{R}\n\\]\nNaturalmente, no os tenéis que saber esta fórmula.\n\n\n\nPero sí que tenéis que saber que:\n\nUna variable aleatoria normal \\(X\\) es continua, y por lo tanto \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc.\nSi \\(X\\) es normal \\(N(\\mu,\\sigma)\\), su valor esperado es \\(E(X)=\\mu\\) y su desviación típica es \\(\\sigma_X=\\sigma\\).\nSi \\(X\\) es normal, su función de distribución \\(F_X\\) es inyectiva y creciente: si \\(x&lt;y\\), \\(F_X(x)&lt;F_X(y)\\).\n\nUna variable aleatoria normal es típica (o estándar) cuando es \\(N(0,1)\\). Usaremos normalmente \\(Z\\) para denotar una variable normal estándar. Por lo tanto, si \\(Z\\) es una normal estándar, \\(E(Z)=0\\) y \\(\\sigma(Z)=1\\).\nLa gráfica de la densidad de una variable aleatoria normal es la famosa campana de Gauss de la que ya hemos hablado varias veces:\n\n\n\n\n\n\n\n\n\nLa distribución normal es una distribución teórica, no la encontraréis exacta en la vida real. Y pese a su nombre, no es más “normal” que otras distribuciones continuas.\nPero es muy importante, debido a que muchas distribuciones de la vida real son aproximadamente normales porque:\n\nToda variable aleatoria que consista en tomar \\(n\\) medidas independientes de una o varias variables aleatorias y sumarlas, tiene distribución aproximadamente normal cuando \\(n\\) es muy grande, aunque las variables aleatorias de partida no sean normales.\n\nEjemplo:\n\nUna variable binomial \\(B(n,p)\\) se obtiene tomando \\(n\\) medidas independientes de una variable Bernoulli \\(Be(p)\\) y sumando los resultados. Por lo tanto, por la “regla” anterior, una \\(B(n,p)\\) tendría que ser aproximadamente normal si \\(n\\) es grande. Pues sí, si \\(n\\) es grande (pongamos mayor que 40, aunque si \\(p\\) está muy cerca de 0 o 1 el tamaño de las muestras tiene que ser mayor), la distribución de una variable \\(X\\) binomial \\(B(n,p)\\) se acerca mucho a la de una normal \\(N(np,\\sqrt{np(1-p)})\\), donde, recordad que si \\(X\\) es \\(B(n,p)\\), entonces \\(\\mu_X=np\\) y \\(\\sigma_X=\\sqrt{np(1-p)}\\).\n\nPor ejemplo, el gráfico siguiente compara las funciones de distribución de una binomial \\(B(40,0.3)\\) y una normal \\(N(40\\cdot 0.3,\\sqrt{40\\cdot 0.3\\cdot 0.7})\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn los próximos temas utilizaremos a menudo que una variable \\(B(n,p)\\) con \\(n\\) es grande es aproximadamente \\(N(np,\\sqrt{np(1-p)})\\).\n\n\nPara calcular probabilidades de una \\(N(\\mu,\\sigma)\\), podéis usar JAMOVI o alguna aplicación para móvil o tablet.\n\n\n\nAsí, por ejemplo, si \\(X\\) es \\(N(1,2)\\)\n\n\n\n\nEl 0.4-cuantil de \\(X\\), es decir, el valor \\(q\\) tal que \\(P(X\\leqslant q)=0.4\\) es\n\n\n\n\n\n\\(P(X=1.5)\\) es\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¡No! Como \\(X\\) es continua, \\(P(X=1.5)=0\\). Lo que os da dnorm(1.5,1,2) es el valor de la función de densidad de \\(X\\) en 1.5.\n\n\nEjemplo:\n\nLa presión sistólica, medida en mm Hg, es una variable aleatoria aproximadamente normal con valor medio \\(\\mu\\) y desviación típica \\(\\sigma\\) que dependen del sexo y la edad. Para la franja de edad 16-24 años, estos valores son:\n\nPara hombres, \\(\\mu=124\\) y \\(\\sigma=13.7\\)\nPara mujeres, \\(\\mu=117\\) y \\(\\sigma=13.7\\)\n\nEl modelo de hipertensión-hipotensión aceptado es el descrito en la Figura anterior. Queremos calcular los límites de cada clase para cada sexo en este grupo de edad.\n\n\n\nVeamos:\n\nEl límite superior del grupo de hipotensión será el valor que deja a la izquierda un 5% de las tensiones: el 0.05-cuantil de la distribución.\nEl límite superior del grupo de riesgo de hipotensión será el valor que deja a la izquierda un 10% de las tensiones: el 0.1-cuantil de la distribución.\nEl límite inferior del grupo de riesgo de hipertensión será el valor que deja a la izquierda un 90% de las tensiones: el 0.9-cuantil de la distribución.\nEl límite inferior del grupo de hipertensión será el valor que deja a la izquierda un 95% de las tensiones: el 0.95-cuantil de la distribución.\n\nEn los hombres, la tensión sistólica es una variable aleatoria \\(N(124,13.7)\\). Si calculamos estos cuantiles, dan:\n\nEl 0.05-cuantil es 101.5\nEl 0.1-cuantil es 106.4\nEl 0.9-cuantil es 141.6\nEl 0.95-cuantil es 146.5\n\nEn resumen, para los hombres de 16 a 24 años:\n\n\n\n\nEjercicio: Calculad estos límites para las mujeres de 16 a 24 años.\n\n\n5.4.3 Propiedades básicas\nUna de las propiedades clave de la distribución normal es la simetría de la campana de Gauss:\n\n\n\n\n\n\nImportante\n\n\n\nSi \\(X\\) es \\(N(\\mu,\\sigma)\\), su densidad \\(f_X\\) es simétrica respecto de \\(\\mu\\), es decir, \\[\nf_{X}(\\mu-x)=f_{X}(\\mu+x),\n\\] y tiene el máximo en \\(x=\\mu\\). Decimos entonces que \\(\\mu\\) es la moda de \\(X\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nRecordad que no tiene sentido definir la moda de una variable continua \\(X\\) como el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sea máximo, porque \\(P(X=x)=0\\) para todo \\(x\\in \\mathbb{R}\\). Se define entonces la moda de una variable continua \\(X\\) como el valor (o los valores) \\(x_0\\) tal que \\(f_X(x_0)\\) es máximo. Así, como \\(f_X(x_0)\\) mide la probabilidad de que \\(X\\) valga aproximadamente \\(x_0\\), la moda de \\(X\\) es el valor cerca del cual es más probable que caiga el valor de \\(X\\).\n\n\nEn particular, si \\(Z\\) es \\(N(0,1)\\), entonces \\(f_Z\\) es simétrica alrededor de 0, es decir, \\(f_{Z}(-x)=f_{Z}(x)\\), y la moda de \\(Z\\) es \\(x=0\\).\nRecordad que la función de distribución de una variable aleatoria continua \\(X\\), \\[\nF_X(x)=P(X\\leqslant x)\n\\] es el área comprendida entre la densidad \\(y=f_X(x)\\) y el eje de abscisas a la izquierda de \\(x\\).\n\n\n\nEntonces, la simetría de \\(f_X\\) alrededor de \\(\\mu\\) hace que, para todo \\(x\\geqslant 0\\), las áreas a la izquierda de \\(\\mu-x\\) y a la derecha de \\(\\mu+x\\) sean iguales.\n\n\n\n\n\n\n\n\n\nEs decir, \\[\nP(X\\leqslant \\mu-x)=P(X\\geqslant \\mu+x)=1-P(X\\leqslant \\mu+x)\n\\]\nEn particular (tomando \\(x=0\\)) \\[\nP(X\\leqslant \\mu)=1-P(X\\leqslant \\mu)\\Rightarrow P(X\\leqslant \\mu)=0.5\n\\] y por lo tanto, \\(\\mu\\) es también la mediana de \\(X\\).\n\n\n\n\n\n\nImportante\n\n\n\nSi \\(X\\) es \\(N(\\mu,\\sigma)\\), \\(\\mu\\) es la media, la mediana y la moda de \\(X\\).\n\n\nEn el caso concreto de la normal estándar \\(Z\\), para cualquier \\(z\\geqslant 0\\) se tiene que las áreas a la izquierda de \\(-z\\) y a la derecha de \\(z\\) son iguales \\[\nP(Z\\leqslant -z)=P(Z\\geqslant z)=1-P(Z\\leqslant z)\n\\] y la mediana de \\(Z\\) es 0.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nAhora que sabemos más cosas de la normal, en el Ejemplo anterior nos hubiéramos podido ahorrar la mitad del trabajo. Llamemos \\(X\\) a la variable aleatoria que nos da la presión arterial, en mm Hg, de un hombre de entre 16 y 24 años. Nos dicen que \\(X\\) es \\(N(124,13.7)\\).\nPor la simetría de \\(X\\) alrededor de \\(\\mu=124\\), si escribimos el 0.05-cuantil como \\(124-x\\), entonces \\(P(X\\geqslant 124+x)=P(X\\leqslant 124-x)=0.05\\) y por lo tanto \\(P(X\\leqslant 124+x)=1-P(X\\geqslant 124+x)=0.95\\), es decir, \\(124+x\\) será el 0.95-cuantil de \\(X\\).\nEl 0.05-cuantil ha sido 101.5. Escribiendo \\(101.5=124-x\\), obtenemos \\(x=22.5\\). Por lo tanto, el 0.95-cuantil tiene que ser \\(124+22.5=146.5\\).\nLo mismo pasa con el 0.9-cuantil y el 0.1-cuantil, razonadlo y comprobadlo.\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEl argumento que hemos desarrollado en la nota anterior muestra en general que si \\(X\\) es \\(N(\\mu,\\sigma)\\) y su \\(q\\)-cuantil es \\(\\mu-x\\), entonces su \\((1-q)\\)-cuantil es \\(\\mu+x\\).\n\n\n\n\n\nSi \\(\\mu\\) crece, desplaza a la derecha el máximo de la densidad, y con él toda la curva.\n\n\n\nSi \\(\\sigma\\) crece, la curva se aplana: al aumentar la desviación típica, los valores se dispersan y se alejan más del valor medio.\n\n\n\nEl gráfico siguiente muestra el efecto combinado:\n\n\n\nDenotaremos por \\(z_q\\) el \\(q\\)-cuantil de una variable normal estándar \\(Z\\). Es decir, \\(z_q\\) es el valor tal que \\(P(Z\\leqslant z_q)=q\\).\nAparte de que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) es 0), hay dos cuantiles más de la normal estándar \\(Z\\) que os conviene recordar:\n\n\\(z_{0.95}=1.64\\); es decir, \\(P(Z\\leqslant 1.64)=0.95\\) y por lo tanto \\(P(Z\\leqslant -1.64)=P(Z\\geqslant 1.64)=0.05\\) y \\[\nP(-1.64\\leqslant Z\\leqslant 1.64)=0.9.\n\\]\n\\(z_{0.975}=1.96\\); es decir, \\(P(Z\\leqslant 1.96)=0.975\\) y por lo tanto \\(P(Z\\leqslant -1.96)=P(Z\\geqslant 1.96)=0.025\\) y \\[\nP(-1.96\\leqslant Z\\leqslant 1.96)=0.95.\n\\]\n\n\n\n\n\n\n\nTip\n\n\n\nMuy a menudo el valor 1.96 de \\(z_{0.975}\\) se aproxima por 2. Tenéis permiso para hacerlo cuando no dispongáis de medios (R, aplis de móvil) para calcular cuantiles o cuando tengáis que hacer algún cálculo “a ojo” que involucre este cuantil.\n\n\nEjemplo:\n\nSupongamos que la concentración de un cierto metabolito es una variable aleatoria de distribución normal, pero cuyos parámetros \\(\\mu\\) y \\(\\sigma\\) dependen de si la medimos en personas sanas o en personas con una cierta enfermedad. Sean:\n\n\n\\(X_E\\) la variable aleatoria “Tomo una persona enferma y mido su concentración de este metabolito”, y supongamos que es \\(N(\\mu_E, \\sigma_E)\\).\n\\(X_S\\) la variable aleatoria “Tomo una persona sana y mido su concentración de este metabolito”, y supongamos que es \\(N(\\mu_S, \\sigma_S)\\).\nSupongamos, para fijar ideas, que \\(\\mu_E&gt;\\mu_S\\): la concentración media de este metabolito en los enfermos es más alta que en las personas sanas.\n\nPodríamos usar como prueba diagnóstica de la enfermedad la concentración del metabolito. Para cada valor de referencia \\(x_0\\), nuestra prueba dará:\n\nPositivo, si la concentración es mayor o igual que \\(x_0\\).\nNegativo, si la concentración es menor que \\(x_0\\).\n\nEntonces:\n\nLa sensibilidad de esta prueba es \\[\nP(+|E)  =P(X_E\\geqslant x_0)=1-P(X_E&lt; x_0)=1-F_{X_E}(x_0)\n\\]\nSu especificidad es \\[\nP(-|S)=P(X_S&lt; x_0)=F_{X_S}(x_0)\n\\]\nSu tasa de falsos positivos es \\[\nP(+|S)=P(X_S\\geqslant  x_0)=1-F_{X_S}(x_0)\n\\]\n\nAl variar \\(x_0\\), tenemos valores diferentes de la sensibilidad y la tasa de falsos positivos. Entonces, podemos dibujar su curva ROC y escoger el umbral con algún criterio o valorar su capacidad diagnóstica global con su AUC.\nPor ejemplo, imaginad que la densidad de \\(X_E\\) es la línea discontinua del gráfico de la izquierda de la figura siguiente y la de \\(X_S\\) la línea continua. Ambas son normales y \\(\\mu_E&gt;\\mu_S\\), porque el pico de la densidad de \\(X_E\\) está a la derecha del de \\(X_S\\).\n\n\n\n\n\n\n\n\n\nSi para cada \\(x\\) dibujamos los puntos \\((1-F_{X_S}(x),1-F_{X_E}(x))\\), obtenemos la curva ROC de la derecha de dicha figura.\nEjercicio: Del gráfico de las densidades de \\(X_E\\) i \\(X_S\\), ¿podéis deducir cuál tiene mayor desviación típica?\nTenemos también el resultado siguiente:\nTeorema: Las variables normales tienen coeficientes de asimetría y de curtosis 0.\nUna de las propiedades de la distribución normal que nos facilitan mucho la vida es que toda combinación lineal de variables aleatorias normales independientes es normal. En concreto, tenemos los resultados siguientes:\nTeorema: Sea \\(X\\) una variable \\(N(\\mu,\\sigma)\\).\n\nPara todos \\(a,b\\in \\mathbb{R}\\), \\(aX+b\\) es \\(N(a\\mu+b,|a|\\cdot\\sigma)\\).\nEn particular, la tipificada de \\(X\\) \\[\nZ=\\dfrac{X-\\mu}{\\sigma}\n\\] es \\(N(0,1)\\).\n\nMás en general:\nTeorema: Si \\(X_1,\\ldots,X_n\\) son variables aleatorias normales independientes, cada \\(X_i\\) de tipo \\(N(\\mu_i,\\sigma_i)\\), y \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), entonces \\(a_1X_1+\\cdots +a_nX_n+b\\) es \\(N(\\mu,\\sigma)\\) con \\[\n\\mu=a_1\\mu_1+\\cdots +a_n\\mu_n+b,\\\n\\sigma=\\sqrt{a_1^2\\sigma^2_1+\\cdots +a_n^2\\sigma^2_n}\n\\]\n\n\n\n\n\n\nNota\n\n\n\nQue toda combinación lineal de variables normales vuelva a ser del mismo tipo, es decir, normal, es una propiedad muy útil de las variables normales que pocas familias de distribuciones comparten. Por ejemplo, si \\(X\\) es una variable binomial \\(B(n,p)\\) con \\(p\\neq 0\\), la variable \\(2X\\) no es binomial, porque solo toma valores pares, mientras que una variable binomial \\(B(m,q)\\) ha de poder tomar todos los valores entre 0 y \\(m\\).\n\n\nLas probabilidades de la normal tipificada determinan las de la normal original, porque si \\(X\\) es \\(N(\\mu,\\sigma)\\): \\[\n\\begin{array}{rl}\nP(a\\leqslant X\\leqslant b)\\!\\!\\!\\!\\! & \\displaystyle  =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{b-\\mu}{\\sigma}\\Big)\\\\ & \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant \\frac{b-\\mu}{\\sigma}\\Big)\n\\end{array}\n\\] Esto sirve para deducir fórmulas, y vuestros padres lo usaban para calcular probabilidades (con tablas de probabilidades de la normal estándar); ahora es más cómodo usar una aplicación del móvil.\n\n\n5.4.4 Intervalos de referencia\nUn intervalo de referencia del \\(Q\\%\\) para una variable aleatoria \\(X\\) es un intervalo \\([a,b]\\) tal que \\[\nP(a\\leqslant X\\leqslant b)=Q\\%(=Q/100).\n\\] Es decir, un intervalo de referencia del \\(Q\\%\\) para \\(X\\) es un intervalo que contiene los valores de \\(X\\) del \\(Q\\%\\) de los sujetos de la población.\nPor ejemplo, hemos visto en la sección anterior que [-1.64,1.64] y [-1.96,1.96] son intervalos de referencia del 90% y del 95%, respectivamente, para una variable normal estándar \\(Z\\). Y en el Ejemplo @ref(exm:exhiperhipo) hemos visto que un intervalo de referencia del 90% para la presión sistólica de los hombres de 16 a 24 años, medida en mm Hg, es [101.5,146.5].\nLos más comunes son los intervalos de referencia del 95%, que satisfacen que \\[\nP(a\\leqslant X\\leqslant b)=0.95\n\\] y son los, que por ejemplo, os dan como valores de referencia en las analíticas:\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nCuando se habla de un intervalo de referencia sin dar la probabilidad, se sobreentiende siempre que es el intervalo de referencia del 95%.\n\n\n\n\n\n\n\n\nImportante\n\n\n\nUn 5% de la población está fuera del intervalo de referencia del 95%, por definición.\n\n\nCuando \\(X\\) es \\(N(\\mu,\\sigma)\\), estos intervalos de referencia se toman siempre centrados en la media \\(\\mu\\), es decir, de la forma \\([\\mu-\\text{algo},\\mu+\\text{algo}]\\). Para calcularlos se usa el resultado siguiente:\nTeorema: Si \\(X\\) es \\(N(\\mu,\\sigma)\\), un intervalo de referencia del \\(Q\\%\\) para \\(X\\) es \\[\n[\\mu- z_{(1+q)/2}\\cdot \\sigma, \\mu+ z_{(1+q)/2}\\cdot \\sigma]\n\\] donde \\(q=Q/100\\) y \\(z_{(1+q)/2}\\) denota el \\((1+q)/2\\)-cuantil de la normal estándar \\(Z\\). Se suele escribir \\[\n\\mu\\pm z_{(1+q)/2}\\cdot \\sigma.\n\\]\nEn efecto: \\[\n\\begin{array}{l}\nP(\\mu-x\\leqslant X\\leqslant \\mu+x)=q\\\\\n\\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\\n\\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant {x}/{\\sigma})=q\\\\\n\\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-P(Z\\leqslant -{x}/{\\sigma})=q\\\\\n\\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-P(Z\\geqslant {x}/{\\sigma})=q\\\\\n\\qquad \\text{(por la simetría de $f_Z$ alrededor de 0)}\\\\\n\\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-(1-P(Z\\leqslant {x}/{\\sigma}))=q\\\\\n\\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant {x}/{\\sigma})=q+1\\\\\n\\qquad \\Longleftrightarrow P(Z\\leqslant {x}/{\\sigma})=(1+q)/2\\\\\n\\qquad \\Longleftrightarrow x/\\sigma=\nz_{(1+q)/2}\\\\\n\\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma\n\\end{array}\n\\]\nSi \\(q=0.95\\), entonces \\((1+q)/2=0.975\\) y \\(z_{0.975}=1.96\\). Por lo tanto, el intervalo de referencia del 95% para una variable \\(X\\) normal \\(N(\\mu,\\sigma)\\) es \\[\n\\mu\\pm 1.96\\sigma.\n\\] Y como este 1.96 a menudo se aproxima por 2, el intervalo de referencia del 95% se simplifica a \\[\n\\mu\\pm 2\\sigma.\n\\] Esto dice, básicamente, que\n\nsi una población sigue una distribución normal \\(N(\\mu,\\sigma)\\), alrededor del 95% de sus individuos tienen su valor de \\(X\\) a distancia como máximo \\(2\\sigma\\) (“a dos sigmas”) de \\(\\mu\\). El 5% restante de distribuye a partes iguales a ambos lados del intervalo: un 2.5% por encima de su extremo superior y un 2.5% por debajo de su extremo inferior.\n\nEjemplo:\n\nSegún la OMS, las alturas (en cm) de las mujeres europeas de 18 años siguen una ley \\(N(163.1,18.53)\\). ¿Cuál es el intervalo de alturas centrado en la media que contiene a la mitad las europeas de 18 años?\nFijaos en que, si llamamos \\(X\\) a la variable aleatoria “Tomo una mujer europea de 18 años y mido su altura en cm”, lo que queremos saber es el intervalo centrado en su media tal que la probabilidad de que la altura de una europea de 18 años escogida al azar pertenezca a este intervalo sea 0.5. Es decir, el intervalo de referencia del 50% para \\(X\\).\nNos dicen que \\(X\\) es \\(N(163.1,18.53)\\). Si \\(q=0.5\\), entonces \\((1+q)/2=0.75\\) y si calculamos el 0.75-cuantil de una normal estándar, da \\(z_{0.75}=0.6745\\).\nPor lo tanto, es el intervalo \\(163.1\\pm 0.6745\\cdot 18.53\\). Redondeando a mm, \\([150.6, 175.6]\\). Esto nos dice que la mitad de las mujeres europeas de 18 años miden entre 150.6 y 175.6 cm. De la otra mitad, la mitad (es decir un cuarto del total) miden menos de 150.6 cm y la otra más de 175.6 cm.\n\nEl z-score (z-valor, z-puntuación, z-puntaje…) de un valor \\(x_0\\in \\mathbb{R}\\) respecto de una distribución \\(N(\\mu,\\sigma)\\) es \\[\n\\frac{x_0-\\mu}{\\sigma}\n\\]\nEs decir, el z-score de \\(x_0\\) es el resultado de “tipificar” \\(x_0\\) en el sentido del Teorema @ref(thm:comblinnormals).\nSi la variable poblacional es normal, cuanto mayor es el valor absoluto del z-score de \\(x_0\\), más “raro” es \\(x_0\\); el signo nos dice si es más grande o más pequeño que el valor esperado \\(\\mu\\).\nEjemplo:\n\nRecordad que, según la OMS, las alturas de las mujeres europeas de 18 años siguen una ley \\(N(163.1,18.53)\\). ¿Cuál sería el z-score de una jugadora de baloncesto de 18 años que midiera 191 cm?\nSería \\[\n\\frac{191-163.1}{18.53}=1.5\n\\]\nEsto se suele leer diciendo que la altura de esta jugadora está 1.5 sigmas por encima de la media (donde, recordad, “sigma” es una abreviatura de “desviación típica poblacional”).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Variables aleatorias</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html",
    "href": "t6_estimacion.html",
    "title": "6  Estimadores",
    "section": "",
    "text": "6.1 La media muestral\nCuando queremos estimar el valor medio de una variable sobre una población, tomamos una muestra de valores y calculamos su media aritmética, ¿verdad? Pues eso es la media muestral.\nDada una variable aleatoria \\(X\\), llamamos media muestral de (muestras de) tamaño \\(n\\) a la variable aleatoria \\(\\overline{X}\\) “Tomamos una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calculamos la media aritmética de sus valores”.\nVeamos algunas propiedades de la distribución de \\(\\overline{X}\\):\nTeorema: Sea \\(X\\) una variable aleatoria cualquiera de media \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\), y sea \\(\\overline{X}\\) la media muestral de tamaño \\(n\\) de \\(X\\). Entonces:\nQue \\(E(\\overline{X})\\) sea \\(\\mu_X\\) nos indica que \\(\\overline{X}\\) sirve para estimar \\(\\mu_X\\), porque su valor esperado es \\(\\mu_X\\):\nCuando el valor esperado de un estimador es precisamente el parámetro poblacional que se quiere estimar, se dice que el estimador es insesgado. Así, el primer punto del teorema anterior dice que la media muestral \\(\\overline{X}\\) es un estimador insesgado de la media poblacional \\(\\mu_X\\).\nQue \\(\\sigma(\\overline{X})\\) sea \\(\\sigma_X/\\sqrt{n}\\) implica que la variabilidad de las medias muestrales crece con la variabilidad de \\(X\\) y decrece si tomamos muestras de mayor tamaño. Esto último es razonable. Aunque la variabilidad de \\(X\\) sea grande, si tomamos muestras grandes, es de esperar que los valores extremos se compensen al calcular sus medias y que estas últimas tengan por lo tanto menos variabilidad que la variable \\(X\\) original.\nA \\(\\sigma_X/\\sqrt{n}\\) se le llama el error típico de la media muestral (para la variable aleatoria \\(X\\) y muestras de tamaño \\(n\\)).\nTeorema: Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\), entonces \\(\\overline{X}\\) es \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\).\nSi \\(X\\) no es normal, sigue siendo cierto que \\(\\overline{X}\\) es “aproximadamente” normal siempre y cuando \\(n\\) sea grande. Este es uno de los más importantes en estadística y el motivo de la importancia de la distribución normal.\nTeorema Central del Límite: Sea \\(X\\) una variable aleatoria cualquiera de esperanza \\(\\mu_X\\) y desviación típica \\(\\sigma_X\\). Si \\(n\\) es muy grande, \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X, {\\sigma_X}/{\\sqrt{n}})\\).\n¿Cuándo es una muestra lo bastante grande como para poder invocar el Teorema Central del Límite? En realidad, depende de la \\(X\\). Cuánto más se parezca \\(X\\) a una variable normal, más pequeñas pueden ser la muestras. Por fijar un valor, aceptaremos que “muy grande” en este teorema es \\(n\\geqslant 40\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html#la-media-muestral",
    "href": "t6_estimacion.html#la-media-muestral",
    "title": "6  Estimadores",
    "section": "",
    "text": "\\(E(\\overline{X})=\\mu_X\\)\n\\(\\sigma(\\overline{X})=\\dfrac{\\sigma_X}{\\sqrt{n}}\\)\n\n\nFormalmente, la media muestral de tamaño \\(n\\) de una variable aleatoria \\(X\\) se define como la variable aleatoria \\[\n\\overline{X}=\\frac{X_1+\\cdots+X_n}{n}\n\\] donde \\(X_1,\\ldots,X_n\\) son \\(n\\) copias independientes de la variable \\(X\\).\nEntonces, por la linealidad de la esperanza \\[\n  E(\\overline{X})=\\frac{E(X_1)+\\cdots+E(X_n)}{n}=\\frac{n\\cdot \\mu_X}{n}=\\mu_X\n\\] porque, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(E(X_1)=\\cdots=E(X_n)=\\mu_X\\).\nY por la “linealidad” de la varianza de la suma de variables independientes \\[\n\\sigma(\\overline{X})^2=\\frac{\\sigma(X_1)^2+\\cdots+\\sigma(X_n)^2}{n^2}=\\frac{n\\cdot \\sigma_X^2}{n^2}=\\frac{\\sigma_X^2}{n}\n\\] porque, de nuevo, como \\(X_1,\\ldots,X_n\\) son copias de \\(X\\), \\(\\sigma(X_1)^2=\\cdots=\\sigma(X_n)^2=\\sigma_X^2\\).\n\n\n\nSi calculáramos muchas medias de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a \\(\\mu_X\\).\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nLa pestaña Teorema Central del Límite del módulo Demonstration de JAMOVI os permite experimentar cómo muestras de diferentes tamaños de medias muestrales de diferentes tamaños y de diferentes distribuciones poblacionales se aproximan más o menos a una distribución normal. Por ejemplo, para 1000 medias de muestras de tamaño 40 de una binomial:\n\n\n\n\n\n\n\n\n\n\n¿Qué quiere decir que una variable aleatoria sea “aproximadamente” normal? Pues que su función de distribución \\(F_X\\) toma valores muy cercanos a la función de distribución de una normal. Recordad cómo una \\(B(n,p)\\) con \\(n\\) grande era “aproximadamente normal” en el tema anterior.\n\n\n\n\n\n\n\nImportante\n\n\n\nEn resumen:\n\nSi \\(X\\) es normal, \\(\\overline{X}\\) es \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\).\nSi \\(X\\) no es normal pero \\(n\\) es grande (pongamos \\(n\\geqslant 40\\), aunque puede ser menor si \\(X\\) se parece a una normal y seguramente tendrá que ser mayor si \\(X\\) es muy diferente de una normal), \\(\\overline{X}\\) es aproximadamente \\(N(\\mu_X,{\\sigma_X}/{\\sqrt{n}})\\).\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLas afirmaciones del bloque anterior son verdaderas para medias muestrales de muestras aleatorias simples. Si no podemos suponer que la muestra sea aleatoria simple, ninguno de los dos resultados es válido.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html#la-proporción-muestral",
    "href": "t6_estimacion.html#la-proporción-muestral",
    "title": "6  Estimadores",
    "section": "6.2 La proporción muestral",
    "text": "6.2 La proporción muestral\nCuando queremos estimar la proporción de sujetos de una población que tienen una determinada característica, tomamos una muestra y calculamos la proporción de sujetos de la muestra con esta característica. Esta será la proporción muestral de sujetos con esta característica en nuestra muestra.\nDada una variable aleatoria \\(X\\) de Bernoulli \\(Be(p_X)\\), la proporción muestral de (muestras de) tamaño \\(n\\), \\(\\widehat{p}_X\\), es la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la proporción de éxitos en la muestra: es decir, contar el número total de éxitos y dividir el resultado por \\(n\\).\nFijaos en que \\(\\widehat{p}_X\\) es un caso particular de media muestral \\(\\overline{X}\\): estamos calculando medias muestrales de muestras aleatorias simples de la variable de Bernoulli \\(X\\). Por lo tanto, todo lo que hemos dicho para medias muestrales vale también para proporciones muestrales:\nTeorema: Si \\(X\\) es una variable aleatoria de Bernoulli con probabilidad poblacional de éxito \\(p_X\\) y \\(\\widehat{p}_X\\) es la proporción muestral de tamaño \\(n\\):\n\n\\(E(\\widehat{p}_X)=p_X\\)\n\\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\)\n\n\n\n\n\n\n\nNota\n\n\n\nNo hace falta invocar que la proporción muestral sea un caso particular de media muestral para obtener el resultado anterior. Si llamamos \\(S_n\\) a la variable que cuenta el número de éxitos en una muestra aleatoria simple de tamaño \\(n\\) de la variable de Bernoulli \\(X\\), entonces, por un lado, tenemos que \\(\\widehat{p}_X=S_n/n\\) y, por otro, que \\(S_n\\) es \\(B(n,p_X)\\). Entonces:\n\n\\(E(\\widehat{p}_X)=E\\Big(\\dfrac{1}{n}S_n\\Big)=\\dfrac{1}{n}\\cdot E(S_n)=\\dfrac{1}{n}\\cdot np_X=p_X\\)\n\\(\\sigma({\\widehat{p}_X})=\\sigma\\Big(\\dfrac{1}{n}S_n\\Big)=\\dfrac{1}{n}\\cdot \\sigma(S_n)=\\dfrac{1}{n} \\sqrt{np_X(1-p_X)}=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\)\n\n\n\n\\(E(\\widehat{p}_X)=p_X\\) nos dice que \\(\\widehat{p}_X\\) es un estimador insesgado de \\(p_X\\). Si calculáramos muchas proporciones muestrales de muestras aleatorias de \\(X\\), es muy probable que, de media, obtuviéramos un valor muy cercano a la proporción poblacional de éxitos \\(p_X\\).\n\\(\\sigma({\\widehat{p}_X})=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) nos dice que, fijada la variable \\(X\\), si tomamos muestras de tamaño mayor, la variabilidad de los resultados de \\(\\widehat{p}_X\\) disminuye.\nSi tomamos muestras aleatorias simples de tamaño \\(n\\) de una variable aleatoria Bernoulli \\(X\\):\n\n\\(\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) es el error típico de la variable aleatoria \\(\\widehat{p}_X\\): su desviación típica.\nPara cada muestra, \\(\\sqrt{\\dfrac{\\widehat{p}_X(1-\\widehat{p}_X)}{n}}\\) es el error típico de la muestra, que estima el error típico de \\(\\widehat{p}_X\\).\n\nY como la proporción muestral es un caso particular de media muestral, por el Teorema Central del Límite tenemos el resultado siguiente:\nTeorema: Si \\(n\\) es grande y las muestras aleatorias son simples, \\(\\widehat{p}_X\\) es aproximadamente \\(N\\big (p_X,\\sqrt{{p_X(1-p_X)}/{n}}\\big)\\) y por lo tanto \\[\n\\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}}\n\\] es aproximadamente \\(N(0,1)\\).\n\n\n\n\n\n\nImportante\n\n\n\nEn el caso de la proporción muestral, a veces vamos a permitir tomar muestras aleatorias sin reposición. En este caso, la variable \\(S_n\\) que cuenta el número de éxitos en una muestra aleatoria sin reposición de tamaño \\(n\\) de la variable de Bernoulli \\(X\\), y que verifica que \\(\\widehat{p}_X=S_n/n\\), es hipergeométrica. De aquí deducimos que seguimos teniendo que \\(E(\\widehat{p}_X)=p_X\\), pero ahora, si \\(N\\) es el tamaño de la población, \\[\n\\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot\n\\sqrt{\\frac{\\vphantom{(p_X}N-n}{N-1}}.\n\\] El factor \\[\n\\sqrt{\\frac{N-n}{N-1}}\n\\] que transforma \\(\\sigma({\\widehat{p}_X})\\) para muestras aleatorias simples en la desviación típica de \\({\\widehat{p}_X}\\) para muestras aleatorias sin reposición es el factor de población finita que transformaba la desviación típica de una variable binomial (que cuenta éxitos en muestras aleatorias simples) en la desviación típica de una variable hipergeométrica (que cuenta éxitos en muestras aleatorias sin reposición).\n\n\n\n\n\n\n\n\nTip\n\n\n\nY recordad que si el tamaño de la población \\(N\\) es muy grande comparado con \\(n\\), podemos suponer que una muestra aleatoria sin reposición es simple.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html#la-varianza-muestral",
    "href": "t6_estimacion.html#la-varianza-muestral",
    "title": "6  Estimadores",
    "section": "6.3 La varianza muestral",
    "text": "6.3 La varianza muestral\nDada una variable aleatoria \\(X\\), llamamos:\n\nVarianza muestral de (muestras de) tamaño \\(n\\), \\(\\widetilde{S}_{X}^2\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la varianza muestral de sus valores.\nDesviación típica muestral de (muestras de) tamaño \\(n\\), \\(\\widetilde{S}_{X}\\), a la variable aleatoria consistente en tomar una muestra aleatoria simple de tamaño \\(n\\) de \\(X\\) y calcular la desviación típica muestral de sus valores.\n\nFormalmente, estas variables se definen tomando \\(n\\) copias independientes \\(X_1,\\ldots,X_n\\) de \\(X\\) y calculando \\[\n\\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1},\\quad\n\\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2}\n\\]\nTenemos los dos resultados siguientes. El primero nos dice que \\(\\widetilde{S}_{X}^2\\) es un estimador insesgado de la varianza poblacional \\(\\sigma_{X}^2\\).\nTeorema: \\(E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2\\).\nPor lo tanto, esperamos que la varianza muestral de una muestra aleatoria simple de \\(X\\) valga \\(\\sigma_{X}^2\\), en el sentido usual de que si tomamos muestras aleatorias simples de \\(X\\) de tamaño \\(n\\) grande y calculamos sus varianzas muestrales, muy probablemente obtengamos de media un valor muy cercano a \\(\\sigma_{X}^2\\).\n\n\n\n\n\n\nAdvertencia\n\n\n\nY por consiguiente NO esperamos que la varianza “a secas” de una muestra aleatoria simple valga \\(\\sigma_{X}^2\\), porque la varianza muestral y la varianza “a secas” dan valores diferentes (tienen el mismo numerador y denominadores diferentes).\n\n\nEl segundo resultado nos dice que si la variable \\(X\\) es normal, un múltiplo adecuado de \\(\\widetilde{S}_{X}^2\\) tiene distribución conocida, lo que nos permitirá calcular probabilidades de sucesos relativos a \\(\\widetilde{S}_{X}^2\\).\nTeorema: Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras aleatorias simples de tamaño \\(n\\), la variable aleatoria \\[\n\\chi^2=  \\dfrac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2}\n\\] tiene una distribución conocida, llamada ji cuadrado con \\(n-1\\) grados de libertad, \\(\\chi_{n-1}^2\\).\n\n\n\n\n\n\nTip\n\n\n\nLa letra griega \\(\\chi\\) en castellano se lee ji; en catalán, khi; en inglés, chi, pronunciado “chai”.\n\n\nLa distribución \\(\\chi_\\nu^2\\), donde \\(\\nu\\) es un parámetro llamado sus grados de libertad, es la distribución de probabilidad de la suma de los cuadrados de \\(\\nu\\) copias independientes de una variable normal estándar. Para R es chisq. La tenéis también en el módulo distrACTION.\n\n\n\nOs puede interesar recordar que una variable \\(\\chi_\\nu^2\\) de tipo ji cuadrado con \\(\\nu\\) grados de libertad:\n\nTiene valor esperado \\(E(\\chi_\\nu^2)=\\nu\\) y varianza \\(\\sigma(\\chi_\\nu^2)^2=2 \\nu\\).\nSu función de distribución es estrictamente creciente.\nSu densidad es asimétrica a la derecha, como muestra el gráfico siguiente:\n\n\n\n\n\n\n\n\n\n\nA medida que el número de grados de libertad \\(\\nu\\) crece, esta asimetría tiende a desaparecer y, por el Teorema Central del Límite, si \\(\\nu\\) es lo bastante grande, la distribución \\(\\chi_\\nu^2\\) se aproxima a la de una variable normal \\(N(\\nu,\\sqrt{2\\nu})\\).\n\n\n\n\n\n\n\n\n\n:::{.callout-warning} Tened cuidado:\n\nSi la variable poblacional \\(X\\) no es normal, la conclusión del Teorema anterior no es verdadera.\nAunque \\(X\\) sea normal, \\(E(\\widetilde{S}_{X})\\neq \\sigma_{X}\\). La desviación típica muestral es un estimador sesgado de \\(\\sigma_{X}\\) (pero tiene otras buenas propiedades que hacen que la usemos igualmente).\nYa lo hemos comentado antes. Si \\(S^2_{X}\\) es la varianza “a secas” (dividiendo por \\(n\\) en vez de por \\(n-1\\)), \\(E(S^2_{X})\\neq \\sigma^2_{X}\\). De hecho, como \\(S_X^2\\) se obtiene a partir de \\(\\widetilde{S}_{X}^2\\) cambiando el denominador, \\[\nS_X^2=\\frac{n-1}{n} \\widetilde{S}_{X}^2\n\\] tenemos que \\[\nE(S_X^2)=\\frac{n-1}{n}E(\\widetilde{S}_{X}^2)=\\frac{n-1}{n}\\sigma^2_{X}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html#la-distribución-t-de-student",
    "href": "t6_estimacion.html#la-distribución-t-de-student",
    "title": "6  Estimadores",
    "section": "6.4 La distribución t de Student",
    "text": "6.4 La distribución t de Student\nRecordad que si la variable poblacional \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) y tomamos muestras aleatorias simples de tamaño \\(n\\), entonces \\(\\overline{X}\\) es \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\) y por lo tanto, tipificando, la variable \\[\n\\frac{\\overline{X}-\\mu_X}{\\sigma_{X}/\\sqrt{n}}\n\\] es normal estándar. Esto no nos sirve de nada para calcular la probabilidad de que \\(\\overline{X}\\) se aleje mucho de \\(\\mu_X\\) si no sabemos la desviación típica poblacional \\(\\sigma_{X}\\), que será lo habitual. ¿Qué pasa si la estimamos por medio de \\(\\widetilde{S}_{X}\\) con la misma muestra con la que calculamos \\(\\overline{X}\\)? Pues que el resultado siguiente nos salva el día, porque la variable que resulta tiene distribución conocida y por lo tanto podemos calcular probabilidades con ella.\nTeorema: Sea \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\). Si tomamos muestras aleatorias simples de tamaño \\(n\\), la variable aleatoria \\[\nT=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}}\n\\] tiene una distribución conocida, llamada t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\).\nAl denominador \\(\\widetilde{S}_{X}/\\sqrt{n}\\) de la \\(T\\) del teorema anterior se le llama el error típico de la muestra, y estima el error típico \\(\\sigma_X/\\sqrt{n}\\) de la media muestral \\(\\overline{X}\\).\nFijaos en que el teorema anterior es solo para variables poblacionales \\(X\\) normales. Si \\(X\\) no es normal, tenemos el resultado siguiente.\nTeorema: Sea \\(X\\) una variable de media \\(\\mu_X\\). Si tomamos muestras aleatorias simples de tamaño \\(n\\) muy grande, la variable aleatoria \\[\nT=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}}\n\\] tiene distribución aproximadamente \\(t_{n-1}\\).\nLa distribución t de Student la tenéis también en el módulo distrACTION.\n\n\n\nAlgunas propiedades que conviene que recordéis de las variables \\(T_\\nu\\) que tienen distribución \\(t\\) de Student con \\(\\nu\\) grados de libertad, \\(t_\\nu\\):\n\nSu valor esperado es \\(E(T_\\nu)=0\\) y su varianza es \\(\\sigma(T_\\nu)=\\dfrac{\\nu}{\\nu-2}\\) (en realidad esto solo es verdad si \\(\\nu\\geqslant 3\\), pero no hace falta recordarlo).\nSu función de distribución es estrictamente creciente.\nSu densidad es simétrica respecto de 0 (como la de una \\(N(0,1)\\)) y por lo tanto \\[\nP(T_\\nu\\leqslant -x)=P(T_\\nu\\geqslant x)=1-P(T_\\nu\\leqslant x)\n\\]\nSi \\(\\nu\\) es grande (digamos, de nuevo, \\(\\nu\\geqslant 40\\)), \\(T_\\nu\\) es aproximadamente una \\(N(0,1)\\) (pero con un poco más de varianza, porque \\(\\nu/(\\nu-2)&gt;1\\), y por consiguiente un poco más achatada).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDenotaremos por \\(t_{\\nu,q}\\) el \\(q\\)-cuantil de una variable aleatoria \\(T_{\\nu}\\) con distribución \\(t_\\nu\\). Es decir, \\(t_{\\nu,q}\\) es el valor tal que \\[\nP(T_{\\nu}\\leqslant t_{\\nu,q})=q\n\\] Entonces:\n\nPor la simetría de la densidad de \\(T_{\\nu}\\), \\[\nt_{\\nu,q}=-t_{\\nu,1-q}.\n\\] Exactamente lo mismo que pasaba con la normal estándar\nSi \\(\\nu\\) es grande, \\(T_\\nu\\) será aproximadamente una \\(N(0,1)\\) y por lo tanto \\(t_{\\nu,q}\\) es aproximadamente igual a \\(z_q\\).\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nNo confundáis:\n\nDesviación típica de una variable aleatoria: El parámetro poblacional, normalmente desconocido. Es \\(\\sigma_X\\).\nDesviación típica (muestral o no) de una muestra: El estadístico que calculamos sobre la muestra. Es \\(\\widetilde{S}_X\\) (la muestral) o \\({S}_X\\) (la “a secas”).\nError típico de la media muestral: La desviación típica de la variable \\(\\overline{X}\\). Es \\(\\sigma_X/\\sqrt{n}\\), con \\(n\\) el tamaño de las muestras.\nError típico de una muestra: Estimación del error típico de \\(\\overline{X}\\) a partir de la muestra. Es \\(\\widetilde{S}_X/\\sqrt{n}\\), con \\(n\\) el tamaño de la muestra.\n\nFijaos en que el denominador \\(\\sqrt{n}\\) hace que, en general, los errores típicos sean mucho más pequeños que las desviaciones típicas. Id con cuidado, porque esto se usa a menudo en artículos para enmascarar los resultados. Si una muestra ha salido con una dispersión muy grande, se da su error típico en vez de su desviación típica y parece que ha salido más concentrada.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html#intervalos-de-confianza",
    "href": "t6_estimacion.html#intervalos-de-confianza",
    "title": "6  Estimadores",
    "section": "6.5 Intervalos de confianza",
    "text": "6.5 Intervalos de confianza\nLos estimadores nos permiten hacer una estimación puntual del valor de un parámetro de una variable poblacional: es decir, intentar adivinar su valor. Pero, naturalmente, es muy difícil que a partir de una muestra podamos acertar exactamente el valor del parámetro. Las técnicas de la estadística inferencial nos permiten entonces cuantificar la precisión de esta estimación. Esto se hace complementando la estimación puntual con un intervalo alrededor de la misma donde “estemos muy seguros de que cae el valor real del parámetro”.\nDe lo que se trata es de dar un intervalo lo más estrecho posible donde estemos muy seguros de que cae el valor real del parámetro. El tamaño de este intervalo dependerá:\n\nDe la variabilidad del estimador: cuánta más variabilidad tenga, menos precisa será la estimación. Normalmente, la variabilidad del estimador crece con la desviación típica de la variable poblacional y decrece con el tamaño de las muestras.\nDel nivel de confianza, o seguridad: cómo de seguros queremos estar de que el valor real del parámetro pertenece al intervalo que damos. Cuánto más seguros queramos estar, más ancho tendrá que ser el intervalo.\n\n\n6.5.1 Definiciones básicas\nUn intervalo de confianza del Q% (para abreviar, un IC-Q%) de un parámetro poblacional (una media, una desviación típica, uno proporción poblacional…) es un intervalo obtenido aplicando a una muestra aleatoria simple de tamaño \\(n\\) una fórmula, o, más en general, un procedimiento, que satisface la propiedad siguiente:\n\nEl intervalo obtenido contiene el valor del parámetro poblacional el Q% de las veces que aplicamos la fórmula a muestras aleatorias simples de tamaño \\(n\\) tomadas al azar.\n\nTener una confianza del Q% significa pues que lo calculamos con una fórmula que acierta el Q% de las veces que la aplicamos.\n\n\n\n\n\n\nNota\n\n\n\nInformalmente: El Q% de los IC-Q% contienen el valor real del parámetro que quieren estimar.\n\n\nPero asumimos que en un (100-Q)% de las veces da un intervalo que no contiene el valor del parámetro poblacional, y no sabemos cuándo sí y cuándo no. De manera que solo podemos tener una cierta confianza, fruto del optimismo, de que esta fórmula acierta con nuestra muestra.\nEjemplo:\n\nEn un experimento se midió el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. Calcularemos con los datos obtenidos en este experimento un IC-95% para el porcentaje de aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza.\nEsto significará que tenemos un 95% de seguridad en que el aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza está entre el 40.53% y el 41.87%, porque habremos calculado este intervalo con una fórmula que el 95% de las veces que la aplicamos a muestras aleatorias de tamaño 40 da un intervalo que contiene la media poblacional que queremos estimar. Nosotros somos optimistas y “confiamos” estar dentro de este 95% de aciertos.\nA menudo esto lo escribiremos diciendo que:\n\nHay un 95% de probabilidad de que el intervalo [40.53, 41.87] contenga el valor real del aumento medio de alcohol en sangre de una persona después de beber 4 cañas de cerveza.\n\nPero hay que entender lo que dice esta frase:\n\nPor definición, un 95% de los intervalos de confianza del 95% para el aumento medio de alcohol etc. contienen el valor real de este aumento medio.\n[40.53, 41.87] es un intervalo de confianza del 95% para el aumento medio de alcohol etc., obtenido a partir de una muestra aleatoria.\nEntonces, [40.53, 41.87] tiene una probabilidad del 95% de contener el valor real del aumento medio de alcohol etc. en el mismo sentido que si un 95% de las personas tienen una determinada característica, y cojo una persona al azar, esta persona tiene un 95% de probabilidad de tener esa característica.\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nNo confundáis:\n\nIntervalo de referencia del Q% para una variable aleatoria: Intervalo que contiene el valor de la variable aleatoria en un individuo con probabilidad Q%.\nIntervalo de confianza del Q% para un parámetro: Intervalo que contiene el valor poblacional del parámetro de la variable aleatoria “con probabilidad” Q%, en el sentido de que lo hemos calculado con una fórmula que da un intervalo que contiene dicho parámetro el Q% de las veces que la aplicamos a una muestra aleatoria.\n\n\n\nPor ejemplo:\n\nSi decimos que un intervalo de referencia del 95% para la concentración de una proteína en suero en individuos sanos en g/dl es [11,16], esto significa\n\nque un 95% de los individuos sanos tienen una concentración de esta proteína en suero entre 11 y 16 g/dl\n\nes decir,\n\nque si escogemos al azar un individuo sano, la probabilidad de que su concentración de esta proteína en suero esté entre 11 y 16 g/dl es del 95%.\n\nSi decimos que un intervalo de confianza del 95% para la concentración media de una proteína en suero en individuos sanos tamaño en g/dl es [11,16], esto significa\n\nque este intervalo tiene un 95% de probabilidad de contener la concentración media de esta proteína en suero en individuos sanos tamaño en g/dl,\n\nen el sentido de que lo hemos obtenido aplicando a una muestra aleatoria de concentraciones de esta proteína en suero en individuos sanos una fórmula que da un intervalo que contiene la media poblacional un 95% de las veces que la aplicamos a muestras aleatorias del mismo tamaño que la nuestra.\n\nQue un IC-Q% para un parámetro \\(\\theta\\) sea \\([a,b]\\) sirve:\n\nPara estimar \\(\\theta\\) con este margen de confianza: Estamos muy seguros de que el valor poblacional de \\(\\theta\\) está entre \\(a\\) y \\(b\\) (porque la fórmula usada acierta a menudo).\nPara descartar, con este margen de confianza, que \\(\\theta\\) valga cualquier valor concreto fuera de \\([a,b]\\): Como estamos muy seguros de que el valor real de \\(\\theta\\) está entre \\(a\\) y \\(b\\), también estamos muy seguros de que es diferente de cualquier valor que sea menor que \\(a\\) o mayor que \\(b\\).\n\nPor ejemplo: si un IC-95% para la prevalencia \\(p\\) de una determinada enfermedad en una población va de 0.025 a 0.047:\n\nEstamos muy (“un 95%”) seguros de que \\(p\\) está entre 0.025 y 0.047 (porque la probabilidad de que un IC-95% para \\(p\\) contenga el valor real de \\(p\\) es del 95%).\nEstamos muy (“un 95%”) seguros de que \\(p\\) no vale 0.05 (porque 0.05 no pertenece al intervalo al que estamos muy seguros de que pertenece el valor real de \\(p\\)).\nPero no estamos muy seguros de que \\(p\\) sea 0.03, por mucho que \\(0.03\\in [0.025,0.047]\\): estamos muy seguros de que \\(p\\) está entre 0.025 y 0.047, pero solo eso.\n\nHay dos tipos de métodos básicos de cálculo de intervalos de confianza a partir de una muestra aleatoria:\n\nParamétricos: Usando alguna fórmula basada en la distribución muestral del estimador. Se basan en teoremas y solo tiene sentido usarlos si la variable aleatoria y la muestra aleatoria satisfacen (aproximadamente) las hipótesis de los teoremas.\nNo paramétricos. Los otros. El más popular, y nuestro favorito, es el bootstrap:\n\nDe nuestra muestra, tomamos al azar muchas (miles) muestras aleatorias con reposición del mismo tamaño que nuestra muestra.\nCalculamos el estimador para cada una de estas muestras.\nUsamos el vector de resultados para estimar un intervalo de confianza. Por ejemplo, tomamos como IC-95% el intervalo entre los cuantiles 0.025 y 0.975 de este vector.\n\nEl bootstrap se puede usar siempre y funciona bien si la muestra es aleatoria, pero se basa en un proceso aleatorio y por lo tanto cada ejecución sobre una misma muestra puede dar un intervalo diferente. Este método escapa al temario de la asignatura, pero lo mencionamos porque es muy popular en la práctica.\n\n\n\n6.5.2 Un ejemplo: IC-95% para la media de una variable aleatoria normal\nUna de las fórmulas más conocidas para intervalos de confianza es la siguiente:\n\n\n\n\n\n\nImportante\n\n\n\nSi \\(X\\) es normal de media \\(\\mu\\) y tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y desviación típica muestral \\(\\widetilde{S}_X\\), un IC-95% para \\(\\mu\\) es \\[\n\\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg]\n\\] donde \\(t_{n-1,0.975}\\) denota el 0.975-cuantil de la distribución t de Student \\(t_{n-1}\\).\n\n\nEste intervalo a veces lo escribiremos \\[\n\\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\n\\] para recalcar que estamos estimando \\(\\mu\\) por medio de \\(\\overline{X}\\) más o menos un cierto error.\n\n\n\n\n\n\nAdvertencia\n\n\n\nA algunos de vosotros os habrán explicado en Bachillerato, o encontraréis en libros que consultéis, una fórmula para el IC-95% para \\(\\mu\\) similar a esta, pero cambiando la \\(\\widetilde{S}_X\\) por la desviación típica de \\(X\\), \\(\\sigma\\), y el \\(t_{n-1,0.975}\\) por \\(z_{0.975}\\), el 0.975-cuantil de la normal estándar. Esta otra fórmula solo se puede usar si se conoce la desviación típica poblacional \\(\\sigma\\), lo que, en la práctica, nunca pasará. Por lo tanto, por favor, olvidadla.\n\n\n¿Cómo podemos estar seguros de que en un 95% de las aplicaciones de esta fórmula a una muestra aleatoria simple el intervalo que obtengamos contendrá el valor real de la media?\nVamos a explicar de dónde sale esta fórmula, puesto que es un paradigma de cómo se obtienen la mayoría de las fórmulas paramétricas para intervalos de confianza. Quien se la quiera tomar como dogma de fe, que salte directamente al Ejemplo.\nSupongamos pues que normal de media \\(\\mu\\) y que tenemos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y desviación típica muestral \\(\\widetilde{S}_X\\). En esta situación, sabemos que \\[\nT=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\n\\] tiene distribución t de Student con \\(n-1\\) grados de libertad, \\(t_{n-1}\\).\nSi podemos encontrar \\(A,B\\in \\mathbb{R}\\) tales que \\[\nP(A\\leqslant T\\leqslant B)=0.95,\n\\] entonces: \\[\n\\begin{array}{rl}\n0.95\\!\\!\\!\\! & =P\\Bigg(A\\leqslant   \\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leqslant  B\\Bigg)\\\\[2ex]\n& =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant  \\overline{X}-\\mu \\leqslant  B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex]\n& =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant  -\\mu \\leqslant  -\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex]\n& =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant  \\mu \\leqslant  \\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\n\\end{array}\n\\]\nComo \\(P(A\\leqslant  T\\leqslant  B)=0.95\\) significa que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) el valor de \\(T\\) está entre \\(A\\) y \\(B\\), \\[\nP\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant  \\mu \\leqslant  \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95\n\\] significará que para el 95% de las muestras aleatorias simples de tamaño \\(n\\) la \\(\\mu\\) cae dentro del intervalo \\[\n\\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg]\n\\] Por lo tanto, ¡esto será un IC-95% para \\(\\mu\\)!\nNos falta encontrar los \\(A,B\\) tales que \\(P(A\\leqslant T\\leqslant B)=0.95\\). Para encontrarlos, usaremos cuantiles de la distribución de \\(T\\). Recordemos que, por definición de cuantil, \\[\nP(T\\leqslant t_{n-1,0.975})=0.975\n\\] y por la simetría de la \\(t\\) de Student, \\[\nP(T\\leqslant  -t_{n-1,0.975})=P(T\\geqslant t_{n-1,0.975})=0.025\n\\] Por tanto: \\[\n\\begin{array}{l}\nP(-t_{n-1,0.975}\\leqslant  T\\leqslant  t_{n-1,0.975})\\\\\n\\quad =P(T\\leqslant  t_{n-1,0.975})-P(T\\leqslant  -t_{n-1,0.975})\\\\\n\\quad =0.975-0.025=0.95\n\\end{array}\n\\]\n\n\n\n\n\n\n\n\n\nAsí pues, podemos tomar \\[\nA=-t_{n-1,0.975},\\quad B=t_{n-1,0.975}\n\\] y obtenemos el IC-95% para \\(\\mu\\) anunciado: \\[\n\\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg]\n\\]\nEjemplo:\n\n\nVolvamos al experimento en el que se midió el porcentaje de aumento de alcohol en sangre a 40 personas después de tomar 4 cañas de cerveza. La media y la desviación típica muestral de estos porcentajes de incremento fueron \\[\n\\overline{x}=41.2,\\quad \\widetilde{s}=2.1.\n\\]\nPara calcular un IC-95% para el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza, \\(\\mu\\) para abreviar, supondremos que la variable aleatoria de interés (de la que queremos estimar la media) \\(X\\), que es “Tomamos una persona, bebe 4 cañas de cerveza y medimos el porcentaje de aumento de alcohol en sangre tras beberlas”, es normal y que la muestra que hemos tomado de esta variable es aleatoria simple.\nEntonces, como \\(t_{n-1,0.975}=2.0227\\), un IC-95% para \\(\\mu\\) es \\[\n41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87]\n\\]\nPor lo tanto, estimamos con un 95% de confianza que el porcentaje medio de aumento de alcohol en sangre después de tomar 4 cañas de cerveza está entre el 40.5% y el 41.9%, o que es del 41.2% más menos 0.7 puntos porcentuales.\nPara calcular el intervalo anterior hemos supuesto que la variable poblacional “Porcentaje de aumento de alcohol en sangre después de tomar 4 cañas de cerveza” sigue una distribución normal. ¿Y si no fuera normal?\n\nEn este caso, como el tamaño de la muestra \\(n=40\\) es lo bastante grande, por lo tanto, el intervalo obtenido sigue siendo (aproximadamente) un intervalo de confianza del 95% para \\(\\mu\\).\nSi \\(n\\) fuera pequeño y \\(X\\) muy diferente de una normal, no se puede usar esta fórmula y habría que buscarse la vida (por ejemplo, usar el método bootstrap).\n\nTambién hemos supuesto que era una muestra aleatoria simple. ¿Y si no lo es? Entonces, no podemos hacer nada para salvar la fórmula, y su validez depende de si la muestra de personas usada puede pasar por aleatoria o no.\n\n\n6.5.3 Intervalo de confianza para la media basado en la t de Student\n\n\n\n\n\n\nAdvertencia\n\n\n\nA partir de ahora, para evitar ambigüedades, en las fórmulas expresaremos el nivel de confianza de los intervalos en tanto por uno, no en tanto por ciento; es decir, como una proporción en vez de como un porcentaje. Por lo tanto, hablaremos de intervalos de confianza de nivel de confianza \\(q\\) (IC-\\(q\\)), con \\(q\\) entre 0 y 1, en vez de intervalos de confianza del Q% con Q=100q. Con estas notaciones, por ejemplo, los intervalos de confianza del 95% serán intervalos de confianza de nivel de confianza 0.95, IC-0.95.\n\n\nEl mismo argumento de la sección anterior, cambiando 0.95 por \\(q\\), da:\nTeorema: Si \\(X\\) es normal de media \\(\\mu\\) y tomamos una muestra aleatoria simple de tamaño \\(n\\), media muestral \\(\\overline{X}\\) y desviación típica muestral \\(\\widetilde{S}_X\\), un IC-\\(q\\) para \\(\\mu\\) es \\[\n\\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\n\\]\nLa fórmula de la sección anterior es un caso particular de esta, porque en los IC-0.95, \\(q=0.95\\) y por lo tanto \\((1+q)/2=1.95/2=0.975\\).\nMás en general:\n\n\n\n\n\n\nNota\n\n\n\nSi \\(X\\) es una variable aleatoria cualquiera de media poblacional \\(\\mu\\) y tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\) grande (digamos, de 40 o más elementos), entonces, un IC-\\(q\\) para \\(\\mu\\) es aproximadamente \\[\n\\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\n\\]\n\n\nLa aproximación del teorema anterior es mejor cuanto mayor sea \\(n\\) o cuanto más próxima a una normal sea la variable poblacional \\(X\\).\nEn resumen:\n\n\n\n\n\n\nImportante\n\n\n\nPodemos usar la fórmula para el IC-\\(q\\) para la media poblacional basada en la t de Student \\[\n\\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\n\\] si la variable poblacional es normal o si la muestra aleatoria simple es grande.\n\n\nObservad que la estructura del IC-\\(q\\) para \\(\\mu\\) dado por esta fórmula es\n\nestimador \\(\\pm\\) (\\(\\frac{1+q}{2}\\)-cuantil de la distr. muestral)\\(\\times\\)(error típico de la muestra)\n\nEsta estructura es muy típica (pero no universal: no creáis que todos los intervalos de confianza paramétricos tienen esta forma) y cumple que:\n\nEl intervalo de confianza está centrado en la estimación puntual.\nLa “probabilidad de equivocarnos” se reparte por igual a los dos lados del intervalo: de media, en una fracción \\((1-q)/2\\) de las veces que se aplica la fórmula, el valor real del parámetro cae a la izquierda del extremo inferior y en otra fracción \\((1-q)/2\\) de estas ocasiones cae a la derecha del extremo superior.\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nPara una misma muestra y una misma fórmula (paramétrica) para calcular el intervalo de confianza, si el nivel de confianza crece, el intervalo se ensancha.\n\n\nEsto es general, para todos los intervalos de confianza paramétricos. El motivo intuitivo es que, para estar más seguros de que un intervalo contiene un valor, el intervalo tiene que ser más ancho. En un intervalo de confianza con la estructura descrita hace un momento, el motivo matemático es que a mayor \\(q\\), mayor \\((1+q)/2\\)-cuantil de la distribución muestral.\nPor ejemplo, en el Ejemplo de las cervezas, teníamos \\(n=40\\), \\(\\overline{x}=41.2\\) y \\(\\widetilde{s}=2.1\\):\n\nEl IC-95% tiene \\(q=0.95\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), y daba \\[\n41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\n\\]\nEl IC-99% tiene \\(q=0.99\\), por lo tanto \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), y da \\[\n41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9\n\\] más ancho\nPero si cambiamos de muestra (o de fórmula, si hay más de una) para calcular el intervalo de confianza, puede pasar cualquier cosa.\n\nEl intervalo de confianza para una media usando la fórmula basada en la t de Student se puede calcular con JAMOVI marcando las casillas Diferencia de medias e Intervalo de confianza (y eligiendo el nivel de confianza) en T-tests/Prueba T en una muestra.\nEjemplo:\n\nQueremos calcular un intervalo de confianza del 95% para la temperatura media de las personas. Para ello, vamos a usar unos datos recogidos por P.A. Mackowiak, S. S. Wasserman y M.M. Levine en un estudio de 1992, en el que tomaron la temperatura a una muestra transversal de 230 personas (114 hombres y 116 mujeres). Tenemos guardadas estas temperaturas en la tabla Temperaturas.txt que podéis descargar de https://raw.githubusercontent.com/AprendeR-UIB/INREMDN/master/Dades/Temperaturas.txt.\n\nTras descargarla, la importamos abriéndola con Importar especial. Seleccionamos T-tests/Prueba T en una muestra, elegimos la variable Temperatura como “variable dependiente” y marcamos Diferencia de medias e Intervalo de confianza (hemos marcado también Descriptivas para calcular algunos estadísticos de la muestra). Obtenemos la pantalla siguiente:\n\n\n\nPor ahora nos fijamos solo en las tres últimas columnas de la tabla superior: el valor “Diferencia de medias” es la media de la muestra (su “diferencia” con 0, que es el Valor de prueba en la columna de la izquierda) y los extremos inferior y superior del intervalo de confianza para la media poblacional del nivel de confianza que hayamos escogdo. La media muestral ha dado 36.8o y el intervalo de confianza del 95% va de 36.8o a 36.9o. Podéis comprobar que coincide (salvo errores de redondeo) con lo que da la fórmula que hemos explicado: al marcar la casilla Descriptivas hemos obtenido el tamaño de la muestra N, la media y la desviación típica (DE, desviación estándar) y podéis calcular que \\(z_{229,0.975}=1.97\\), y tenéis todos los datos necesarios para usar la fórmula.\n\n\n6.5.4 Intervalos de confianza para proporciones\nSupongamos que tenemos una variable Bernoulli \\(X\\) con probabilidad poblacional de éxito \\(p_X\\) desconocida. Queremos calcular un intervalo de confianza para \\(p_X\\). Para hacerlo, tomamos una muestra aleatoria simple de \\(X\\) de tamaño \\(n\\), con número de éxitos \\(S\\) y por tanto proporción muestral de éxitos \\(\\widehat{p}_{X}=S/n\\).\nExplicaremos uno de los métodos más populares para calcular este intervalo de confianza:\n\n\n\n\n\n\nImportante\n\n\n\nEl método aproximado de Laplace, que solo se puede usar cuando la muestra es bastante más grande, digamos que de tamaño 100 o más, y la proporción muestral \\(\\widehat{p}_{X}\\) no es muy próxima ni a 0 ni a 1. Es el método más clásico y conocido.\n\n\nPara fijar unas condiciones suficientes, supongamos que:\n\n\\(n\\geqslant 100\\).\nTanto el número de éxitos, \\(S\\), como el número de fracasos, \\(n-S\\), en la muestra son \\(\\geqslant 10\\).\n\nTeorema: En las condiciones explicadas, un IC-\\(q\\) para \\(p_X\\) es aproximadamente \\[\n\\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}\n(1-\\widehat{p}_{X})}{n}}\n\\]\nEsta fórmula es la más popular, y forma parte de la “cultura general” de un científico. De hecho, tiene más de 200 años y precede en más de 100 años a los otros dos métodos. Además, tiene la forma familiar “estimador \\(\\pm\\) cuantil\\(\\times\\)error típico”.\nJAMOVI por ahora no incorpora el cálculo del intervalos de Laplace, pero los podéis calcular en la ventana de su editor de R con la función binom.approx del paquete epitools. La sintaxis de esta función es siempre la misma:\n\nbinom.approx(x,n,conf.level)\n\ndonde x y n representan, respectivamente, el número de éxitos y el tamaño de la muestra, y conf.level es nuestra \\(q\\), el nivel de confianza en tanto por uno. El valor por defecto de conf.level es 0.95, por lo que no hace falta especificarlo si queréis calcular un IC-95%. El intervalo que se obtiene tiene como extremo inferior el valor lower y extremo superior el valor upper.\nEjemplo:\n\nEn un ensayo de un tratamiento de quimioterapia, en una muestra de 100 pacientes tratados, 25 desarrollaron cáncer testicular secundario. ¿Cuál es un IC-95% para la proporción de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular?\nEn este caso podemos Laplace, porque \\(n\\geqslant 100\\), \\(S=25\\geqslant 10\\) y \\(n-S=75\\geqslant 10\\).\nVamos a aplicar a mano la fórmula de Laplace, que es la única que es sensato calcular a mano (y es la que os recomendamos usar si podéis). Tenemos que \\(\\widehat{p}_{X}=25/100=0.25\\) y \\(z_{0.975}=1.96\\). Da: \\[\n0.25\\pm 1.96\\sqrt{\\frac{0.25\\cdot 0.75}{100}}=0.25\\pm 0.085\\Rightarrow [0.165, 0.335]\n\\] Concluimos, con un nivel de confianza del 95%, que entre aproximadamente un 16.5% y un 33.5% de los pacientes tratados con esta quimioterapia desarrollan cáncer testicular. En este caso podríamos decir que estimamos, con un nivel de confianza del 95%, que el porcentaje de pacientes tratados con esta quimioterapia que desarrollan cáncer testicular es del 25% más o menos 8.5 puntos porcentuales.\nCalculamos el intervalo de Laplace con R:\n\nbinom.approx(25,100)\n\n   x   n proportion     lower     upper conf.level\n1 25 100       0.25 0.1651311 0.3348689       0.95\n\n\nDa lo mismo que a mano.\n\n\n6.5.4.1 Cálculo del tamaño de la muestra para fijar el error\nLlamaremos margen de error (o error, precisión…) de un intervalo de confianza de Laplace a la mitad de su amplitud. En el caso del intervalo de Laplace, este margen de error es lo que sumamos y restamos a la proporción muestral para obtenerlo: \\[\nM= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\n\\] Fijaos en que el intervalo de confianza de Laplace es \\(\\widehat{p}_X\\pm M\\) y por lo tanto, si contiene el valor real de \\(p_X\\), el error \\(|\\widehat{p}_X-p_X|\\) que cometemos cuando decimos que el valor de \\(p_X\\) es \\(\\widehat{p}_X\\) es como máximo este “margen de error” \\(M\\).\nUna pregunta que hay que hacerse al diseñar un estudio es ¿de qué tamaño he de tomar la muestra para garantizar que el margen de error en la estimación sea como máximo un valor dado \\(M_{max}\\)? En el caso del intervalo de Laplace para una proporción, podemos dar un tamaño \\(n\\) que garantice un error máximo dado \\(M_{max}\\) valga lo que valga \\(\\widehat{p}_{X}\\in [0,1]\\).\nFijaos en que la función \\(y=p(1-p)\\), con \\(p\\in [0,1]\\), es una parábola cóncava con vértice en su punto \\(p=0.5\\).\n\n\n\n\n\n\n\n\n\nPor lo tanto, \\(y=p(1-p)\\) toma su valor máximo en \\(p=0.5\\). Así, pues, valga lo que valga \\(\\widehat{p}_{X}\\), siempre pasa que \\[\n\\widehat{p}_{X} (1-\\widehat{p}_{X})\\leqslant 0.5(1-0.5)=0.5^2\n\\] y por lo tanto \\[\n\\begin{array}{l}\n\\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\\n\\qquad\\displaystyle\n\\leqslant z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}}\n\\end{array}\n\\]\nAsí pues, si tomamos \\(n\\) tal que \\[\n\\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leqslant M_{max}\n\\] entonces seguro que \\(M\\leqslant M_{max}\\), independientemente del valor de \\(\\widehat{p}_{X}\\).\nPor consiguiente, lo que haremos será calcular la \\(n\\) para obtener un margen de error como máximo \\(M_{max}\\) en el caso más desfavorable: cuando el intervalo de confianza es lo más ancho posible, es decir, suponiendo que \\(\\widehat{p}_{X}=0.5\\): \\[\nM_{max}\\geqslant \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\n\\Longrightarrow\nn\\geqslant \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\n\\right)^2\n\\]\nEn resumen:\nTeorema: Si \\[\nn\\geqslant \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2,\n\\] el margen de error del intervalo de Laplace calculado con una muestra de tamaño \\(n\\) será como máximo \\(M_{max}\\).\nEjemplo:\n\n¿Cuál es el menor tamaño de una muestra que garantiza un margen de error de como máximo 5 puntos porcentuales al estimar una proporción \\(p_X\\) usando un intervalo de confianza de Laplace del 95%?\nPor el teorema anterior, para garantizar un margen de error máximo \\(M_{max}= 0.05\\) al calcular un IC-95% para una proporción \\(p_X\\) usando la fórmula de Laplace, tenemos que usar una muestra de tamaño \\(n\\) tal que \\[\nn\\geqslant \\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{2\\cdot 0.05}\\Bigg)^2=384.16\n\\]\nEl menor tamaño que satisface esta condición es \\(n=385\\).\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nLa respuesta correcta no es 384, por mucho que 384.16 se redondee a 384. Fijaos en que 384 no es más grande que 384.16.\n\n\nObservad tres cosas:\n\nEl valor de \\(n\\) solo depende del margen de error deseado y del nivel de confianza, no de la naturaleza del estudio ni de la población. Para garantizar un margen de error de como máximo 5 puntos porcentuales, es suficiente tomar una muestra aleatoria simple de 385 sujetos, tanto si queremos estimar la prevalencia de la diabetes en la India (1400 millones de habitantes) como la proporción de personas tatuadas en Mallorca (menos de 1 millón de habitantes).\nTal y como hemos encontrado la \\(n\\), estamos seguros de que si tomamos una muestra como mínimo de este tamaño, el margen de error del intervalo de confianza de Laplace será como máximo \\(M_{max}\\), sea cual sea la muestra. ¡Es de las pocas veces que podemos estar seguros de algo en estadística!\nEl teorema anterior es para el intervalo de Laplace, pero la \\(n\\) seguramente os saldrá muy grande y en este caso el intervalo de Laplace aproxima muy bien los otros dos intervalos si la proporción muestral luego no os sale muy extrema.\n\n\n\n6.5.4.2 “Poblaciones finitas”\nEn esta sección hasta ahora hemos usado muestras aleatorias simples. Ya sabemos que si tomamos muestras aleatorias sin reposición y la población es mucho más grande que el tamaño \\(n\\) de las muestras, las fórmulas que hemos dado siguen funcionando (aproximadamente) bien. Pero, ¿qué pasa si tomamos una muestra aleatoria sin reposición y la población no es mucho más grande que la muestra?\nLo que se hace, cuando se puede, es usar la fórmula de Laplace teniendo en cuenta el factor de población finita:\n\nSi \\(X\\) una variable aleatoria de Bernoulli \\(Be(p_X)\\) definida sobre una población de tamaño \\(N\\) y tomamos una muestra aleatoria sin reposición de \\(X\\), con \\(n\\geqslant 100\\) y números de éxitos y fracasos \\(\\geqslant 10\\), un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) es, aproximadamente, \\[\n\\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}\n(1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}}\n\\]\nEn las condiciones del punto anterior, para obtener un intervalo de confianza de nivel de confianza \\(q\\) para \\(p_X\\) con un margen de error \\(M_{max}\\) en el caso más desfavorable (\\(\\widehat{p}_X=0.5\\)) habrá que tomar una muestra de tamaño \\[\nn\\geqslant \\frac{Nz_{(q+1)/2}^2}{4(N-1)M_{max}^2+z_{(q+1)/2}^2}\n\\]\n\nEjemplo:\n\nEn una muestra aleatoria sin reposición de 727 estudiantes de la UIB (\\(N=11797\\)), 557 afirmaron haber cometido plagio en algún trabajo durante sus estudios. ¿Cuál sería un intervalo de confianza del 95% para la proporción \\(p_X\\) de estudiantes de la UIB que han cometido plagio en algún trabajo?\nUna muestra de 727 estudiantes diferentes es muy grande respecto del total de estudiantes de la UIB, por lo que conviene usar la fórmula de Laplace con el factor de población finita: \\[\n\\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}\n(1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}}\n\\] donde \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) y \\(N=11797\\): da \\[\n0.766\\pm 1.96\\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}11797-727}{11797-1}}\\Rightarrow [0.736, 0.796]\n\\] Estimamos con un nivel de confianza del 95% que entre un 73.6% y un 79.6% de los estudiantes de la UIB han cometido plagio en algún trabajo.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t6_estimacion.html#otros-intervalos-de-confianza",
    "href": "t6_estimacion.html#otros-intervalos-de-confianza",
    "title": "6  Estimadores",
    "section": "6.6 Otros intervalos de confianza",
    "text": "6.6 Otros intervalos de confianza\nComo os podéis imaginar, hay fórmulas paramétricas para calcular intervalos de confianza (y a veces más de una) para todos los parámetros de interés: varianza, desviación típica, odds ratios, etc. No vamos a dar las fórmulas de todos ellos; en la vida real, los intervalos de confianza se calculan con algún paquete estadístico. Pero al menos vamos a dar dos fórmulas muy comunes y conocidas.\n\n6.6.1 Un intervalo de confianza para la diferencia de proporciones\nSean \\(X_1\\) y \\(X_2\\) dos variables Bernoulli de probabilidades poblacionales de éxito \\(p_1\\) y \\(p_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de estas probabilidades, \\(p_1-p_2\\). Para ello, tomamos dos muestras independientes, una de cada variable:\n\nUna muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de proporción muestral \\(\\widehat{p}_1\\).\nUna muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de proporción muestral \\(\\widehat{p}_2\\).\n\nSi las dos muestras son grandes, pongamos cada una de 50 o más sujetos, y las proporciones muestrales no son muy cercanas a 0 o a 1 (para fijar ideas, que en cada muestra haya como mínimo 5 éxitos y 5 fracasos), un IC-\\(q\\) para la diferencia \\(p_1-p_2\\) es, aproximadamente, \\[\n\\widehat{p}_1-\\widehat{p}_2 \\pm z_{(q+1)/2}\\cdot\n\\sqrt{\\frac{n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2}{n_1\n+n_2}\\cdot \\frac{n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)}{n_1\n+n_2}\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2}\n\\Big)}\n\\] Notad que \\(n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) es el número total de éxitos y \\(n_1 (1-\\widehat{p}_1) +n_2( 1-\\widehat{p}_2)\\) el número total de fracasos en las dos muestras.\nEjemplo:\n\nEn un estudio francés sobre la efectividad de la hidroxicloroquina en el tratamiento de la COVID-19 leve o moderada en personas de edad avanzada, participaron 247 pacientes de este grupo de riesgo. Se dividieron al azar en dos grupos de 124 y 123 sujetos. Los del primer grupo fueron tratados con hidroxicloroquina y los del segundo grupo, con un placebo. Se anotó en cada grupo cuántos fallecieron o necesitaron intubación en los 14 días siguientes al inicio del tratamiento (lo resumiremos en “desenlace negativo”). En el grupo tratado con hidroxicloroquina hubo 9 desenlaces negativos y en el grupo del placebo, 8.\n\nLlamemos \\(p_1\\) a la probabilidad de que un paciente de edad avanzada con COVID-19 leve o moderada tratado con placebo tenga un desenlace negativo, y \\(p_2\\) a la correspondiente probabilidad para los tratados con hidroxicloroquina. Queremos calcular un IC-95% para la RAR de desenlace negativo con hidroxicloroquina comparado con placebo, es decir, para la diferencia \\(p_1-p_2\\).\nLas variables de interés son:\n\n\\(X_1\\): Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con placebo y miramos si tiene un desenlace negativo; es Bernoulli \\(Be(p_1)\\).\n\\(X_2\\): Tomamos un paciente de edad avanzada con COVID-19 leve o moderada, lo tratamos con hidroxicloroquina y miramos si tiene un desenlace negativo; es Bernoulli \\(Be(p_2)\\).\n\nSe tomó una muestra de \\(X_1\\) de tamaño \\(n_1=123\\) y hubo 8 éxitos, de manera que su proporción muestral de éxitos fue \\(\\widehat{p}_1=8/123=0.06504\\), y una muestra de \\(X_2\\) de tamaño \\(n_2=124\\), donde hubo 9 éxitos y por lo tanto su proporción muestral de éxitos fue \\(\\widehat{p}_2=9/124=0.07258\\). El número total de éxitos (es decir, de desenlaces negativos) fue \\(8+9=17\\) y el de fracasos \\(247-17=230\\). Las dos muestras son independientes, ya que los sujetos se asignaron al azar a uno u otro grupo.\nSuponiendo que las muestras puedan pasar por aleatorias, estamos en condiciones de aplicar la fórmula anterior. Obtenemos \\[\n\\begin{array}{l}\n\\displaystyle 0.06504-0.07258 \\pm 1.96\\cdot\n\\sqrt{\\frac{17}{247}\\cdot \\frac{230}{247}\\cdot \\Big(\\frac{1}{123}+\\frac{1}{124}\n\\Big)}\\\\\n\\qquad\\qquad =-0.00754\\pm 0.06314\\Rightarrow [-0.0707,  0.0556]\n\\end{array}\n\\] Así pues, estimamos con un 95% de confianza que la RAR de desenlace negativo con hidroxicloroquina entre estos pacientes está entre -0.0707 y 0.0556. Es decir, estimamos con una confianza del 95% que el efecto de administrar hidroxicloroquina está entre el aumento en 7.1 puntos porcentuales del riesgo de desenlace negativo y su disminución en 5.6 puntos porcentuales. En particular, no podemos ni afirmar ni descartar que su uso mejore el pronóstico del paciente.\nCon JAMOVI, podemos calcular este intervalo de confianza en Frecuencias/Muestras independientes: Prueba de asociación de \\(\\chi^2\\) a partir de una tabla de datos que contenga la muestra. En este caso concreto, hemos guardado los datos en la tabla EstudioHCQ.csv que podéis descargar de https://raw.githubusercontent.com/AprendeR-UIB/INREMDN/master/Dades/EstudioHCQ.csv. Contiene las variables Tratamiento que indica el tratamiento (HCQ es la abreviatura de hidroxicloroquina) y DN que indica si hubo desenlace negativo o no.\nPara calcular el intervalo de confianza anterior, importamos la tabla y cambiamos el orden de los niveles de DN para que 1 vaya antes que 0. A continuación, seleccionamos en Frecuencias/Muestras independientes: Prueba de asociación de \\(\\chi^2\\) las casillas Diferencia de proporciones e Intervalo de confianza, así como Comparar columnas si, como hemos hecho nosotros, hemos definido el Tratamiento como la variable de las columnas:\n\n\n\nObtenemos el mismo intervalo de confianza que antes.\n\n\n6.6.2 Intervalos de confianza para diferencias de medias\nSean \\(X_1\\) y \\(X_2\\) dos variables de medias \\(\\mu_1\\) y \\(\\mu_2\\), respectivamente. Supongamos que queremos calcular un IC-\\(q\\) para la diferencia de medias \\(\\mu_1-\\mu_2\\). Para ello, tomamos:\n\nUna muestra aleatoria simple de tamaño \\(n_1\\) de \\(X_1\\), de media muestral \\(\\overline{X}_1\\).\nUna muestra aleatoria simple de tamaño \\(n_2\\) de \\(X_2\\), de media muestral \\(\\overline{X}_2\\).\n\nSi \\(X_1\\) y \\(X_2\\) son aproximadamente normales o si las muestras usadas son grandes (de nuevo, digamos, ambas de tamaño como mínimo 40), entonces podemos usar un método paramétrico basado en una distribución t de Student, que da un intervalo centrado en la diferencia de medias muestrales, de la forma \\[\n\\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\times\\text{error típico}\n\\]\nPero el número de grados de libertad \\(\\nu\\) a usar en el cuantil y la fórmula del error típico van a depender de dos factores.\nPor un lado, de que las muestras sean independientes (hemos medido \\(X_1\\) y \\(X_2\\) sobre dos muestras obtenidas de manera independiente la una de la otra) o emparejadas (hemos medido \\(X_1\\) y \\(X_2\\) sobre los individuos de una misma muestra o hay algún apareamiento explícito entre los sujetos de las dos muestras; en particular, si las muestras son emparejadas ha de pasar que \\(n_1=n_2\\)).\nY si las muestras son independientes, la fórmula a usar depende de si las varianzas de \\(X_1\\) y \\(X_2\\) son iguales o diferentes. (¿Y cómo podemos saber si son iguales o diferentes? Ya os podéis imaginar que, con un 100% de seguridad, no podremos; pero sí que podemos determinar si son iguales o no con un cierto margen de confianza, es decir, aceptando una pequeña probabilidad de equivocarnos. No os perdáis las próximas lecciones.)\nOs damos las fórmulas. No hace falta saberlas, pero sí recordar que la fórmula concreta a usar depende de estas condiciones. Supongamos, pues, que \\(X_1\\) y \\(X_2\\) son aproximadamente normales o que \\(n_1,n_2\\geqslant 40\\). Entonces:\n\nSi las muestras son emparejadas y \\(n_1=n_2=n\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[\n\\overline{X}_1-\\overline{X}_2\\pm t_{n-1,(q+1)/2}\\cdot \\frac{\\widetilde{S}_D}{\\sqrt{n}}\n\\] donde \\(\\widetilde{S}_D\\) es la desviación típica muestral de las diferencias \\(X_1-X_2\\) sobre las parejas de la muestra.\n\n\nEsta fórmula es simplemente la traducción de la fórmula basada en la t de Student del IC-\\(q\\), aplicada a estimar la media \\(\\mu_1-\\mu_2\\) de la variable \\(D=X_1-X_2\\) a partir de una muestra de valores de esta diferencia.\n\n\nSi las muestras son independientes y \\(\\sigma_{X_1}^2=\\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[\n\\overline{X}_1-\\overline{X}_2\\pm t_{n_1+n_2-2,(q+1)/2} \\sqrt{\\Big(\\frac{1}{n_1}+\\frac{1}{n_2}\\Big)\\cdot\n\\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2}\n{n_1+n_2-2}}\n\\] donde \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente.\nSi las muestras son independientes y \\(\\sigma_{X_1}^2\\neq \\sigma_{X_2}^2\\), un IC-\\(q\\) para \\(\\mu_1-\\mu_2\\) es \\[\n\\overline{X}_1-\\overline{X}_2\\pm t_{\\nu,(q+1)/2}\\cdot\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}}\n\\] donde, de nuevo, \\(\\widetilde{S}_1^2\\) y \\(\\widetilde{S}_2^2\\) son las varianzas muestrales de las muestras de \\(X_1\\) y \\(X_2\\), respectivamente, y ahora el número de grados de libertad que tenemos que usar al calcular el cuantil es \\[\n\\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2}{\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2}\n\\]\n\nEjemplo:\n\nQueremos calcular un intervalo de confianza del 95% para la diferencia en la temperatura media de las mujeres y los hombres. Para ello, vamos a usar la tabla de datos que ya usamos en un ejemplo previo.\nDemos algunos nombres. Las variables aleatorias de interés son:\n\n\\(X_F\\): “Tomamos una mujer y le tomamos la temperatura, en grados C”,de media \\(\\mu_F\\) y desviación típica \\(\\sigma_F\\).\n\\(X_M\\): “Tomamos un hombre y le tomamos la temperatura, en grados C”, de media \\(\\mu_M\\) y desviación típica \\(\\sigma_M\\).\n\nVamos a calcular un IC-95% para \\(\\mu_F-\\mu_M\\). Como ambas muestras son grandes, vamos a usar una fórmula basada en la t de Student. Calculamos con JAMOVI los estadísticos necesarios:\n\n\n\nTenemos pues los datos siguientes:\n\nPara la muestra de \\(X_F\\), su tamaño es \\(n_F=116\\), su media muestral es \\(\\overline{X}_F=36.9\\) y su varianza muestral es \\(\\widetilde{S}_F^2=0.191\\).\nPara la muestra de \\(X_M\\), su tamaño es \\(n_M=114\\), su media muestral es \\(\\overline{X}_M=36.75\\) y su varianza muestral es \\(\\widetilde{S}_M^2=0.228\\).\n\nPara calcular el IC-95%, necesitamos saber si \\(\\sigma_M^2=\\sigma_F^2\\) o \\(\\sigma_M^2\\neq \\sigma_F^2\\). Vamos a suponer que \\(\\sigma_M^2=\\sigma_F^2\\), es decir, que las temperaturas de las mujeres son “igual de variadas” que las de los hombres, básicamente porque no vemos ningún motivo para que no sea así (bueno, y porque en una próxima lección veremos cómo decidir, con una cierta probabilidad de equivocarnos, si dos varianzas poblacionales son iguales o diferentes, y en concreto concluiremos que, en este caso, podemos aceptar que \\(\\sigma_M^2=\\sigma_F^2\\): mirad el spoiler al final de esta sección).\nAsí que hemos de usar la fórmula para muestras independientes y varianzas iguales: \\[\n\\overline{X}_F-\\overline{X}_M\\pm t_{n_F+n_M-2,0.975} \\sqrt{\\Big(\\frac{1}{n_F}+\\frac{1}{n_M}\\Big)\\cdot\n\\frac{(n_F-1)\\widetilde{S}_F^2+(n_M-1)\\widetilde{S}_M^2}\n{n_F+n_M-2}}\n\\]\ndonde \\(t_{n_F+n_M-2,0.975}=t_{228,0.975}=1.97\\). Da \\[\n\\begin{array}{l}\n\\displaystyle 36.9-36.7\\pm 1.97 \\sqrt{\\Big(\\frac{1}{116}+\\frac{1}{114}\\Big)\\cdot\n\\frac{115\\cdot 0.191+113\\cdot 0.228}\n{228}}\\\\\n\\qquad \\displaystyle = 0.2\\pm 1.97\\cdot 0.06\\Longrightarrow [ 0.037, 0.273]\n\\end{array}\n\\] Estimamos con un 95% de confianza que la temperatura media de las mujeres es entre una y dos décimas de grado C más alta que la de los hombres.\nCon JAMOVI, podemos calcular estos intervalos de confianza a partir de una tabla de datos en T-Tests/Prueba T para muestras independientes (si las muestras son independientes) o T-Tests/Prueba T para muestras emparejadas (si las muestras son emparejadas). En el primer caso, a parte de Diferencia de medias e Intervalo de confianza, hay que marcar t de Student si suponemos que las varianzas poblacionales son iguales y t de Welch si suponemos que las varianzas poblacionales son diferentes.\nPor ejemplo, para calcular el intervalo de confianza anterior suponiendo que las varianzas poblacionales de las temperaturas de hombres y mujeres son iguales:\n\n\n\n(no da exactamente igual a nuestro intervalo por errores de redondeo) y suponiendo que las varianzas poblacionales de las temperaturas de hombres y mujeres son diferentes:\n\n\n\nNo hay apenas diferencia entre los dos intervalos: [0.0363,0.274] contra [0.0362,0.274].\n\n\n\n\n\n\nImportante\n\n\n\nUn pequeño spoiler para introducir el próximo tema. Para decidir, con un cierto nivel de seguridad, si las dos varianzas poblacionales son iguales o diferentes basta marcar en la ventana T-Tests/Prueba T para muestras independientes la casilla Prueba de homogeneidad: en este contexto, homogeneidad significa “igualdad de varianzas poblacionales”. Hay que mirar entonces el resultado p de la tabla “Prueba de Levene para homogeneidad de varianzas” (con el módulo moretests instalado, esta tabla tiene más filas).\nEsta p es lo que llamaremos el p-valor en el próximo tema. Avanzando acontecimientos, es la probabilidad de obtener varianzas muestrales tan diferentes como las de nuestras muestras si las varianzas poblacionales fueran iguales. Un p-valor pequeño nos permite dudar de que las varianzas poblacionales sean diferentes (porque si fueran iguales sería mucha casualidad obtener varianzas muestrales tan diferentes como las nuestras), mientras que un p-valor grande no aporta evidencia de que sean diferentes y nos hace concluir que son iguales. Como regla general, p-valores por encima de 0.1 se consideran grandes. Así que en este caso, con un p-valor 0.266, podemos aceptar que las varianzas poblacionales de las temperaturas de hombres y mujeres son iguales.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimadores</span>"
    ]
  },
  {
    "objectID": "t7_ch.html",
    "href": "t7_ch.html",
    "title": "7  Introducción a los contrastes de hipótesis",
    "section": "",
    "text": "7.1 Hipótesis nula y alternativa\nEn un contraste de hipótesis, se comparan siempre dos hipótesis alternativas: la hipótesis nula \\(H_{0}\\) y la hipótesis alternativa \\(H_{1}\\). Se suele plantear formalmente \\[\n\\left\\{\\begin{array}{ll}\nH_{0}:\\text{hipótesis nula}\\\\\nH_{1}:\\text{hipótesis alternativa}\n\\end{array}\n\\right.\n\\]\nEn los contrastes de hipótesis de esta asignatura:",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a los contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "t7_ch.html#hipótesis-nula-y-alternativa",
    "href": "t7_ch.html#hipótesis-nula-y-alternativa",
    "title": "7  Introducción a los contrastes de hipótesis",
    "section": "",
    "text": "La hipótesis nula \\(H_{0}\\) es “no hay diferencia”, “no pasa nada”, “no hay nada extraño” o el equivalente en el contexto del contraste:\n\nLa moneda es equilibrada (50% de probabilidad de cara).\nLos tratamientos A y B son igual de efectivos en la curación de la enfermedad X.\n\nLa hipótesis alternativa \\(H_{1}\\) plantea la diferencia de la que buscamos evidencia:\n\nLa moneda está trucada a favor de cara (más del 50% de probabilidad de cara).\nA es más efectivo que B en la curación de la enfermedad X.\n\nEstamos dispuestos a aceptar \\(H_0\\) por defecto: que no hay diferencia, que no pasa nada.\n\nPor defecto, estamos dispuestos a aceptar que la moneda es equilibrada (la mayoría lo son, ¿no?).\nPor defecto, estamos dispuestos a aceptar que los dos tratamientos son igual de efectivos (si tomáis dos sustancias cualesquiera y las administráis a enfermos de X, lo más normal es que ninguna de los dos tenga efecto alguno, y por lo tanto que las dos sean igual de (in)efectivas).\n\nSi obtenemos evidencia suficiente de que \\(H_0\\) es falsa, rechazaremos \\(H_0\\) en favor de \\(H_1\\) y concluiremos que \\(H_1\\) es verdadera.\n¿Qué quiere decir “obtener evidencia suficiente de que \\(H_0\\) es falsa”? Pues que las pruebas obtenidas hacen que \\(H_0\\) sea inverosímil (difícil de creer) por comparación con \\(H_1\\):\n\nTendremos evidencia de que la moneda está trucada a favor de cara si en nuestra serie de lanzamientos la proporción de caras es tan grande que se nos hace muy difícil creer que la moneda sea equilibrada.\nTendremos evidencia de que A es más efectivo que B en la curación de X si en nuestro ensayo la tasa de curación de la enfermedad X con el tratamiento A es tan superior a la de B que se nos hace muy difícil creer que los dos tratamientos tengan la misma efectividad.\n\nSi no obtenemos evidencia suficiente de que \\(H_0\\) es falsa, es decir, si nuestros datos son razonablemente compatibles con \\(H_0\\), no podremos rechazarla. Entonces, aceptaremos la hipótesis nula.\n\nAceptaremos que la moneda no está trucada a favor de cara si en nuestra serie de lanzamientos la proporción de caras no es lo bastante grande como para hacernos dudar de que sea equilibrada\nAceptaremos que A es igual de efectivo que B en la curación de X si en nuestro ensayo la tasa de curación de la enfermedad X con el tratamiento A no es lo bastante superior a la de B como para hacernos dudar de que los dos tratamientos sean igual de efectivos.\n\n\n\n\n\n\n\n\nImportante\n\n\n\nRechazamos la hipótesis nula en favor de la alternativa cuando sería mucha casualidad obtener los resultados obtenidos si la hipótesis nula fuera cierta en vez de la alternativa.\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nSi rechazamos \\(H_0\\) en favor de \\(H_1\\), en general no será porque hayamos demostrado que \\(H_0\\) sea imposible, ni siquiera que sea improbable: tan solo resultará difícil de creer a la vista de los resultados de nuestro experimento.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introducción a los contrastes de hipótesis</span>"
    ]
  },
  {
    "objectID": "referencias.html",
    "href": "referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Bolton, S., & Bon, C. B. (2010). Pharmaceutical Statistics: Practical and Clinical Applications (5th ed.). CRC Press.\nMartínez González, M., Sánchez Villegas, A., & Faulín Fajardo, J. (2020). Bioestadística Amigable. CRC Press.",
    "crumbs": [
      "Referencias"
    ]
  }
]