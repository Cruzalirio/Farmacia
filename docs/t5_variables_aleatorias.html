<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Matemáticas y Estadística Farmacia - 5&nbsp; Variables aleatorias</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./t6_estimacion.html" rel="next">
<link href="./t4_probabilidades.html" rel="prev">
<link href="./Figuras/atlas.jpeg" rel="icon" type="image/jpeg">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./t5_variables_aleatorias.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Variables aleatorias</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Matemáticas y Estadística Farmacia</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/Cruzalirio/Farmacia" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Alternar modo lector">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Presentación</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t1_MatesBasicas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Matemáticas básicas</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t2_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Representación gráfica y análisis de Datos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t3_losDatosTipos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Los datos y sus tipos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t4_probabilidades.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probabilidades</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t5_variables_aleatorias.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Variables aleatorias</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./t6_estimacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Estimadores</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./referencias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#variables-aleatorias-discretas" id="toc-variables-aleatorias-discretas" class="nav-link active" data-scroll-target="#variables-aleatorias-discretas"><span class="header-section-number">5.1</span> Variables aleatorias discretas</a>
  <ul class="collapse">
  <li><a href="#densidad-y-distribución" id="toc-densidad-y-distribución" class="nav-link" data-scroll-target="#densidad-y-distribución"><span class="header-section-number">5.1.1</span> Densidad y distribución</a></li>
  <li><a href="#esperanza" id="toc-esperanza" class="nav-link" data-scroll-target="#esperanza"><span class="header-section-number">5.1.2</span> Esperanza</a></li>
  <li><a href="#varianza-y-desviación-típica" id="toc-varianza-y-desviación-típica" class="nav-link" data-scroll-target="#varianza-y-desviación-típica"><span class="header-section-number">5.1.3</span> Varianza y desviación típica</a></li>
  <li><a href="#cuantiles" id="toc-cuantiles" class="nav-link" data-scroll-target="#cuantiles"><span class="header-section-number">5.1.4</span> Cuantiles</a></li>
  </ul></li>
  <li><a href="#familias-importantes-de-variables-aleatorias-discretas" id="toc-familias-importantes-de-variables-aleatorias-discretas" class="nav-link" data-scroll-target="#familias-importantes-de-variables-aleatorias-discretas"><span class="header-section-number">5.2</span> Familias importantes de variables aleatorias discretas</a>
  <ul class="collapse">
  <li><a href="#variables-aleatorias-binomiales" id="toc-variables-aleatorias-binomiales" class="nav-link" data-scroll-target="#variables-aleatorias-binomiales"><span class="header-section-number">5.2.1</span> Variables aleatorias binomiales</a></li>
  <li><a href="#variables-aleatorias-hipergeométricas" id="toc-variables-aleatorias-hipergeométricas" class="nav-link" data-scroll-target="#variables-aleatorias-hipergeométricas"><span class="header-section-number">5.2.2</span> Variables aleatorias hipergeométricas</a></li>
  <li><a href="#variables-aleatorias-de-poisson" id="toc-variables-aleatorias-de-poisson" class="nav-link" data-scroll-target="#variables-aleatorias-de-poisson"><span class="header-section-number">5.2.3</span> Variables aleatorias de Poisson</a></li>
  </ul></li>
  <li><a href="#variables-aleatorias-continuas" id="toc-variables-aleatorias-continuas" class="nav-link" data-scroll-target="#variables-aleatorias-continuas"><span class="header-section-number">5.3</span> Variables aleatorias continuas</a></li>
  <li><a href="#densidad-y-distribución-1" id="toc-densidad-y-distribución-1" class="nav-link" data-scroll-target="#densidad-y-distribución-1"><span class="header-section-number">5.4</span> Densidad y distribución</a>
  <ul class="collapse">
  <li><a href="#esperanza-varianza-cuantiles" id="toc-esperanza-varianza-cuantiles" class="nav-link" data-scroll-target="#esperanza-varianza-cuantiles"><span class="header-section-number">5.4.1</span> Esperanza, varianza, cuantiles…</a></li>
  <li><a href="#variables-aleatorias-normales" id="toc-variables-aleatorias-normales" class="nav-link" data-scroll-target="#variables-aleatorias-normales"><span class="header-section-number">5.4.2</span> Variables aleatorias normales</a></li>
  <li><a href="#propiedades-básicas" id="toc-propiedades-básicas" class="nav-link" data-scroll-target="#propiedades-básicas"><span class="header-section-number">5.4.3</span> Propiedades básicas</a></li>
  <li><a href="#intervalos-de-referencia" id="toc-intervalos-de-referencia" class="nav-link" data-scroll-target="#intervalos-de-referencia"><span class="header-section-number">5.4.4</span> Intervalos de referencia</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Cruzalirio/Farmacia/edit/main/t5_variables_aleatorias.qmd" class="toc-action"><i class="bi bi-github"></i>Editar esta página</a></li><li><a href="https://github.com/Cruzalirio/Farmacia/issues/new" class="toc-action"><i class="bi empty"></i>Informar de un problema</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Variables aleatorias</span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p>Una <strong>variable aleatoria</strong> sobre una población <span class="math inline">\(\Omega\)</span> es una función <span class="math display">\[
X: \Omega\to  \mathbb{R}
\]</span> que asigna a cada sujeto de <span class="math inline">\(\Omega\)</span> un número real. La idea intuitiva tras esta definición es que una variable aleatoria <strong>mide</strong> una característica de los sujetos de <span class="math inline">\(\Omega\)</span> que varía al azar de un sujeto a otro. Por ejemplo:</p>
<ul>
<li><p>Tomamos una persona de una población y medimos su nivel de colesterol, o su altura, o su número de hijos… En este caso, <span class="math inline">\(\Omega\)</span> es la población bajo estudio, de la que tomamos la persona que medimos.</p></li>
<li><p>Lanzamos una moneda equilibrada 3 veces y contamos las caras que obtenemos. En este caso, <span class="math inline">\(\Omega\)</span> es la población virtual de las secuencias de 3 lanzamientos de una moneda equilibrada.</p></li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Procurad adquirir la disciplina de describir siempre las variables aleatorias mediante una plantilla del estilo de “Tomamos … y medimos …”, para que os quede claro cuál es la unidad muestral, la población y las unidades de medición si es necesario. Por ejemplo:</p>
<ul>
<li>“Tomamos una persona de Mallorca y medimos su altura (en cm)”.</li>
</ul>
<p>Fijaos en que esta variable aleatoria no es la misma que</p>
<ul>
<li>“Tomamos una persona de Mallorca y medimos su altura (en m)”</li>
</ul>
<p>porque, aunque mide lo mismo sobre los mismos sujetos, les asigna números diferentes. Y también es diferente de</p>
<ul>
<li>“Tomamos una persona de Suecia y medimos su altura (en cm)”</li>
</ul>
<p>porque ha cambiado la población.</p>
<p>En cambio en</p>
<ul>
<li>“Lanzamos una moneda 3 veces al aire y contamos las caras”</li>
</ul>
<p>no hay necesidad de especificar unidades, a no ser que vayáis a usar una unidad inesperada (yo qué sé, que contéis las caras en fracciones de docena).</p>
</div>
</div>
<p>Lo que más nos interesará de una variable aleatoria son las probabilidades de los sucesos que define. ¿Y qué tipo de sucesos son los que nos interesan cuando medimos características numéricas? Pues básicamente sucesos definidos mediante igualdades y desigualdades. Por ejemplo, si <span class="math inline">\(X\)</span> es la variable aleatoria “Tomamos una persona y medimos su nivel de colesterol en plasma (en mg/dl)”, nos pueden interesar sucesos del estilo de:</p>
<ul>
<li><p>El conjunto de las personas cuyo nivel de colesterol está entre 200 y 240. Lo denotaremos <span class="math display">\[
200\leqslant X\leqslant 240
\]</span></p></li>
<li><p>El conjunto de las personas cuyo nivel de colesterol es menor o igual que 200: <span class="math display">\[
X\leqslant 200
\]</span></p></li>
<li><p>El conjunto de las personas cuyo nivel de colesterol es mayor que 180: <span class="math display">\[
X&gt;180
\]</span></p></li>
<li><p>El conjunto de las personas cuyo nivel de colesterol es exactamente 180: <span class="math display">\[
X=180
\]</span></p></li>
<li><p>Etc.</p></li>
</ul>
<p>Normalmente, de estos sucesos lo que nos interesará será su probabilidad, y entonces usaremos notaciones del estilo de las siguientes:</p>
<ul>
<li><p><span class="math inline">\(P(200\leqslant X\leqslant 240)\)</span>. Esto denota la probabilidad de que una persona tenga el nivel de colesterol entre 200 y 240. Para abreviar, lo leeremos “la probabilidad de que <span class="math inline">\(X\)</span> esté entre 200 y 240”. Y recordad que nuestras probabilidades son proporciones. Por lo tanto, esta probabilidad es la <strong>proporción</strong> de personas (de la población <span class="math inline">\(\Omega\)</span> donde hayamos definido la variable <span class="math inline">\(X\)</span>) con nivel de colesterol entre 200 y 240.</p></li>
<li><p><span class="math inline">\(P(X\leqslant 200)\)</span>: La probabilidad de que una persona tenga el nivel de colesterol menor o igual que 200; o la probabilidad de que <span class="math inline">\(X\)</span> sea menor o igual que 200; o la proporción de personas con nivel de colesterol menor o igual que 200…</p></li>
<li><p>Etc.</p></li>
</ul>
<p>En este contexto, indicaremos normalmente la <strong>unión</strong> con una <strong>o</strong> y la <strong>intersección</strong> con una <strong>coma</strong>. Por ejemplo, si <span class="math inline">\(X\)</span> es la variable aleatoria “Lanzamos una moneda 6 veces y contamos las caras”:</p>
<ul>
<li><p><span class="math inline">\(P(X\leqslant 2\text{ o }X\geqslant 5)\)</span>: Probabilidad de sacar como máximo 2 caras o como mínimo 5.</p></li>
<li><p><span class="math inline">\(P(2\leqslant X, X&lt; 5)\)</span>: Probabilidad de sacar un número de caras que sea mayor o igual que 2 y menor que 5; es decir, <span class="math inline">\(P(2\leqslant X&lt; 5)\)</span>.</p></li>
</ul>
<p>Dos variables aleatorias <span class="math inline">\(X,Y\)</span> son <strong>independientes</strong> cuando, para todos los pares de valores <span class="math inline">\(a,b\in \mathbb{R}\)</span>, los sucesos <span class="math display">\[
X\leqslant a, Y\leqslant b
\]</span> son independientes, lo que viene a decir intuitivamente que el valor que toma una de ellas sobre un sujeto no influye en la probabilidad del valor que toma la otra.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recordad que los sucesos <span class="math inline">\(X\leqslant a\)</span> e <span class="math inline">\(Y\leqslant b\)</span> son <strong>independientes</strong> cuando satisfacen las tres condiciones equivalentes siguientes: <span class="math display">\[
\begin{array}{l}
P(X\leqslant a|Y\leqslant b)=P(X\leqslant a)\\
P(Y\leqslant b|X\leqslant a)=P(Y\leqslant b)\\
P(X\leqslant a, Y\leqslant b)=P(X\leqslant a)\cdot P(Y\leqslant b)
\end{array}
\]</span></p>
</div>
</div>
<p>Por ejemplo, si tomamos una persona y:</p>
<ul>
<li><p><span class="math inline">\(X\)</span>: le pedimos que lance una moneda 3 veces y contamos las caras</p></li>
<li><p><span class="math inline">\(Y\)</span>: medimos su nivel de colesterol en plasma (en mg/dl)</p></li>
</ul>
<p>(seguramente) <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> son independientes.</p>
<p>Más en general, unas variables aleatorias <span class="math inline">\(X_1,X_2,\ldots,X_n\)</span> son <strong>independientes</strong> cuando, para cualesquiera <span class="math inline">\(a_1,a_2,\ldots,a_n\in \mathbb{R}\)</span>, los sucesos <span class="math display">\[
X_1\leqslant a_1, X_2\leqslant a_2,\ldots, X_n\leqslant a_n
\]</span> son independientes. Es decir, cuando los valores que toman algunas de estas variables sobre un sujeto nunca influyen en los valores que toman las otras.</p>
<p>Vamos a distinguir dos tipos de variables aleatorias:</p>
<ul>
<li><p><strong>Discretas</strong>: Sus posibles valores son datos cuantitativos discretos:</p>
<ul>
<li>Número de caras en 3 lanzamientos de una moneda</li>
<li>Número de hijos</li>
<li>Número de casos nuevos de COVID-19 en un día en Mallorca</li>
</ul></li>
<li><p><strong>Continuas</strong>: Sus posibles valores son datos cuantitativos continuos:</p>
<ul>
<li>Peso</li>
<li>Nivel de colesterol en sangre</li>
<li>Diámetro de un tumor</li>
</ul></li>
</ul>
<p>Empezamos tratando las variables aleatorias discretas.</p>
<section id="variables-aleatorias-discretas" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="variables-aleatorias-discretas"><span class="header-section-number">5.1</span> Variables aleatorias discretas</h2>
<section id="densidad-y-distribución" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="densidad-y-distribución"><span class="header-section-number">5.1.1</span> Densidad y distribución</h3>
<p>Sea <span class="math inline">\(X: \Omega\to \mathbb{R}\)</span> una <strong>variable aleatoria discreta</strong>.</p>
<ul>
<li><p>Su <strong>dominio</strong> <strong><span class="math inline">\(D_X\)</span></strong> es el conjunto de los valores que puede tomar: más concretamente, el conjunto de los <span class="math inline">\(x\in \mathbb{R}\)</span> tales que <span class="math inline">\(P(X=x)&gt;0\)</span>.</p></li>
<li><p>Su <strong>función de densidad</strong> es la función <span class="math inline">\(f_X:\mathbb{R}\to [0,1]\)</span> definida por <span class="math display">\[
f_X(x)=P(X=x)
\]</span> Es decir, la función que asigna a cada <span class="math inline">\(x\in \mathbb{R}\)</span> la probabilidad de que <span class="math inline">\(X\)</span> valga <span class="math inline">\(x\)</span> (la proporción de sujetos de la población en los que <span class="math inline">\(X\)</span> vale <span class="math inline">\(x\)</span>, la frecuencia relativa del valor <span class="math inline">\(x\)</span> en el total de la población…).</p></li>
<li><p>Su <strong>función de distribución</strong> es la función <span class="math inline">\(F_X:\mathbb{R}\to  [0,1]\)</span> definida por <span class="math display">\[
F_X(x)=P(X\leqslant x)
\]</span> Es decir, la función que asigna a cada <span class="math inline">\(x\in \mathbb{R}\)</span> la probabilidad de que el valor de <span class="math inline">\(X\)</span> sea <span class="math inline">\(\leqslant x\)</span> (la proporción de sujetos de la población en los que <span class="math inline">\(X\)</span> vale <span class="math inline">\(\leqslant x\)</span>, la frecuencia relativa acumulada de <span class="math inline">\(x\)</span> en el total de la población… También se la suele llamar <strong>función de probabilidad acumulada</strong> para poner énfasis en esta última interpretación).</p></li>
</ul>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Sea <span class="math inline">\(X\)</span> la variable aleatoria “Lanzamos 3 veces una moneda equilibrada y contamos las caras”. Entonces</p>
<ul>
<li><p>Su <strong>dominio</strong> es el conjunto de sus posibles valores: <span class="math inline">\(D_X=\{0,1,2,3\}\)</span>.</p></li>
<li><p>Su <strong>función de densidad</strong> viene definida por <span class="math inline">\(f_X(x)=P(X=x)\)</span>:</p>
<ul>
<li><span class="math inline">\(f_X(0)=P(X=0)=1/8\)</span> (la probabilidad de sacar 0 caras)</li>
<li><span class="math inline">\(f_X(1)=P(X=1)=3/8\)</span> (la probabilidad de sacar 1 cara)</li>
<li><span class="math inline">\(f_X(2)=P(X=2)=3/8\)</span> (la probabilidad de sacar 2 caras)</li>
<li><span class="math inline">\(f_X(3)=P(X=3)=1/8\)</span> (la probabilidad de sacar 3 caras)</li>
<li><span class="math inline">\(f_X(x)=P(X=x)=0\)</span> para cualquier otro valor de <span class="math inline">\(x\)</span> (la probabilidad de sacar <span class="math inline">\(x\)</span> caras es 0 si <span class="math inline">\(x\notin\{0,1,2,3\}\)</span>)</li>
</ul>
<p>En resumen, la función de densidad de <span class="math inline">\(X\)</span> es <span class="math display">\[
f_X(x) =\left\{
\begin{array}{ll}
1/8 &amp; \text{ si $x=0$}\\
3/8 &amp; \text{ si $x=1$}\\
3/8 &amp; \text{ si $x=2$}\\
1/8 &amp; \text{ si $x=3$}\\
0 &amp; \text{ si $x\neq 0,1,2,3$}
\end{array}\right.
\]</span></p></li>
</ul>
</div>
<p><img src="Figuras/densidad_caras.png" class="img-fluid"></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si <span class="math inline">\(X\)</span> es una variable aleatoria discreta, <span class="math inline">\(P(X\in A)=0\)</span> para cualquier subconjunto <span class="math inline">\(A\)</span> disjunto de <span class="math inline">\(D_X\)</span>, porque <span class="math inline">\(X\)</span> no puede tomar ningún valor de <span class="math inline">\(A\)</span>. Por ejemplo, ¿cuál es la probabilidad de sacar entre 2.5 y 2.7 caras al lanzar 3 veces una moneda? 0 ¿Y la de sacar <span class="math inline">\(\pi\)</span> caras? 0 de nuevo.</p>
</div>
</div>
<ul>
<li><p>Veamos su <strong>función de distribución</strong> <span class="math inline">\(F_X\)</span>. Recordad que <span class="math inline">\(F_X(x)=P(X\leqslant x)\)</span> y que nuestra variable solo puede tomar los valores 0, 1, 2 y 3.</p>
<ul>
<li><p>Si <span class="math inline">\(x&lt;0\)</span>, <span class="math inline">\(F_X(x)=P(X\leqslant x)=0\)</span> porque <span class="math inline">\(X\)</span> no puede tomar ningún valor estrictamente negativo.</p></li>
<li><p>Si <span class="math inline">\(0\leqslant x&lt;1\)</span>, el único valor <span class="math inline">\(\leqslant x\)</span> que puede tomar <span class="math inline">\(X\)</span> es el 0 y por lo tanto <span class="math display">\[
  F_X(x)=P(X\leqslant x)=P(X=0)=f_X(0)=1/8
  \]</span></p></li>
<li><p>Si <span class="math inline">\(1\leqslant x&lt;2\)</span>, los únicos valores <span class="math inline">\(\leqslant x\)</span> que puede tomar <span class="math inline">\(X\)</span> son 0 y 1 y por lo tanto <span class="math display">\[
  \begin{array}{rl}
  F_X(x)\!\!\!\!\! &amp; =P(X\leqslant x)=P(X=0\text{ o }X=1)\\ &amp; =f_X(0)+f_X(1)=4/8=1/2
  \end{array}
  \]</span></p></li>
<li><p>Si <span class="math inline">\(2\leqslant x&lt;3\)</span>, los únicos valores <span class="math inline">\(\leqslant x\)</span> que puede tomar <span class="math inline">\(X\)</span> son 0, 1 y 2 y por lo tanto <span class="math display">\[
  \begin{array}{rl}
F_X(x)\!\!\!\!\! &amp; =P(X\leqslant x)=P(X=0\text{ o }X=1\text{ o }X=2)\\ &amp;  =f_X(0)+f_X(1)+f_X(2)=7/8
  \end{array}
  \]</span></p></li>
<li><p>Si <span class="math inline">\(x\geqslant 3\)</span>, seguro que obtenemos un número de caras <span class="math inline">\(\leqslant x\)</span> y por lo tanto <span class="math inline">\(F_X(x)=P(X\leqslant x)=1\)</span>.</p></li>
</ul>
<p>Así pues, la función <span class="math inline">\(F_X\)</span> es la función <span class="math display">\[
F_X(x) =\left\{
\begin{array}{ll}
0 &amp; \text{ si $x&lt;0$}\\
1/8 &amp; \text{ si $0\leqslant x&lt; 1$}\\
4/8 &amp; \text{ si $1\leqslant x&lt; 2$}\\
7/8 &amp; \text{ si $2\leqslant x&lt; 3$}\\
1 &amp; \text{ si $3\leqslant x$}
\end{array}\right.
\]</span> Su gráfico es el siguiente:</p></li>
</ul>
<p><img src="Figuras/distri_caras.png" class="img-fluid"></p>
<p>Observad en este gráfico que esta función de distribución <span class="math inline">\(F_X\)</span> es creciente y escalonada, y el valor en los puntos de escalón es el superior. Esto es general. Si <span class="math inline">\(X\)</span> es una variable aleatoria discreta:</p>
<ul>
<li><p><span class="math inline">\(F_X\)</span> es una función <strong>escalonada</strong>, con saltos en los valores de <span class="math inline">\(D_X\)</span>, que son los únicos con probabilidad estrictamente mayor que 0 y por lo tanto los únicos que “suman” probabilidad.</p></li>
<li><p><span class="math inline">\(F_X\)</span> es <strong>creciente</strong>, porque si <span class="math inline">\(x\leqslant y\)</span>, todos los sujetos tales que <span class="math inline">\(X\leqslant x\)</span> también cumplen que <span class="math inline">\(X\leqslant y\)</span>, y por lo tanto <span class="math display">\[
P(X\leqslant x)\leqslant P(X\leqslant y).
\]</span></p></li>
<li><p>Si <span class="math inline">\(x_0,y_0\in D_X\)</span> y <span class="math inline">\(x_0&lt;y_0\)</span>, entonces <span class="math inline">\(F_X(x_0)&lt; F_X(y_0)\)</span>, porque <span class="math display">\[
\begin{array}{rl}
F_X(x_0)\!\!\!\!\! &amp; =P(X\leqslant x_0)&lt;P(X\leqslant x_0)+P(X=y_0)\\
&amp; =P(X\leqslant x_0\text{ o }X=y_0)\leqslant P(X\leqslant y_0)=F_X(y_0)
\end{array}
\]</span></p></li>
<li><p>Como los valores que toma <span class="math inline">\(F_X\)</span> son probabilidades, no pueden ser ni menores que 0 ni mayores que 1.</p></li>
</ul>
<p>El conocimiento de <span class="math inline">\(f_X\)</span>, más las reglas del cálculo de probabilidades, permite calcular la probabilidad de cualquier suceso relacionado con <span class="math inline">\(X\)</span>: <span class="math display">\[
P(X\in A) =\sum_{x\in A} P(X=x) = \sum_{x\in A} f_X(x)
\]</span> En particular <span class="math display">\[
F_X(x_0)=P(X\leqslant x_0)=\sum_{x\leqslant x_0} f_X(x)
\]</span></p>
<p>La <strong>moda</strong> de una variable aleatoria discreta <span class="math inline">\(X\)</span> es el valor (o los valores) <span class="math inline">\(x_0\)</span> tal que <span class="math inline">\(f_X(x_0)=P(X=x_0)\)</span> es máximo. Se trata por lo tanto del “valor más frecuente de <span class="math inline">\(X\)</span>” en la población. Por ejemplo, para nuestra variable aleatoria que cuenta el número de caras en 3 lanzamientos de una moneda equilibrada, la moda son los valores 1 y 2.</p>
<p>Hay un aspecto de las variables aleatorias discretas sobre el que queremos llamar la atención, sobre todo por comparación con las variables continuas:</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>Los valores de <span class="math inline">\(P(X\leqslant x)\)</span> y <span class="math inline">\(P(X&lt;x)\)</span> pueden ser diferentes.</p>
</div>
</div>
<p>De hecho, como <span class="math display">\[
P(X\leqslant x)=P(X&lt;x)+P(X=x),
\]</span> se tiene que <span class="math inline">\(P(X&lt; x)\neq P(X\leqslant x)\)</span> exactamente cuando <span class="math inline">\(x\in D_X\)</span>.</p>
<p>Por ejemplo, con la variable <span class="math inline">\(X\)</span> “Lanzamos una moneda equilibrada 3 veces y contamos las caras”:</p>
<ul>
<li><p>La probabilidad de sacar 2 caras o menos ya la hemos calculado, y es <span class="math inline">\(P(X\leqslant 2)=7/8\)</span></p></li>
<li><p>Pero la probabilidad de sacar <strong>menos de 2 caras</strong>, <span class="math inline">\(P(X&lt;2)\)</span>, es la de sacar 1 cara o menos, por lo tanto <span class="math inline">\(P(X&lt;2)=P(X\leqslant 1)=4/8\)</span>.</p></li>
</ul>
<p><strong>Ejercicio</strong> Considerad la variable aleatoria <span class="math inline">\(X\)</span> “Lanzamos una moneda equilibrada al aire tantas veces como sea necesario hasta que salga una cara por primera vez, y contamos cuántas veces la hemos tenido que lanzar”.</p>
<ol type="1">
<li>¿Cuál es su dominio?</li>
<li>¿Cuál es su función de densidad?</li>
<li>¿Cuál es su moda? ¿Qué significa?</li>
<li>¿Cuál es su función de distribución?</li>
</ol>
</section>
<section id="esperanza" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="esperanza"><span class="header-section-number">5.1.2</span> Esperanza</h3>
<p>Cuando tomamos una muestra de una variable aleatoria <span class="math inline">\(X\)</span> definida sobre una población, podemos calcular la media y la desviación típica de sus valores para obtener una idea de cuál es su valor central y de la variabilidad de sus valores. También nos podemos preguntar por este tipo de información para el total de la población: ¿cuál es el “valor medio” de <span class="math inline">\(X\)</span> sobre toda la población? ¿<span class="math inline">\(X\)</span> toma valores muy dispersos, o más bien concentrados alrededor de este valor medio? Lo primero lo medimos con la <strong>media</strong>, o <strong>esperanza</strong>, de <span class="math inline">\(X\)</span>, y lo segundo con su <strong>desviación típica</strong>. Empecemos con la primera.</p>
<p>La <strong>media</strong>, o <strong>esperanza</strong> (o <strong>valor esperado</strong>, <strong>valor medio</strong>, <strong>valor promedio</strong>…), de una variable aleatoria discreta <span class="math inline">\(X\)</span> con densidad <span class="math inline">\(f_X:D_X\to  [0,1]\)</span> es <span class="math display">\[
E(X)=\sum_{x\in D_X} x\cdot f_X(x)
\]</span> A veces también la denotaremos por <span class="math inline">\(\mu_X\)</span>.</p>
<p>La interpretación natural de <span class="math inline">\(E(X)\)</span> es que es <strong>la media de los valores de la variable <span class="math inline">\(X\)</span> en el total de la población <span class="math inline">\(\Omega\)</span></strong>. En efecto, como <span class="math inline">\(f_X(x)=P(X=x)\)</span> es la proporción de los sujetos de <span class="math inline">\(\Omega\)</span> en los que <span class="math inline">\(X\)</span> vale <span class="math inline">\(x\)</span>, entonces <span class="math display">\[
E(X)=\sum_{x\in D_X} x\cdot f_X(x)
\]</span> es el promedio del valor de <span class="math inline">\(X\)</span> sobre todos los elementos de <span class="math inline">\(\Omega\)</span>. Comparadlo con el ejemplo siguiente.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si, en una clase, un 10% de los estudiantes han sacado un 4 en un examen, un 20% un 6, un 50% un 8 y un 20% un 10, ¿cuál ha sido la nota media del examen?</p>
</div>
</div>
<p>Suponemos que calcularíais esta media como <span class="math display">\[
4\cdot 0.1+6\cdot 0.2+8\cdot 0.5+10\cdot 0.2=7.6
\]</span> Pues este valor es la <strong>media</strong> de la variable aleatoria <span class="math inline">\(X\)</span> “Tomo un estudiante de esta clase y miro qué nota ha sacado en este examen”: <span class="math display">\[
\begin{array}{rl}
E(X)\!\!\!\!\! &amp;=4\cdot P(X=4)+6\cdot P(X=6)+8\cdot P(X=8)+10\cdot P(X=10)\\
&amp; = 4\cdot 0.1+6\cdot 0.2+8\cdot 0.5+10\cdot 0.2=7.6
\end{array}
\]</span></p>
<p>Aparte de su interpretación como “el promedio de <span class="math inline">\(X\)</span> en el total de la población”, <span class="math inline">\(E(X)\)</span> es también el <strong>valor esperado de <span class="math inline">\(X\)</span></strong>, en el sentido siguiente:</p>
<blockquote class="blockquote">
<p>Suponed que tomamos una muestra aleatoria de <span class="math inline">\(n\)</span> sujetos de la población, medimos <span class="math inline">\(X\)</span> sobre ellos y calculamos la media aritmética de los <span class="math inline">\(n\)</span> valores obtenidos. Entonces, cuando el tamaño <span class="math inline">\(n\)</span> de la muestra tiende a <span class="math inline">\(\infty\)</span>, esta media aritmética tiende a valer <span class="math inline">\(E(X)\)</span> “casi seguro” (en el sentido de que la probabilidad de que su límite sea <span class="math inline">\(E(X)\)</span> es 1).</p>
</blockquote>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>Aquí probabilidad 1 no significa “total y absolutamente seguro”, porque este límite va a ser una variable aleatoria continua, donde, como veremos en la próxima lección, probabiilidad 0 no significa imposible ni probabilidad 1 significa 100% seguro. Por ejemplo, si repetís muchas veces el proceso de lanzar una moneda equilibrada 3 veces, por pura mala suerte puede pasar que en todas las ocasiones saquéis tres caras. Casi seguro que no pasa, pero no podemos estar 100% seguros de que no pase, no es imposible.</p>
</div>
</div>
<p>Es decir: si midiéramos <span class="math inline">\(X\)</span> sobre <strong>muchos</strong> sujetos elegidos al azar, <strong>de media casi seguro que obtendríamos un valor muy próximo a <span class="math inline">\(E(X)\)</span></strong>.</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Seguimos con la variable aleatoria <span class="math inline">\(X\)</span> “Lanzamos una moneda equilibrada al aire 3 veces y contamos las caras”. Su esperanza es <span class="math display">\[
E(X)= 0\cdot \frac{1}{8}+1\cdot \frac{3}{8}+2\cdot \frac{3}{8}+3\cdot \frac{1}{8}=1.5
\]</span></p>
</div>
<p>Esto nos dice que:</p>
<ul>
<li><p>La <strong>media</strong> de <span class="math inline">\(X\)</span> es 1.5: El valor medio de la variable <span class="math inline">\(X\)</span> sobre toda la población de secuencias de 3 lanzamientos de una moneda equilibrada es 1.5.</p></li>
<li><p>El <strong>valor esperado</strong> de <span class="math inline">\(X\)</span> es 1.5: Si repitiésemos muchas veces el experimento de lanzar la moneda 3 veces y contar las caras, la media de los resultados obtenidos daría, muy probablemente, un valor muy cercano a 1.5. Abreviamos esto diciendo que <strong>si lanzamos la moneda 3 veces, de media esperamos sacar 1.5 caras</strong>.</p></li>
</ul>
<p>Más en general, si <span class="math inline">\(g:\mathbb{R}\to  \mathbb{R}\)</span> es una aplicación, el valor esperado de la composición <span class="math inline">\(\Omega \stackrel{X}{\longrightarrow} \mathbb{R}\stackrel{g}{\longrightarrow}\mathbb{R}\)</span> es <span class="math display">\[
E(g(X))=\sum_{x\in D_X} g(x)\cdot f_X(x)  
\]</span> De nuevo, su interpretación natural es que es el promedio de <span class="math inline">\(g(X)\)</span> sobre la población en la que medimos <span class="math inline">\(X\)</span>, y también es el valor “esperado” de <span class="math inline">\(g(X)\)</span> en el sentido anterior.</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Si lanzamos una moneda equilibrada al aire 3 veces, contamos las caras y elevamos este número de caras al cuadrado, ¿qué valor esperamos obtener, de media? Será la esperanza de <span class="math inline">\(X^2\)</span>, siendo <span class="math inline">\(X\)</span> la variable aleatoria “Lanzamos una moneda equilibrada al aire 3 veces y contamos las caras” (o sea, <span class="math inline">\(X^2\)</span> es la variable aleatoria “Lanzamos una moneda equilibrada al aire 3 veces, contamos las caras y elevamos este número al cuadrado”):</p>
<p><span class="math display">\[
E(X^2)= 0\cdot \frac{1}{8}+1\cdot \frac{3}{8}+2^2\cdot \frac{3}{8}+3^2\cdot \frac{1}{8}=3
\]</span></p>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>En los dos últimos ejemplos hemos visto que si <span class="math inline">\(X\)</span> es la variable aleatoria que cuenta el número de caras en 3 lanzamientos de una moneda equilibrada, <span class="math inline">\(E(X^2)=3\)</span> pero <span class="math inline">\(E(X)^2=1.5^2=2.25\)</span>. Por lo tanto, puede pasar que <span class="math inline">\(E(X^2) \neq E(X)^2\)</span>. De hecho, es lo más común.</p>
<p>Más en general, dada una aplicación <span class="math inline">\(g:\mathbb{R}\to  \mathbb{R}\)</span>, lo usual es que <span class="math inline">\(E(g(X))\neq g(E(X))\)</span>.</p>
</div>
</div>
<p>La esperanza de las variables aleatorias discretas tiene las propiedades siguientes, todas razonables si las interpretáis en términos del valor promedio de <span class="math inline">\(X\)</span> sobre la población:</p>
<ul>
<li><p>Sea <span class="math inline">\(b\)</span> una variable aleatoria constante, que sobre todos los individuos de la población toma el mismo valor <span class="math inline">\(b\in \mathbb{R}\)</span>. Entonces <span class="math inline">\(E(b)=b\)</span>.</p>
<p>Si en una clase todo el mundo saca un 8 de un examen, la nota media es 8, ¿no?</p></li>
<li><p>La esperanza es <strong>lineal</strong>:</p>
<ul>
<li><p>Si <span class="math inline">\(a,b\in \mathbb{R}\)</span>, <span class="math inline">\(E(aX+b)=aE(X)+b\)</span></p>
<p>Si en una clase la media de un examen ha sido un 6 y decidimos multiplicar por 1.2 todas las notas y sumarles 1 punto, la nueva nota media será 1.2·6+1=8.2, ¿no?</p></li>
<li><p>Si <span class="math inline">\(Y\)</span> es otra variable aleatoria, <span class="math inline">\(E(X+Y)=E(X)+E(Y)\)</span>.</p>
<p>Si en una clase la media de la parte de cuestiones de un examen ha sido un 3.5 (sobre 5) y la de la parte de ejercicios ha sido un 3 (sobre 5) y la nota del examen es la suma sus dos partes, la nota media del examen será un 3.5+3=6.5, ¿no?</p></li>
<li><p>Más en general, si <span class="math inline">\(X_1,\ldots,X_n\)</span> son variables aleatorias y <span class="math inline">\(a_1,\ldots,a_n,b\in \mathbb{R}\)</span>, <span class="math display">\[
E(a_1X_1+\cdots +a_nX_n+b)=a_1E(X_1)+\cdots +a_nE(X_n)+b
\]</span></p></li>
</ul></li>
<li><p>La esperanza es <strong>monótona creciente</strong>: Si <span class="math inline">\(X\leqslant Y\)</span> (en el sentido de que, para cada sujeto de la población <span class="math inline">\(\Omega\)</span>, su valor de <span class="math inline">\(X\)</span> es menor o igual que su valor de <span class="math inline">\(Y\)</span>), entonces <span class="math inline">\(E(X)\leqslant E(Y)\)</span>.</p>
<p>Si todos sacáis mejor nota de Anatomía que de Bioestadística, la nota media de Anatomía será mayor que la de Bioestadística, ¿no?</p></li>
</ul>
</section>
<section id="varianza-y-desviación-típica" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="varianza-y-desviación-típica"><span class="header-section-number">5.1.3</span> Varianza y desviación típica</h3>
<p>La <strong>varianza</strong> de una variable aleatoria discreta <span class="math inline">\(X\)</span> es <span class="math display">\[
\sigma^2(X) =E((X-\mu_X)^2) =\sum_{x\in D_X} (x-\mu_X)^2\cdot f_X(x)
\]</span> Es decir, es el valor medio del cuadrado de la diferencia entre <span class="math inline">\(X\)</span> y su media <span class="math inline">\(\mu_X\)</span>. También la denotaremos <span class="math inline">\(\sigma_X^2\)</span>.</p>
<p>Fijaos en que se trata de la traducción “poblacional” de la definición de varianza para una muestra, y por lo tanto sirve para medir lo mismo que aquella: la dispersión de los resultados de <span class="math inline">\(X\)</span> respecto de la media. Solo que ahora para toda la población.</p>
<p>La identidad siguiente os puede ser útil para calcular varianzas “a mano”. Ya vimos en la lección anterior esta igualdad para la varianza de una muestra.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[\sigma^2(X)=E(X^2)-\mu_X^2\]</span>.</p>
</div>
</div>
<p>Operemos (y recordad que <span class="math inline">\(E(X)=\mu_X\)</span>) <span class="math display">\[
\begin{array}{rl}
\sigma^2(X)\!\!\!\!\! &amp; =E((X-\mu_X)^2)=E(X^2-2\mu_X\cdot X+\mu_X^2)\\
&amp; = E(X^2)-2\mu_X\cdot E(X)+\mu_X^2\\
&amp; \text{(por la linealidad de $E$)}\\
&amp; = E(X^2)-2\mu_X^2+\mu_X^2=E(X^2)-\mu_X^2
\end{array}
\]</span></p>
<p>:::{.callout note} En particular, si <span class="math inline">\(X\)</span> no es una variable constante, <span class="math inline">\(\sigma^2(X)\)</span> es una suma de cuadrados, algunos de los cuales va a ser diferente de 0 y por lo tanto estrictamente positivo, en cuyo caso <span class="math inline">\(E(X^2)-\mu_X^2=\sigma^2(X)&gt;0\)</span>: el valor esperado de <span class="math inline">\(X^2\)</span> es mayor que el cuadrado del valor esperado de <span class="math inline">\(X\)</span>. :::</p>
<p>La <strong>desviación típica</strong> (o <strong>desviación estándar</strong>) de una variable aleatoria discreta <span class="math inline">\(X\)</span> es la raíz cuadrada positiva de su varianza: <span class="math display">\[
\sigma(X)=+\sqrt{\sigma^2(X)}
\]</span> También mide la dispersión de los valores de <span class="math inline">\(X\)</span> respecto de la media. La denotaremos a veces por <span class="math inline">\(\sigma_X\)</span>.</p>
<p>El motivo para introducir la varianza <strong>y</strong> la desviación típica para medir la dispersión de los valores de <span class="math inline">\(X\)</span> es la misma que en estadística descriptiva: la varianza es más fácil de manejar (no involucra raíces cuadradas) pero sus unidades son las de <span class="math inline">\(X\)</span> al cuadrado, mientras que las unidades de la desviación típica son las de <span class="math inline">\(X\)</span>, y por lo tanto su valor es más fácil de interpretar.</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Seguimos con la variable aleatoria <span class="math inline">\(X\)</span> “Lanzamos una moneda equilibrada 3 veces y contamos las caras”. Su varianza es:</p>
<p><span class="math display">\[
\begin{array}{rl}
\sigma^2(X) \!\!\!\!\! &amp; \displaystyle=(0-1.5)^2\cdot \frac{1}{8}+(1-1.5)^2\cdot \frac{3}{8}\\ &amp;\displaystyle\qquad +(2-1.5)^2\cdot \frac{3}{8}+(3-1.5)^2\cdot \frac{1}{8}=0.75
\end{array}
\]</span> Si recordamos que <span class="math inline">\(\mu_X=E(X)=1.5\)</span> y <span class="math inline">\(E(X^2)=3\)</span>, podemos ver que <span class="math display">\[
E(X^2)-\mu_X^2=3-1.5^2=0.75=\sigma^2(X)
\]</span> Su desviación típica es <span class="math display">\[
\sigma(X) =\sqrt{\sigma^2(X)}=\sqrt{0.75}= 0.866
\]</span></p>
</div>
<p>Veamos algunas propiedades de la varianza y la desviación típica:</p>
<ul>
<li>Si <span class="math inline">\(b\)</span> es una variable aleatoria constante que sobre todos los individuos de la población toma el valor <span class="math inline">\(b\in \mathbb{R}\)</span>, es decir, tal que <span class="math inline">\(D_b=\{b\}\)</span>, entonces <span class="math inline">\(\mu_b=b\)</span> y <span class="math inline">\(\sigma(b)^2=(b-b)f_b(b)=0\)</span>..</li>
</ul>
<p>Una variable aleatoria constante tiene cero dispersión, ¿no?</p>
<p>El recíproco también es cierto:</p>
<p>Si <span class="math inline">\(0=\sigma^2(X)=\sum_{x\in D_X} (x-\mu_X)^2\cdot f_X(x)\)</span>, entonces todos los sumandos son 0, y como <span class="math inline">\(f_X(x)\neq 0\)</span> si <span class="math inline">\(x\in D_X\)</span>, concluimos que, para todo <span class="math inline">\(x\in D_X\)</span>, <span class="math inline">\(x=\mu_X\)</span>: es decir, que el dominio está formado por un solo número y la variable aleatoria es constante.</p>
<ul>
<li><span class="math inline">\(\sigma(aX+b)^2=a^2\cdot \sigma^2(X)\)</span>.</li>
</ul>
<p>En efecto <span class="math display">\[
\begin{array}{l}
\sigma(aX+b)^2 =E((aX+b)^2)-E(aX+b)^2\\
\quad = E(a^2X^2+2abX+b^2)-(aE(X)+b)^2\\
\quad \text{(por la linealidad de $E$)}\\
\quad = a^2E(X^2)+2abE(X)+b^2-a^2E(X)^2-2abE(X)-b^2\\
\quad \text{(de nuevo, por la linealidad de $E$)}\\
\quad = a^2(E(X^2)-E(X)^2)=a^2\sigma^2(X)
\end{array}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Sumar un valor constante <span class="math inline">\(b\)</span> a una variable aleatoria no modifica su dispersión: si en un examen a todos los estudiantes les sumamos 1 punto, la media va a subir 1 punto pero la dispersión de las notas alrededor de esta media va a ser la misma que antes de sumarlo.</p>
</div>
</div>
<ul>
<li><p><span class="math inline">\(\sigma(aX+b)=|a|\cdot \sigma(X)\)</span> (recordad que la desviación típica es positiva y que <span class="math inline">\(+\sqrt{a^2}=|a|\)</span>).</p></li>
<li><p>Si <span class="math inline">\(X,Y\)</span> son variables aleatorias <strong>independientes</strong>, <span class="math display">\[
\sigma(X+Y)^2=\sigma^2(X)+\sigma(Y)^2
\]</span> y por lo tanto <span class="math display">\[
\sigma(X+Y)=\sqrt{\sigma^2(X)+\sigma(Y)^2}
\]</span> Si no son independientes, en general esta igualdad es falsa. Por poner un ejemplo extremo, <span class="math display">\[
\sigma(X+X)^2=4\sigma^2(X)\neq \sigma^2(X)+\sigma^2(X).
\]</span></p></li>
<li><p>Más en general, si <span class="math inline">\(X_1,\ldots,X_n\)</span> son variables aleatorias <strong>independientes</strong> y <span class="math inline">\(a_1,\ldots,a_n,b\in \mathbb{R}\)</span>, <span class="math display">\[
   \sigma(a_1X_1+\cdots +a_nX_n+b)^2=a_1^2\sigma(X_1)^2+\cdots +a_n^2\sigma(X_n)^2
    \]</span></p></li>
</ul>
</section>
<section id="cuantiles" class="level3" data-number="5.1.4">
<h3 data-number="5.1.4" class="anchored" data-anchor-id="cuantiles"><span class="header-section-number">5.1.4</span> Cuantiles</h3>
<p>Sea <span class="math inline">\(p\)</span> tal que <span class="math inline">\(0&lt;p&lt;1\)</span>. El <strong>cuantil de orden <span class="math inline">\(p\)</span></strong> (o <strong><span class="math inline">\(p\)</span>-cuantil</strong>) de una variable aleatoria <span class="math inline">\(X\)</span> discreta es el menor valor <span class="math inline">\(x_p\)</span> de su dominio <span class="math inline">\(D_X\)</span> tal que <span class="math inline">\(P(X\leqslant x_p)\geqslant p\)</span>; es decir, es el valor <span class="math inline">\(x_p\in D_X\)</span> tal que <span class="math inline">\(P(X\leqslant x_p)\geqslant p\)</span> pero <span class="math inline">\(P(X&lt; x_p)&lt;p\)</span>.</p>
<p>Por ejemplo, que el 0.25-cuantil de una variable aleatoria discreta <span class="math inline">\(X\)</span> sea, pongamos, 8, significa que 8 es el menor valor del dominio de <span class="math inline">\(X\)</span> tal que su probabilidad acumulada llega a (o pasa de) 0.25. En otras palabras, que al menos una cuarta parte de la población tiene un valor de <span class="math inline">\(X\)</span> menor o igual que 8, pero estrictamente menos de un 25% de la población tiene un valor de <span class="math inline">\(X\)</span> estrictamente menor que 8.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si existe algún <span class="math inline">\(x_p\in D_X\)</span> tal que <span class="math inline">\(F_X(x_p)(=P(X\leqslant x_p))=p\)</span>, entonces el <span class="math inline">\(p\)</span>-cuantil es ese <span class="math inline">\(x_p\)</span>, porque si <span class="math inline">\(x&lt;x_p\)</span>, <span class="math inline">\(P(X\leqslant x)&lt;P(X\leqslant x_p)=F_X(x_p)=p\)</span> y por lo tanto es el menor elemento del dominio con probabilidad acumulada al menos (en este caso, exactamente) <span class="math inline">\(p\)</span>.</p>
</div>
</div>
<p>Como en estadística descriptiva, algunos cuantiles de variables aleatorias tienen nombres propios. Por ejemplo:</p>
<ul>
<li><p>La <strong>mediana</strong> de <span class="math inline">\(X\)</span> es su 0.5-cuantil</p></li>
<li><p>El <strong>primer</strong> y el <strong>tercer cuartiles</strong> de <span class="math inline">\(X\)</span> son sus <span class="math inline">\(0.25\)</span>-cuantil y <span class="math inline">\(0.75\)</span>-cuantil, respectivamente.</p></li>
<li><p>Etc.</p></li>
</ul>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Seguimos con la variable aleatoria <span class="math inline">\(X\)</span> “Lanzamos una moneda equilibrada 3 veces y contamos las caras”. Recordemos que su función de distribución es</p>
<p><span class="math display">\[
F_X(x)=\left\{
\begin{array}{ll}
0 &amp; \text{ si $x&lt;0$}\\
0.125 &amp; \text{ si $0\leqslant x&lt;1$}\\
0.5 &amp; \text{ si $1\leqslant x&lt;2$}\\
0.875 &amp; \text{ si $2\leqslant x&lt;3$}\\
1 &amp; \text{ si $3\leqslant x $}
\end{array}
\right.
\]</span></p>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" style="width:60.0%"></p>
</figure>
</div>
</div>
</div>
<p>Entonces, por ejemplo:</p>
<ul>
<li><p>Su 0.1-cuantil es 0</p></li>
<li><p>Su 0.25-cuantil es 1</p></li>
<li><p>Su mediana es 1</p></li>
<li><p>Su 0.75-cuantil es 2</p></li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>Aunque usamos “media”, “varianza”, “cuantiles”, etc. tanto para muestras como para variables aleatorias, no debéis confundirlas.</p>
<ul>
<li><p>Una <strong>variable aleatoria</strong> representa una característica númerica de los sujetos de una <strong>población</strong>. Por ejemplo:</p>
<ul>
<li><p>“Tomamos un estudiante de farmacia y medimos su altura en m.”</p>
<p>La <em>media</em> y la <em>varianza</em> de esta variable son las de <strong>toda la población de estudiantes de farmacia</strong>.</p></li>
</ul></li>
<li><p>Una <strong>muestra</strong> de una variable aleatoria son los valores de la misma sobre un <strong>subconjunto</strong> (relativamente pequeño) de la población. Por ejemplo:</p>
<ul>
<li><p>Medimos las alturas (en m) de 50 estudiantes de farmacia de este curso.</p>
<p>La <em>media</em> y la <em>varianza</em> de esta muestra son solo las de esas 50 alturas.</p></li>
</ul></li>
</ul>
</div>
</div>
<p>Cuando queramos destacar que una media, una varianza etc. son las de una variable aleatoria y por lo tanto refieren a toda una población, los calificaremos de <strong>poblacionales</strong>.</p>
</section>
</section>
<section id="familias-importantes-de-variables-aleatorias-discretas" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="familias-importantes-de-variables-aleatorias-discretas"><span class="header-section-number">5.2</span> Familias importantes de variables aleatorias discretas</h2>
<p>Vamos a describir tres familias de variables aleatorias “distinguidas” que tenéis que conocer:</p>
<ul>
<li>Binomial</li>
<li>Hipergeométrica</li>
<li>Poisson</li>
</ul>
<p>Cada una de estas familias tienen un tipo específico de función de densidad, que depende de uno o varios <strong>parámetros</strong>.</p>
<p>De estas familias de variables tenéis que saber:</p>
<ul>
<li>Distinguirlas: saber cuando una variable aleatoria es de una de estas familias.</li>
<li>Sus propiedades más básicas, como por ejemplo cuáles son sus parámetros, cuál es su valor esperado y si su densidad es simétrica o presenta una cola a algún lado.</li>
<li>Usar algún programa o alguna aplicación para calcular cosas con ellas cuando sea necesario.</li>
</ul>
<section id="variables-aleatorias-binomiales" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="variables-aleatorias-binomiales"><span class="header-section-number">5.2.1</span> Variables aleatorias binomiales</h3>
<p>Un <strong>experimento de Bernoulli</strong> es una acción con solo dos posibles resultados, que identificamos con “Éxito” (<span class="math inline">\(E\)</span>) y “Fracaso” (<span class="math inline">\(F\)</span>). Por ejemplo, lanzar un dado cúbico y mirar si ha salido un 6 (<span class="math inline">\(E\)</span>: sacar un 6; <span class="math inline">\(F\)</span>: cualquier otro resultado). La <strong>probabilidad de éxito</strong> <span class="math inline">\(p\)</span> de un experimento de Bernoulli es la probabilidad de obtener <span class="math inline">\(E\)</span>. Es decir, <span class="math inline">\(P(E)=p\)</span>. Naturalmente, entonces, <span class="math inline">\(P(F)=1-p\)</span>. En el ejemplo del dado, donde <span class="math inline">\(E\)</span> es sacar un 6, <span class="math inline">\(p=1/6\)</span>.</p>
<p>Otros ejemplos de experimentos de Bernoulli:</p>
<ul>
<li><p>Lanzar una moneda equilibrada y mirar si da cara:</p>
<ul>
<li><span class="math inline">\(E\)</span>: Sacar cara</li>
<li><span class="math inline">\(p=1/2\)</span></li>
</ul></li>
<li><p>Realizar un test PCR de COVID-19 a una persona y mirar si da positivo:</p>
<ul>
<li><span class="math inline">\(E\)</span>: Dar positivo</li>
<li><span class="math inline">\(p\)</span>: La proporción de personas que dan positivo en el test (su <strong>tasa de positividad</strong>).</li>
</ul></li>
</ul>
<p>Una <strong>variable aleatoria de Bernoulli de parámetro <span class="math inline">\(p\)</span></strong> (abreviadamente, <span class="math inline">\(Be(p)\)</span>) es una variable aleatoria <span class="math inline">\(X\)</span> consistente en efectuar un experimento de Bernoulli y dar 1 si se ha obtenido un éxito y 0 si se ha obtenido un fracaso.</p>
<p>Una <strong>variable aleatoria binomial de parámetros <span class="math inline">\(n\)</span> y <span class="math inline">\(p\)</span></strong> (abreviadamente, <span class="math inline">\(B(n,p)\)</span>) es una variable aleatoria <span class="math inline">\(X\)</span> que cuenta el número de éxitos <span class="math inline">\(E\)</span> en una secuencia de <span class="math inline">\(n\)</span> repeticiones independientes de un mismo experimento de Bernoulli de probabilidad de éxito <span class="math inline">\(p\)</span>. <strong>Independientes</strong> significa que las <span class="math inline">\(n\)</span> variables aleatorias de Bernoulli, una para cada repetición del experimento de Bernoulli, son independientes; intuitivamente, que el resultado de cada repetición en la secuencia no depende de los resultados de las otras.</p>
<p>Llamaremos a <span class="math inline">\(n\)</span> el <strong>tamaño de las muestras</strong> y a <span class="math inline">\(p\)</span> la <strong>probabilidad</strong> (<strong>poblacional</strong>) <strong>de éxito</strong>. A veces también diremos de una variable <span class="math inline">\(X\)</span> de tipo <span class="math inline">\(B(n,p)\)</span> que <strong>tiene distribución binomial de parámetros <span class="math inline">\(n\)</span> y <span class="math inline">\(p\)</span></strong>.</p>
<p>Por ejemplo:</p>
<ul>
<li><p>Una variable de Bernoulli <span class="math inline">\(Be(p)\)</span> es una variable binomial <span class="math inline">\(B(1,p)\)</span>.</p></li>
<li><p>Lanzar una moneda equilibrada 10 veces y contar las caras es una variable binomial <span class="math inline">\(B(10,0.5)\)</span></p></li>
<li><p>Elegir 20 personas al azar, una tras otra, permitiendo repeticiones y de manera independiente las unas de las otras, realizar sobre ellas un test PCR de COVID-19 y contar cuántos dan positivo, es una variable binomial <span class="math inline">\(B(20,p)\)</span> con <span class="math inline">\(p\)</span> la tasa de positividad del test.</p></li>
</ul>
<p>Tenemos el resultado siguiente.</p>
<p><strong>Teorema:</strong> Si <span class="math inline">\(X\)</span> es una variable <span class="math inline">\(B(n,p)\)</span>:</p>
<ul>
<li><p>Su dominio es <span class="math inline">\(D_X=\{0,1,\ldots,n\}\)</span></p></li>
<li><p>Su función de densidad es <span class="math display">\[
f_X(k)=\left\{\begin{array}{ll}
\displaystyle\binom{n}{k}p^k(1-p)^{n-k} &amp; \text{ si $k\in D_X$}\\
0 &amp; \text{ si $k\notin D_X$}
\end{array}\right.
\]</span></p></li>
<li><p>Su valor esperado es <span class="math inline">\(E(X)=np\)</span></p></li>
<li><p>Su varianza es <span class="math inline">\(\sigma^2(X)=np(1-p)\)</span></p></li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recordad que:</p>
<ul>
<li><p>El <strong>factorial</strong> <span class="math inline">\(m!\)</span> de un número natural <span class="math inline">\(m\)</span> se define como <span class="math inline">\(m!=m(m-1)\cdots 2\cdot 1\)</span> si <span class="math inline">\(m\geqslant 1\)</span>. Si <span class="math inline">\(m=0\)</span>, se toma <span class="math inline">\(0!=1\)</span>.</p></li>
<li><p>El <strong>número combinatorio</strong> <span class="math inline">\(\binom{n}{k}\)</span> se define como <span class="math display">\[
\binom{n}{k}=\frac{\overbrace{n\cdot (n-1)\cdots (n-k+1)}^k}{k\cdot (k-1)\cdots 2\cdot 1}=\frac{n!}{k!(n-k)!}
\]</span> y nos da el número de subconjuntos de <span class="math inline">\(k\)</span> elementos de <span class="math inline">\(\{1,\ldots,n\}\)</span>.</p></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si lo pensáis, veréis que el valor de <span class="math inline">\(E(X)\)</span> es el “esperado”. Si tomáis una muestra aleatoria de <span class="math inline">\(n\)</span> sujetos de una población en la que la proporción de sujetos <span class="math inline">\(E\)</span> es <span class="math inline">\(p\)</span>, ¿cuántos sujetos <span class="math inline">\(E\)</span> “esperáis” obtener en vuestra muestra? Pues una fracción <span class="math inline">\(p\)</span> de la muestra, es decir <span class="math inline">\(p\cdot n\)</span>, ¿no?</p>
</div>
</div>
<p>Para calcular el valor esperado y la varianza se suman <span class="math display">\[
\begin{array}{l}
\displaystyle E(X)=\sum_{k=0}^n k\cdot \binom{n}{k}p^k(1-p)^{n-k}\\
\displaystyle \sigma^2(X)=\sum_{k=0}^n k^2\cdot \binom{n}{k}p^k(1-p)^{n-k}-\Big(\sum_{k=0}^n k\cdot \binom{n}{k}p^k(1-p)^{n-k}\Big)^2
\end{array}
\]</span> Os podéis fiar de nosotros, dan <span class="math inline">\(np\)</span> y <span class="math inline">\(np(1-p)\)</span>, respectivamente.</p>
<p>El tipo de teorema anterior es el que hace que nos interese conocer algunas familias distinguidas frecuentes de variables aleatorias. Si, por ejemplo, reconocemos que una variable aleatoria es binomial y conocemos sus valores de <span class="math inline">\(n\)</span> y <span class="math inline">\(p\)</span> y sabemos el teorema anterior (o sabemos dónde consultarlo), automáticamente sabemos su función de densidad, y con ella su función de distribución, su valor esperado, su varianza etc., sin necesidad de deducir toda esta información cada vez que encontremos una variable de estas.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>El conocimiento ahorra tiempo.</p>
</div>
</div>
<p>Conocer las propiedades de las variables aleatorias binomiales solo es útil si sabemos reconocer cuándo estamos ante una de ellas. Fijaos en que en una variable aleatoria binomial <span class="math inline">\(B(n,p)\)</span>:</p>
<ul>
<li><p>Contamos cuántas veces ocurre un suceso (el éxito <span class="math inline">\(E\)</span>) en una secuencia de intentos.</p></li>
<li><p>En cada intento, el suceso que nos interesa pasa o no pasa, sin términos medios.</p></li>
<li><p>El número de intentos es fijo, <span class="math inline">\(n\)</span>.</p></li>
<li><p>Cada intento es independiente de los otros.</p></li>
<li><p>En cada intento, la probabilidad de que pase el suceso que nos interesa es siempre la misma, <span class="math inline">\(p\)</span>.</p></li>
</ul>
<p>Veamos algunos gráficos de la función densidad de variables aleatorias binomiales. Primero, para <span class="math inline">\(n=10\)</span> y diferentes valores de <span class="math inline">\(p\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p>Ahora para <span class="math inline">\(n=100\)</span>:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p>Podréis observar que si <span class="math inline">\(p&lt;0.5\)</span>, la distribución <span class="math inline">\(B(n,p)\)</span> presenta una cola a la derecha, y si <span class="math inline">\(p&gt;0.5\)</span>, la cola es a la izquierda. Es razonable. Por ejemplo, si <span class="math inline">\(p&lt;0.5\)</span>, el valor esperado será <span class="math inline">\(pn&lt;n/2\)</span> y hay más valores posibles a la derecha de <span class="math inline">\(pn\)</span> que a su izquierda (porque una binomial <span class="math inline">\(B(n,p)\)</span> puede llegar a tomar el valor <span class="math inline">\(n\)</span>, pero no puede tomar valores negativos).</p>
<p>Si <span class="math inline">\(p=0.5\)</span>, es simétrica: como <span class="math inline">\(E\)</span> y <span class="math inline">\(F\)</span> tienen la misma probabilidad, 0.5, la probabilidad de sacar <span class="math inline">\(k\)</span> <span class="math inline">\(E\)</span>’s es la misma que la de sacar <span class="math inline">\(k\)</span> <span class="math inline">\(F\)</span>’s, es decir, la de sacar <span class="math inline">\(n-k\)</span> <span class="math inline">\(E\)</span>’s.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<section id="cómo-efectuar-cálculos-con-una-variable-aleatoria-de-una-familia-dada" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="cómo-efectuar-cálculos-con-una-variable-aleatoria-de-una-familia-dada">¿Cómo efectuar cálculos con una variable aleatoria de una familia dada?</h5>
<p>Una posibilidad es usar una aplicación de móvil o tablet. Nuestra favorita es <em>Probability distributions</em>, disponible tanto para Android como para iOS.</p>
<p><img src="Figuras/App_Proba.png" class="img-fluid"></p>
<p>Otra posibilidad es usar JAMOVI. El módulo <strong>distrACTION</strong> permite calcular probabilidades y cuantiles de todas las distribuciones que usaremos en este curso salvo una, la hipergeométrica. Ya hablaremos de ella en la próxima sección.</p>
<p><img src="Figuras/binom.png" class="img-fluid"></p>
<p>Por ejemplo:</p>
<ul>
<li><p>Si lanzamos 20 veces un dado equilibrado (de 6 caras), ¿cuál es la probabilidad de sacar exactamente 5 unos?</p>
<p>Si llamamos <span class="math inline">\(X\)</span> a la variable aleatoria que cuenta el número de unos en secuencias de 20 lanzamientos de un dado equilibrado, se trata de una variable binomial <span class="math inline">\(B(20,1/6)=B(20,0.166667)\)</span>. Nos piden <span class="math inline">\(P(X=5)\)</span>. Da 0.129:</p></li>
</ul>
<p><img src="Figuras/binom1.png" class="img-fluid"></p>
<ul>
<li><p>Si lanzamos 20 veces un dado equilibrado, ¿cuál es la probabilidad de sacar como máximo 5 unos?</p>
<p>Con las notaciones anteriores, nos piden <span class="math inline">\(P(X\leqslant 5)\)</span>. Da 0.898:</p></li>
</ul>
<p><img src="Figuras/binom2.png" class="img-fluid"></p>
<ul>
<li><p>Si lanzamos 20 veces un dado equilibrado, ¿cuál es la probabilidad de sacar menos de 5 unos?</p>
<p>Con las notaciones anteriores, nos piden <span class="math inline">\(P(X&lt; 5)\)</span>, es decir, <span class="math inline">\(P(X\leqslant 4)\)</span>. Da 0.769:</p></li>
</ul>
<p><img src="Figuras/binom3.png" class="img-fluid"></p>
<ul>
<li><p>Si lanzamos 20 veces un dado equilibrado, ¿cuál es el menor número <span class="math inline">\(N\)</span> de unos para el que la probabilidad de sacar como máximo <span class="math inline">\(N\)</span> unos llega al 25%?</p>
<p>Nos piden el menor valor <span class="math inline">\(N\)</span> tal que <span class="math inline">\(P(X\leqslant N)\geqslant 0.25\)</span>, y esto por definición es el 0.25-cuantil de <span class="math inline">\(X\)</span>. Da 2:</p></li>
</ul>
<p><img src="Figuras/binom4.png" class="img-fluid"></p>
<p>Podéis comprobar que en efecto <span class="math inline">\(N=2\)</span> cumple lo pedido: si las calculáis, veréis que la probabilidad de sacar como máximo 2 unos es <span class="math inline">\(P(X\leqslant 2)=0.329\)</span> y la probabilidad de sacar como máximo 1 uno es <span class="math inline">\(P(X\leqslant 1)=0.13\)</span>. Por lo tanto, con 1 uno no llegamos al 25% de probabilidad y con 2 sí.</p>
</section>
</section>
<section id="variables-aleatorias-hipergeométricas" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="variables-aleatorias-hipergeométricas"><span class="header-section-number">5.2.2</span> Variables aleatorias hipergeométricas</h3>
<p>Recordad que el paradigma de variable aleatoria binomial es: tengo una población con una proporción <span class="math inline">\(p\)</span> de sujetos que satisfacen una condición <span class="math inline">\(E\)</span>, tomo una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> y cuento el número de sujetos <span class="math inline">\(E\)</span> en mi muestra. Si cambiamos “muestra aleatoria simple” por “muestra aleatoria sin reposición”, la distribución de la variable aleatoria que obtenemos es otra: la <strong>hipergeométrica</strong>.</p>
<p>Una variable aleatoria <strong>hipergeométrica</strong> (o <strong>tiene distribución hipergeométrica</strong>) <strong>de parámetros <span class="math inline">\(K\)</span>, <span class="math inline">\(M\)</span> y <span class="math inline">\(n\)</span></strong> (para abreviar, <span class="math inline">\(H(K,M,n)\)</span>) es cualquier variable aleatoria <span class="math inline">\(X\)</span> que podáis identificar con el proceso siguiente: Tenemos una población formada por <span class="math inline">\(K\)</span> sujetos que satisfacen una condición <span class="math inline">\(E\)</span> y <span class="math inline">\(M\)</span> sujetos que no la satisfacen (por lo tanto, en total, <span class="math inline">\(K+M=N\)</span> sujetos en la población), tomamos una muestra aleatoria <strong>sin reposición</strong> de tamaño <span class="math inline">\(n\)</span> y contamos el número de sujetos <span class="math inline">\(E\)</span> en esta muestra.</p>
<p>Llamaremos a <span class="math inline">\(K\)</span> el <strong>número poblacional de éxitos</strong>, a <span class="math inline">\(M\)</span> el <strong>número poblacional de fracasos</strong> y a <span class="math inline">\(n\)</span> el <strong>tamaño de las muestras</strong>. Fijaos entonces que <span class="math inline">\(K+M=N\)</span> es el <strong>tamaño total de la población</strong> y que <span class="math inline">\(K/(K+M)\)</span> es la <strong>probabilidad poblacional de éxito</strong> (la fracción de sujetos que satisfacen <span class="math inline">\(E\)</span> en el total de la población), que llamaremos <span class="math inline">\(p\)</span>.</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>En una aula hay 5 chicos y 45 chicas. Escogemos 10 estudiantes, uno tras otro y sin repetirlos, para hacerles una pregunta. Contamos cuántos chicos hemos interrogado. Se trata de una variable hipergeométrica <span class="math inline">\(H(5,45,10)\)</span>.</p>
</div>
<p><strong>Teorema:</strong> Si <span class="math inline">\(X\)</span> es una variable <span class="math inline">\(H(K,M,n)\)</span>:</p>
<ul>
<li><p>Su dominio es <span class="math inline">\(D_X=\{0,1,\ldots,\text{min}(N,n)\}\)</span></p></li>
<li><p>Su función de densidad es <span class="math display">\[
f_X(k)=\left\{\begin{array}{ll}
\displaystyle\dfrac{\binom{K}{k}\cdot \binom{M}{n-k}}{\binom{N}{n}} &amp; \text{ si $k\in D_X$}\\
0 &amp; \text{ si $k\notin D_X$}
\end{array}\right.
\]</span></p></li>
<li><p>Su valor esperado es <span class="math inline">\(E(X)=\dfrac{nK}{N}\)</span></p></li>
<li><p>Su varianza es <span class="math inline">\(\sigma^2(X)=\dfrac{nKM(N-n)}{N^2(N-1)}\)</span></p></li>
</ul>
<p>Fijaos en que si llamamos <span class="math inline">\(p\)</span> a la probabilidad poblacional de éxito, <span class="math inline">\(p=K/N\)</span>, entonces <span class="math display">\[
E(X)=np.
\]</span> Es la misma fórmula que para las variables binomiales <span class="math inline">\(B(n,p)\)</span> (y si lo pensáis un rato veréis que, de nuevo y por el mismo argumento, es lo razonable). Por otro lado, <span class="math display">\[
\sigma^2(X)=n\cdot\dfrac{K}{N}\cdot\dfrac{M}{N}\cdot\frac{N-n}{N-1}=np(1-p)\cdot\dfrac{\mathbf{N}-n}{\mathbf{N}-1}
\]</span> que es la varianza de una variable <span class="math inline">\(B(n,p)\)</span> multiplicada por un factor de corrección debido a que ahora tomamos muestras sin repeticiones, lo que hace que la dispersión de resultados sea más pequeña que si permitiéramos repeticiones (yendo a un caso extremo, de tamaño <span class="math inline">\(N\)</span> hay una sola muestra posible sin repetición, pero muchísimas si permitimos repeticiones). A la raíz cuadrada de este factor, <span class="math display">\[
\sqrt{\dfrac{N-n}{N-1}}
\]</span> se la llama <strong>factor</strong> (<strong>corrector</strong>) <strong>de población finita</strong>.</p>
<p>Fijaos en que si <span class="math inline">\(N\)</span> es muchísimo mayor que <span class="math inline">\(n\)</span>, tendremos que <span class="math inline">\(N-n \approx N-1\)</span> y por lo tanto <span class="math inline">\((N-n)/(N-1)\approx 1\)</span> y la varianza de la hipergeométrica será aproximadamente la de la binomial. Esto es consistente con lo que ya hemos comentado varias veces: si la población es mucho mayor que la muestra, tomar las muestras con o sin reposición no afecta demasiado a las muestra obtenidas, por lo que la distribución de probabilidad ha de ser muy parecida. Recordad los ejemplos siguientes:</p>
<ul>
<li><p>En España hay 46,700,000 personas, de las cuales un 11.7% son diabéticos. Escogemos 100 españoles y contamos cuántos son diabéticos.</p>
<p>Esta variable es, en realidad, hipergeométrica con <span class="math inline">\(K=0.117\cdot 46700000=5463900\)</span>, <span class="math inline">\(M=46700000-N=41236100\)</span> y <span class="math inline">\(n=100\)</span>, pero en la práctica la consideramos binomial <span class="math inline">\(B(100,0.117)\)</span>. El factor de población finita es <span class="math display">\[
\frac{46700000-100}{46700000-1}=0.9999979
\]</span></p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Hay otro motivo para considerarla binomial en este ejemplo, y es que, en realidad, no sabemos los valores exactos de <span class="math inline">\(K\)</span> y <span class="math inline">\(M\)</span>. Estamos seguros de que no es verdad que el tamaño de la población española sea exactamente de 46,700,000 personas, tan redondo, ni que los diabéticos representen exactamente un 11.7%, sin más cifras decimales. Así que ya puestos a aproximar, tomamos la aproximación binomial, que es más sencilla.</p>
<p>Pero cuidado: si la muestra fuera, pongamos, de 10,000 personas, entonces la aproximación binomial sería teóricamente incorrecta, aunque el factor corrector de población finita es de 0.999786: de media, un poco menos de 2 de cada 3 muestras aleatorias simples de 10,000 personas tomadas de una población de 46,700,000 personas contienes alguna repetición, como muestra el cálculo siguiente.</p>
</div>
</div>
<p>Para hacer cálculos de la hipergeométrica en Jamovi:</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>En una clase de 50 estudiantes, 5 son hombres (y 45 mujeres). Escogemos una muestra aleatoria sin reposiciòn de 10 estudiantes. ¿Cuál es la probabilidad de que exactamente dos de los estudiantes elegidos sean hombres?</p>
</div>
<p>La variable <span class="math inline">\(X\)</span> que cuenta el número de hombres en estas muestras es hipergeométrica <span class="math inline">\(H(5,45,10)\)</span>. Nos piden <span class="math inline">\(P(X=2)\)</span>, y esta probabilidad nos la da la función de densidad de <span class="math inline">\(X\)</span>. Es <span class="math inline">\(f_X(2)\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dhyper</span>(<span class="dv">2</span>,<span class="dv">5</span>,<span class="dv">45</span>,<span class="dv">10</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2098397</code></pre>
</div>
</div>
<p><img src="Figuras/hiper_jamovi.png" class="img-fluid"></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Fijaos en el orden de los argumentos de la función entre los paréntesis. Para calcular <span class="math inline">\(f_X(x)\)</span>, aplicamos <code>dhyper</code> a <span class="math inline">\((x,K,M,n)\)</span>.</p>
</div>
</div>
<p>En la situación anterior, ¿cuál es la probabilidad de la muestra contenga como máximo 2 hombres?, ¿cuál es la probabilidad de la muestra contenga al menos 2 hombres?</p>
</section>
<section id="variables-aleatorias-de-poisson" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="variables-aleatorias-de-poisson"><span class="header-section-number">5.2.3</span> Variables aleatorias de Poisson</h3>
<p>Una variable aleatoria <span class="math inline">\(X\)</span> es <strong>de Poisson</strong> (o tiene <strong>distribución de Poisson</strong>) <strong>con parámetro <span class="math inline">\(\lambda&gt;0\)</span></strong> (para abreviar, <span class="math inline">\(Po(\lambda)\)</span>) cuando:</p>
<ul>
<li><p>Su <strong>dominio</strong> es <span class="math inline">\(D_X=\mathbb{N}\)</span>, el conjunto de todos los números naturales (es decir, <em>teóricamente</em> puede tomar como valor cualquier número natural).</p></li>
<li><p>Su <strong>función de densidad</strong> es <span class="math display">\[
f_X(k)=\left\{\begin{array}{ll}
e^{-\lambda}\cdot \dfrac{\lambda^k}{k!} &amp;  \text{ si $k\in \mathbb{N}$}\\
0 &amp; \text{ si $k\notin \mathbb{N}$}
\end{array}\right.
\]</span></p></li>
</ul>
<p><strong>Teorema:</strong> Si <span class="math inline">\(X\)</span> es una variable <span class="math inline">\(Po(\lambda)\)</span>, entonces <span class="math inline">\(E(X)= \sigma^2(X)= \lambda\)</span>.</p>
<p>Es decir, el “parámetro” <span class="math inline">\(\lambda\)</span> de una variable de Poisson es su valor esperado, y coincide con su varianza.</p>
<p>La familia de Poisson incluye un tipo de variables aleatorias muy común en epidemiología.</p>
<p>Supongamos que tenemos un tipo de objetos o acontecimientos que pueden darse en una región continua de tiempo o espacio. Por ejemplo, defunciones de personas por una determinada enfermedad en el curso del tiempo, casos de un tipo de cáncer en diferentes zonas geográficas de un país, o bacterias en una superficie. Para simplificar el lenguaje, vamos a suponer que observamos apariciones de objetos en el tiempo.</p>
<p>Si las apariciones de estos objetos satisfacen las propiedades siguientes:</p>
<ul>
<li><p>Las apariciones de los objetos son <strong>aleatorias</strong>: en cada instante, un objeto se da, o no, al azar, con una probabilidad fija y constante</p></li>
<li><p>Las apariciones de los objetos son <strong>independientes</strong>: que se dé un objeto en un instante concreto, no depende para nada de que se haya dado o no un objeto en otro instante</p></li>
<li><p>Las apariciones de los objetos <strong>no son simultáneas</strong>: es prácticamente imposible que dos objetos de estos se den en el mismo instante exacto, medido con precisión infinita</p></li>
</ul>
<p>entonces, la variable <span class="math inline">\(X_t\)</span> que toma un intervalo de tiempo de duración <span class="math inline">\(t\)</span> y cuenta el número de objetos que se dan en él es de <strong>Poisson</strong>: <span class="math inline">\(Po(\lambda_t)\)</span>, con <span class="math inline">\(\lambda_t\)</span> el número esperado de objetos en este intervalo de tiempo (es decir, el número medio de objetos en intervalos de tiempo de este tamaño).</p>
<p>Por ejemplo, cuando lo que cuentan ocurre al azar, son variables de Poisson:</p>
<ul>
<li><p>El número de enfermos admitidos en urgencias en un día (o en 12 horas, o en una semana…)</p></li>
<li><p>El número de defunciones por una enfermedad concreta en un día (o en una semana, o en un año…)</p></li>
<li><p>El número de bacterias en un cuadrado de 1 cm de lado (o de 1 m de lado…)</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Más en concreto, si <span class="math inline">\(X\)</span> es una variable binomial <span class="math inline">\(B(n,p)\)</span> con <span class="math inline">\(n\)</span> MUY grande y <span class="math inline">\(p\)</span> MUY pequeño, entonces <span class="math inline">\(X\)</span> es aproximadamente <span class="math inline">\(Po(\lambda)\)</span> con <span class="math inline">\(\lambda=p\cdot n\)</span>. Aquí <span class="math inline">\(n\)</span> es, para entendernos, el número de instantes en un día, o el número de puntos del cuadrado de 1 cm de lado: MUY grande.</p>
<p>Para que os hagáis una idea, la instrucción siguiente calcula el máximo (<code>max</code>) de los valores absolutos (<code>abs</code>) de las diferencias entre la densidad de una <span class="math inline">\(B(10^6,10^{-5})\)</span> y una <span class="math inline">\(Po(10)\)</span>: esta diferencia máxima es del orden de 0.0000006.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(<span class="fu">abs</span>(<span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>,<span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>,<span class="dv">10</span><span class="sc">^-</span><span class="dv">5</span>)<span class="sc">-</span><span class="fu">dpois</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span><span class="sc">^</span><span class="dv">6</span>,<span class="dv">10</span>)))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 6.255548e-07</code></pre>
</div>
</div>
<p>Podemos aplicar esta información de dos maneras:</p>
<ul>
<li><p>Si sabemos que una variable es (aproximadamente) de Poisson, conocemos su densidad y por lo tanto podemos calcular lo que queramos para ella.</p></li>
<li><p>Si los datos que observamos tocarían seguir una distribución de Poisson pero parece que no (por ejemplo, porque su varianza sea muy diferente de su media, tan diferente que sea difícil de creer que la media y la varianza poblacionales sean iguales), entonces es señal de que algo “raro” está pasando en realidad.</p></li>
</ul>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Observad la diferencia entre las dos variables siguientes:</p>
<ul>
<li><p>Número semanal de defunciones por un tipo de cáncer en un país. El momento exacto de las defunciones se produce al azar, podemos entender que no se dan dos defunciones exactamente en el mismo instante, con precisión infinita, y las defunciones se producen de manera independiente. Es de Poisson.</p></li>
<li><p>Número semanal de defunciones en accidentes de tráfico en un país. De nuevo, el momento exacto de las defunciones se produce al azar y podemos entender que no se dan dos defunciones exactamente en el mismo instante, con precisión infinita. Pero las muertes en accidentes de tráfico no son independientes: en un mismo accidente mortal se pueden producir varias muertes casi simultáneas. No es buena idea modelarla mediante una distribución de Poisson. En cambio, el número de accidentes de tráfico sí.</p></li>
</ul>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Como las apariciones de los objetos que cuenta una variable de Poisson son aleatorias e independientes, el número medio de objetos es lineal en el tamaño de la región. Es decir, por ejemplo, en un intervalo de dos días esperamos ver el doble de objetos que en un día. O por ejemplo, si se diagnostican de media 32,240 casos de cáncer de colon anuales en España (y siguen una ley de Poisson), esperamos que de media se diagnostiquen 32240/52=620 casos semanales.</p>
</div>
</div>
<p>Veamos algunos gráficos de funciones de densidad de variables de Poisson.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" style="width:90.0%"></p>
</figure>
</div>
</div>
</div>
<p>Como podéis ver, la densidad de una variable de Poisson es asimétrica, con un máximo alrededor de <span class="math inline">\(\lambda\)</span> y una cola a la derecha, pero a medida que <span class="math inline">\(\lambda\)</span> crece, la asimetría se va atenuando.</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>La incidencia anual de un cierto accidente laboral sigue una distribución de Poisson. A lo largo del tiempo se ha observado que el 55% de los años no se produce ningún accidente. ¿Cuántos accidentes esperas que ocurran en un año?</p>
</div>
<p>Sea <span class="math inline">\(X\)</span> la variable que cuenta estos accidentes laborales anuales. Nos dicen que es <span class="math inline">\(Po(\lambda)\)</span>, donde <span class="math inline">\(\lambda\)</span> es su valor esperado, y por lo tanto lo que nos piden. Nos dicen también que <span class="math inline">\(P(X=0)=0.55\)</span>. Por la fórmula de la densidad de una variable de Poisson: <span class="math display">\[
0.55=e^{-\lambda}\cdot \dfrac{\lambda^0}{0!}=e^{-\lambda}\Longrightarrow
\lambda=-\ln(0.55)
\]</span></p>
</section>
</section>
<section id="variables-aleatorias-continuas" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="variables-aleatorias-continuas"><span class="header-section-number">5.3</span> Variables aleatorias continuas</h2>
<p>Recordad que una variable aleatoria <strong>continua</strong> toma valores continuos. Por ejemplo:</p>
<ul>
<li>Peso de una persona</li>
<li>Nivel de colesterol en sangre</li>
<li>Diámetro de un tumor</li>
</ul>
<p>En este curso vamos a restringirnos a variables aleatorias continuas <span class="math inline">\(X: \Omega\to \mathbb{R}\)</span> que cumplen la siguiente propiedad extra: su <strong>función de distribución</strong> <span class="math display">\[
\begin{array}{rcl}
F_X: \mathbb{R} &amp; \to &amp; [0,1]\\
x &amp;\mapsto &amp;P(X\leqslant x)
\end{array}
\]</span> es continua. Todas las variables aleatorias continuas que os puedan interesar en algún momento van a tener esta propiedad, así que no perdemos nada imponiéndola. ¿Y qué ganamos? Pues que podemos usar todas las técnicas matemáticas aplicables a funciones continuas para estudiar <span class="math inline">\(F_X\)</span>.</p>
<p>Por ejemplo, nuestras variables continuas verifican la propiedad siguientes:</p>
<p><strong>Teorema:</strong> Si <span class="math inline">\(X\)</span> es una variable aleatoria continua, la probabilidad de que tome un valor concreto siempre es 0: <span class="math display">\[
P(X=a)=0 \text{ para todo $a\in \mathbb{R}$}.
\]</span></p>
<p>Por si pasa por aquí alguien que necesite una demostración: <span class="math display">\[
\begin{array}{l}
\displaystyle P(X=a) = P(X\leqslant a)-P(X&lt;a)=P(X\leqslant a)-P\Big(\bigcup_{n\geqslant 1} \Big(X\leqslant a-\frac{1}{n}\Big)\Big)\\
\displaystyle \qquad= P(X\leqslant a)-\lim_{n\geqslant 1}P\Big(X\leqslant a-\frac{1}{n}\Big)\\
\displaystyle \qquad= F_X(a)-\lim_{n\geqslant 1}F_X\Big(a-\frac{1}{n}\Big)=0
\end{array}
\]</span> porque <span class="math inline">\(F_X\)</span> es continua.</p>
<p>En particular, para una variable aleatoria continua:</p>
<blockquote class="blockquote">
<p>Probabilidad 0 no significa imposible.</p>
</blockquote>
<p>Cada valor de <span class="math inline">\(X\)</span> tiene probabilidad 0, pero cuando tomamos un sujeto, tendrá algún valor de <span class="math inline">\(X\)</span>, ¿no?. Por lo tanto, su valor de <span class="math inline">\(X\)</span> es posible, aunque tenga probabilidad 0.</p>
<p>De <span class="math inline">\(P(X=a)=0\)</span> se deduce que la probabilidad de un suceso definido con una desigualdad es la misma que la del suceso correspondiente definido con una desigualdad estricta. Por ejemplo, y contrariamente a lo que pasaba en las variables aleatorias discretas, para una variable aleatoria continua siempre tenemos que <span class="math display">\[
P(X\leqslant a)=P(X&lt;a)
\]</span> porque <span class="math display">\[
P(X\leqslant a)=P(X&lt;a)+P(X=a)=P(X&lt;a)+0=P(X&lt;a).
\]</span></p>
<p>De manera similar:</p>
<ul>
<li><span class="math inline">\(P(X\geqslant a)=P(X&gt; a)+P(X=a)=P(X&gt; a)\)</span></li>
<li><span class="math inline">\(P(a\leqslant X\leqslant b)=P(a&lt;X&lt;b)+P(X=a)+P(X=b)\)</span> <span class="math inline">\(=P(a&lt;X&lt;b)\)</span></li>
</ul>
</section>
<section id="densidad-y-distribución-1" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="densidad-y-distribución-1"><span class="header-section-number">5.4</span> Densidad y distribución</h2>
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria continua. Como ya hemos dicho, su <strong>función de distribución</strong> <span class="math inline">\(F_X\)</span> se sigue definiendo como <span class="math display">\[
x\mapsto F_X(x)=P(X\leqslant x)
\]</span> recordando además que, ahora, también <span class="math display">\[
F_X(x)=P(X&lt; x)
\]</span></p>
<p>Pero puesto que tenemos que <span class="math inline">\(P(X=x)=0\)</span>, ahora no podemos definir la función de densidad de <span class="math inline">\(X\)</span> como <span class="math inline">\(f_X(x)=P(X=x)\)</span>. ¿Qué podemos hacer?</p>
<p>Recordad que, en las variables aleatorias discretas <span class="math display">\[
F_X(a)=\sum_{x\leqslant a} f_X(x)
\]</span></p>
<p>En el contexto de matemáticas “continuas”, la suma <span class="math inline">\(\sum\)</span> se traduce en la integral <span class="math inline">\(\int\)</span>. Se define entonces la <strong>función de densidad</strong> de una variable aleatoria continua <span class="math inline">\(X\)</span> como la función <span class="math inline">\(f_X:\mathbb{R}\to \mathbb{R}\)</span> tal que:</p>
<ul>
<li><p><span class="math inline">\(f_X(x)\geqslant 0\)</span>, para todo <span class="math inline">\(x\in \mathbb{R}\)</span></p></li>
<li><p><span class="math inline">\(\displaystyle F_X(a)=\int_{-\infty}^a f_{X}(x)\, dx\)</span> para todo <span class="math inline">\(a\in \mathbb{R}\)</span>.</p></li>
</ul>
<center>
<img src="Figuras/panic.png" class="img-fluid" style="width:25.0%">
</center>
<p><br></p>
<p>Recordad (o aprended por primera vez) que la integral tiene una interpretación sencilla en términos de áreas. En concreto, dados <span class="math inline">\(a\in \mathbb{R}\)</span> y una función <span class="math inline">\(f(x)\)</span>, la integral <span class="math display">\[
\int_{-\infty}^a f(x)\, dx
\]</span> es igual al área de la región a la izquierda de la recta vertical <span class="math inline">\(x=a\)</span> comprendida entre la curva <span class="math inline">\(y=f(x)\)</span> y el eje de abscisas <span class="math inline">\(y=0\)</span>. Por lo tanto, la función de densidad <span class="math inline">\(f_X\)</span> de <span class="math inline">\(X\)</span> es la función positiva tal que para todo <span class="math inline">\(a\in \mathbb{R}\)</span>, <span class="math inline">\(F_X(a)\)</span> es igual al <strong>área bajo la curva</strong> <span class="math inline">\(y=f_X(x)\)</span> (entre esta curva y el eje de abscisas) a la izquierda de <span class="math inline">\(x=a\)</span>.</p>
<center>
<img src="Figuras/Fyf.png" class="img-fluid">
</center>
<p>¿Cuál es la idea intuitiva que hay detrás de esta definición de densidad? Suponed que dibujamos histogramas de frecuencias relativas de los valores de <span class="math inline">\(X\)</span> sobre toda la población. Como estamos hablando de toda la población, la frecuencia relativa de cada clase es la proporción de individuos de la población cuyo valor de <span class="math inline">\(X\)</span> pertenece a esta clase: es decir, la <strong>probabilidad</strong> de que <span class="math inline">\(X\)</span> caiga dentro de la clase.</p>
<p>Recordad que, en un histograma de frecuencias relativas:</p>
<ul>
<li>La frecuencia relativa (ahora, la <strong>probabilidad</strong>) de cada clase es el área de su barra, es decir, el ancho de la clase por la altura de la barra.</li>
<li>Llamamos a la altura de una barra la <strong>densidad</strong> de la clase.</li>
<li>Si <span class="math inline">\(a\)</span> es un extremo de una clase, la frecuencia relativa acumulada (la <strong>probabilidad</strong>) de que <span class="math inline">\(X&lt;a\)</span> es la suma de las áreas de las barras a la izquierda de <span class="math inline">\(a\)</span>.</li>
</ul>
<p>Si dibujamos los histogramas de <span class="math inline">\(X\)</span> tomando clases cada vez más estrechas, sus polígonos de frecuencias (en rojo) tienden a dibujar una curva:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Cuando el ancho de las clases tiende a 0, obtenemos una curva que es el límite de estos polígonos de frecuencias:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>En el límite, la probabilidad de que <span class="math inline">\(X&lt; a\)</span> (o sea, de que <span class="math inline">\(X\leqslant a\)</span>) será el límite de las sumas de las áreas de las barras a la izquierda de <span class="math inline">\(a\)</span>, y por tanto el área a la izquierda de <span class="math inline">\(a\)</span> bajo esta curva límite. Esto nos dice que esta curva es precisamente la función de densidad <span class="math inline">\(y=f_X(x)\)</span>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>La <strong>función de densidad</strong> <span class="math inline">\(f_X\)</span> de una variable aleatoria continua <span class="math inline">\(X\)</span> es la función límite de los polígonos de frecuencias de histogramas de <span class="math inline">\(X\)</span> cuando el ancho de las clases tiende a 0.</p>
</div>
</div>
<p>Veamos algunas propiedades que se deducen de que <span class="math inline">\(F_X(a)=P(X\leqslant a)\)</span> sea igual al <strong>área bajo la curva</strong> <span class="math inline">\(y=f_X(x)\)</span> a la izquierda de <span class="math inline">\(x=a\)</span>:</p>
<ul>
<li>Como <span class="math inline">\(P(X&lt;\infty)=P(\Omega)=1\)</span>, <strong>el área total bajo la curva <span class="math inline">\(y=f_X(x)\)</span> es 1.</strong></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><span class="math inline">\(P(a\leqslant X\leqslant b)=P(X\leqslant b)-P(X&lt;a)\)</span> es el área bajo la curva <span class="math inline">\(y=f_X(x)\)</span> a la izquierda de <span class="math inline">\(x=b\)</span> <strong>menos</strong> el área bajo la curva <span class="math inline">\(y=f_X(x)\)</span> a la izquierda de <span class="math inline">\(x=a\)</span>, es decir, <strong><span class="math inline">\(P(a\leqslant X\leqslant b)\)</span> es igual al área bajo la curva <span class="math inline">\(y=f_X(x)\)</span> entre <span class="math inline">\(x=a\)</span> y <span class="math inline">\(x=b\)</span>.</strong></li>
</ul>
<p><img src="Figuras/proba_ayb.png" class="img-fluid"></p>
<ul>
<li>Si <span class="math inline">\(\varepsilon&gt;0\)</span> es muy, muy pequeño, el área bajo <span class="math inline">\(y=f_X(x)\)</span> entre <span class="math inline">\(a-\varepsilon\)</span> y <span class="math inline">\(a+\varepsilon\)</span> es aproximadamente igual a la del rectángulo de base el intervalo <span class="math inline">\([a-\varepsilon,a+\varepsilon]\)</span> y altura <span class="math inline">\(f_X(a)\)</span>, que vale <span class="math inline">\(2\varepsilon\cdot f_X(a)\)</span> (ved la Figura @ref(fig:epsilon)). Es decir, <span class="math display">\[
P(a-\varepsilon\leqslant X\leqslant a+\varepsilon)\approx 2\varepsilon\cdot f_X(a).
\]</span></li>
</ul>
<p>Por lo tanto <span class="math inline">\(f_X(a)\)</span> nos da una indicación de la probabilidad de que <span class="math inline">\(X\)</span> valga aproximadamente <span class="math inline">\(a\)</span> (pero <strong>no es</strong> <span class="math inline">\(P(X=a)\)</span>, que vale 0). Es decir, por ejemplo, si <span class="math inline">\(f_X(a)=0.1\)</span> y <span class="math inline">\(f_X(b)=0.5\)</span>, <strong>la probabilidad de que <span class="math inline">\(X\)</span> tome un valor muy cercano a <span class="math inline">\(b\)</span> es 5 veces mayor que la probabilidad de que tome un valor muy cercano a <span class="math inline">\(a\)</span></strong>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pero <span class="math inline">\(P(X=a)=P(X=b)=0\)</span>, así que, por favor, evitad decir que “la probabilidad de que <span class="math inline">\(X\)</span> valga <span class="math inline">\(b\)</span> es 5 veces <strong>mayor</strong> que la probabilidad de que valga <span class="math inline">\(a\)</span>”. Sí, ya sabemos que <span class="math inline">\(5\cdot 0=0\)</span>, pero la frase es engañosa.</p>
</div>
</div>
<p>Unas consideraciones finales:</p>
<ul>
<li><p>Lo hemos dicho en la definición, y lo hemos usado implícitamente en toda la sección, pero lo volvemos a repetir: <span class="math inline">\(f_X(x)\geqslant 0\)</span> para todo <span class="math inline">\(x\in \mathbb{R}\)</span>.</p></li>
<li><p><span class="math inline">\(f_X(x)\)</span> no es una probabilidad, y por lo tanto puede ser mayor que 1. Por ejemplo, el gráfico siguiente muestra la densidad de una variable normal <span class="math inline">\(N(0,0.01)\)</span>, que llega a valer casi 40. Pero el área bajo toda la curva densidad es 1: a partir de <span class="math inline">\(\pm 0.06\)</span> la densidad vale prácticamente 0.</p></li>
</ul>
<p><img src="Figuras/densidad_normal_desv_peque.png" class="img-fluid"></p>
<ul>
<li>La función de densidad <span class="math inline">\(f_X\)</span> no tiene por qué ser continua, aunque la función de distribución <span class="math inline">\(F_X\)</span> lo sea.</li>
</ul>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Sea <span class="math inline">\(X\)</span> una variable aleatoria continua con función de distribución <span class="math display">\[
F_X(x)=P(X\leqslant x)=\left\{
\begin{array}{ll}
0 &amp; \text{ si $x\leqslant 0$}\\
x &amp;  \text{ si $x\in [0,1]$}\\
1 &amp;  \text{ si $x\geqslant 1$}
\end{array}\right.
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Su función de densidad es <span class="math display">\[
f_X(x)\left\{
\begin{array}{ll}
0 &amp; \text{ si $x&lt; 0$}\\
1 &amp;  \text{ si $x\in [0,1]$}\\
0 &amp;  \text{ si $x&gt; 1$}
\end{array}\right.
\]</span> porque la integral de <span class="math inline">\(-\infty\)</span> hasta <span class="math inline">\(a\)</span> de esta función es (calculadlo como áreas si os cuesta recordar cómo calcular integrales definidas) <span class="math display">\[
\int_{-\infty}^a  f_X(x)\,dx=\left\{
  \begin{array}{ll}
\int_{-\infty}^a  0\,dx =0 &amp; \text{ si $a&lt; 0$}\\
\int_{-\infty}^0  0\,dx+ \int_{0}^a  1\,dx=0 + a=a &amp;  \text{ si $a\in [0,1]$}\\
\int_{-\infty}^0  0\,dx+ \int_{0}^1  1\,dx+ \int_{1}^a  0\,dx=0 + 1+0=1 &amp;  \text{ si $x&gt; 1$}
\end{array}\right.
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Observad que <span class="math inline">\(f_X(x)\)</span> es discontinua, con saltos en 0 y 1. Esta densidad representa que <span class="math inline">\(X\)</span> solo puede tomar valores entre 0 y 1 y que entre estos dos valores los toma todos “con la misma probabilidad”. Diremos que <span class="math inline">\(X\)</span> tiene <strong>distribución uniforme</strong> entre 0 y 1.</p>
</div>
<p><strong>Ejercicio:</strong> Más en general, una variable con distribución uniforme entre <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> (con <span class="math inline">\(a&lt;b\)</span>) solo puede tomar valores entre <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> y entre estos dos valores los toma todos “con la misma probabilidad”. ¿Cuál sería su densidad? ¿Cuál sería su distribución? Comprobad que el área bajo la curva de la densidad que hayáis dado es la distribución que hayáis dado.</p>
<section id="esperanza-varianza-cuantiles" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="esperanza-varianza-cuantiles"><span class="header-section-number">5.4.1</span> Esperanza, varianza, cuantiles…</h3>
<p>La esperanza y la varianza de una variable aleatoria continua <span class="math inline">\(X\)</span>, con función de densidad <span class="math inline">\(f_X\)</span>, se definen como en el caso discreto, substituyendo la suma <span class="math inline">\(\sum_{x\in D_x}\)</span> por una integral <span class="math inline">\(\int_{-\infty}^{\infty}\)</span>.</p>
<p>La <strong>media</strong>, o <strong>esperanza</strong> (<strong>valor medio</strong>, <strong>valor esperado</strong>…), de <span class="math inline">\(X\)</span> es <span class="math display">\[
E(X)=\int_{-\infty}^{\infty}x \cdot f_{X}(x)\, dx
\]</span> Es decir, es el área comprendida entre el eje de abscisas y la curva <span class="math inline">\(y=xf_X(x)\)</span>. Como en el caso discreto, también la denotaremos a veces por <span class="math inline">\(\mu_X\)</span>.</p>
<p>Este valor tiene la misma interpretación que en el caso discreto:</p>
<ul>
<li><p>Representa el valor medio de <span class="math inline">\(X\)</span> sobre el total de la población.</p></li>
<li><p>Es (con probabilidad 1) el límite de la media aritmética de los valores de <span class="math inline">\(X\)</span> sobre muestras aleatorias simples de tamaño <span class="math inline">\(n\)</span>, cuando <span class="math inline">\(n\to \infty\)</span>.</p></li>
</ul>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Volvamos a la variable aleatoria <span class="math inline">\(X\)</span> con distribución uniforme entre 0 y 1 del Ejemplo @ref(exm:unif), que toma todos los valores entre 0 y 1 con la misma probabilidad. ¿Cuál tendría que ser su valor medio? El valor medio del intervalo, 1/2, ¿no?. Veamos: como <span class="math inline">\(f_X(x)=1\)</span> entre 0 y 1 y <span class="math inline">\(f_X(x)=0\)</span> fuera de este intervalo, <span class="math display">\[
\int_{-\infty}^{\infty}x \cdot f_{X}(x)\, dx  =\int_{0}^1 x\,dx=\left[\frac{x^2}{2}\right]^1_0=\frac{1}{2}-0=\frac{1}{2}
\]</span> Nuestra intuición era correcta.</p>
</div>
<div class="cell" type="rmdnote">

<div class="rmdnote">
Si os da pereza calcular la integral del ejemplo anterior, fijaos en que el área bajo la curva <span class="math inline">\(y=x\)</span> entre 0 y 1 es la del triángulo de base (0,0)-(1,0) y altura (1,0)-(1,1), que es la mitad del cuadrado unidad y por lo tanto su área es 1/2
</div>
</div>
<p>Si <span class="math inline">\(g:\mathbb{R}\to \mathbb{R}\)</span> es una función continua, la <strong>esperanza</strong> de la composición <span class="math inline">\(\Omega \stackrel{X}{\longrightarrow} \mathbb{R}\stackrel{g}{\longrightarrow}\mathbb{R}\)</span> es <span class="math display">\[
E(g(X))=\int_{-\infty}^{+\infty} g(x) \cdot f_X(x)dx
\]</span></p>
<p>La <strong>varianza</strong> de <span class="math inline">\(X\)</span> es <span class="math display">\[
\sigma^2(X)=E((X-\mu_X)^2)
\]</span> y se puede demostrar que es igual a <span class="math display">\[
\sigma^2(X)=E(X^2)-\mu_X^2
\]</span> También se escribe <span class="math inline">\(\sigma_X^2\)</span>.</p>
<p>La <strong>desviación típica</strong> de <span class="math inline">\(X\)</span> es <span class="math display">\[
\sigma(X)=+\sqrt{\sigma^2(X)}
\]</span> y también se escribe <span class="math inline">\(\sigma_X\)</span>.</p>
<p>Como en el caso discreto, la varianza y la desviación típica miden la variabilidad de los resultados de <span class="math inline">\(X\)</span> respecto de su valor medio.</p>
<p>Estos parámetros de <span class="math inline">\(X\)</span> tienen las <strong>mismas propiedades</strong> en el caso continuo que en el discreto. Las recordamos:</p>
<ul>
<li><p>Si <span class="math inline">\(b\)</span> es una variable aleatoria constante, <span class="math inline">\(E(b)=b\)</span> y <span class="math inline">\(\sigma(b)^2=0\)</span>.</p></li>
<li><p>Si <span class="math inline">\(\sigma^2X)=0\)</span>, <span class="math inline">\(X\)</span> es constante.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Y por supuesto, si <span class="math inline">\(X\)</span> solo puede tomar un valor, ya no es continua, sino discreta. Por lo tanto, por convenio, de ahora en adelante supondremos que <strong>nuestras variables aleatorias continuas siempre tienen varianza no nula</strong>.</p>
</div>
</div>
<ul>
<li><p>Si <span class="math inline">\(X_1,\ldots,X_n\)</span> son variables aleatorias y <span class="math inline">\(a_1,\ldots,a_n,b\in \mathbb{R}\)</span>, <span class="math display">\[
E(a_1X_1+\cdots+a_nX_n+b)=a_1E(X_1)+\cdots+a_nE(X_n)+b
\]</span> En particular:</p>
<ul>
<li><p><span class="math inline">\(E(a X+b)=a E(X)+b\)</span>.</p></li>
<li><p><span class="math inline">\(E(X+Y)=E(X)+E(Y)\)</span>.</p></li>
</ul></li>
<li><p>Si <span class="math inline">\(X\leqslant Y\)</span>, entonces <span class="math inline">\(E(X)\leqslant E(Y)\)</span>.</p></li>
<li><p>Si <span class="math inline">\(a,b\in \mathbb{R}\)</span>, <span class="math inline">\(\sigma(aX+b)^2=a^2 \sigma^2(X)\)</span> y <span class="math inline">\(\sigma(aX+b)=|a|\cdot \sigma(X)\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X,Y\)</span> son <strong>independientes</strong>, <span class="math inline">\(\sigma^2(X+Y)=\sigma^2(X)+\sigma^2(Y)\)</span>. Si no, en principio no.</p></li>
<li><p>Si <span class="math inline">\(X_1,\ldots,X_n\)</span> son variables aleatorias <strong>independientes</strong> y <span class="math inline">\(a_1,\ldots,a_n,b\in \mathbb{R}\)</span>, <span class="math display">\[
\begin{array}{l}
\sigma^2(a_1X_1+\cdots+a_nX_n+b)=a_1^2\cdot\sigma^2(X_1)+\cdots+a_n^2\cdot\sigma^2(X_n)\\
\sigma(a_1X_1+\cdots+a_nX_n+b)=\sqrt{a_1^2\cdot\sigma^2(X_1)+\cdots+a_n^2\cdot\sigma^2(X_n)}
\end{array}
\]</span> Si no son independientes, estas igualdades pueden ser falsas.</p></li>
</ul>
<p>Dado <span class="math inline">\(p\)</span> entre 0 y 1, el <strong>cuantil de orden <span class="math inline">\(p\)</span></strong> (o <strong><span class="math inline">\(p\)</span>-cuantil</strong>) de una variable aleatoria continua <span class="math inline">\(X\)</span> es el menor valor <span class="math inline">\(x_p\in \mathbb{R}\)</span> tal que <span class="math display">\[
F_X(x_p)=P(X\leqslant x_p)=p
\]</span></p>
<p>La <strong>mediana</strong> de <span class="math inline">\(X\)</span> es su 0.5-cuantil, los <strong>primer</strong> y <strong>tercer cuartiles</strong> son su 0.25-cuantil y su 0.75-cuantil, etc.</p>
<p>Los <strong>coeficientes de asimetría</strong> y de <strong>curtosis</strong> se definen de manera similar a los de una muestra: <span class="math display">\[
\begin{array}{l}
\displaystyle \gamma_1=E\Big(\Big(\frac{X-\mu_X}{\sigma}\Big)^3\Big)\\
\displaystyle \beta_2=E\Big(\Big(\frac{X-\mu_X}{\sigma}\Big)^4\Big)-3
\end{array}
\]</span> Miden para la densidad de la variable lo que medían los de la muestra: el coeficiente de asimetría, si es simétrica o si tiene cola a algún lado; el coeficiente de curtosis, si sus colas son más largas o más cortas que las de una campana de Gauss.</p>
</section>
<section id="variables-aleatorias-normales" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="variables-aleatorias-normales"><span class="header-section-number">5.4.2</span> Variables aleatorias normales</h3>
<p>Una variable aleatoria continua <span class="math inline">\(X\)</span> es <strong>normal</strong> (o <strong>tiene distribución normal</strong>) de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span> (es <span class="math inline">\(N(\mu,\sigma)\)</span>, para abreviar) cuando su función de densidad es <span class="math display">\[
f_{X}(x)=\frac{1}{\sqrt{2\pi}\sigma} e^{{-(x-\mu)^2}/{2\sigma^{2}}} \mbox{
para todo } x\in \mathbb{R}
\]</span></p>
<p>Naturalmente, no os tenéis que saber esta fórmula.</p>
<center>
<img src="Figuras/normal_censurada.png" class="img-fluid">
</center>
<p>Pero sí que tenéis que saber que:</p>
<ul>
<li><p>Una variable aleatoria normal <span class="math inline">\(X\)</span> es continua, y por lo tanto <span class="math inline">\(P(X=x)=0\)</span>, <span class="math inline">\(P(X\leqslant x)=P(X&lt;x)\)</span> etc.</p></li>
<li><p>Si <span class="math inline">\(X\)</span> es normal <span class="math inline">\(N(\mu,\sigma)\)</span>, su valor esperado es <span class="math inline">\(E(X)=\mu\)</span> y su desviación típica es <span class="math inline">\(\sigma_X=\sigma\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X\)</span> es normal, su función de distribución <span class="math inline">\(F_X\)</span> es <strong>inyectiva y creciente</strong>: si <span class="math inline">\(x&lt;y\)</span>, <span class="math inline">\(F_X(x)&lt;F_X(y)\)</span>.</p></li>
</ul>
<p>Una variable aleatoria normal es <strong>típica</strong> (o <strong>estándar</strong>) cuando es <span class="math inline">\(N(0,1)\)</span>. Usaremos normalmente <span class="math inline">\(Z\)</span> para denotar una variable normal estándar. Por lo tanto, si <span class="math inline">\(Z\)</span> es una normal estándar, <span class="math inline">\(E(Z)=0\)</span> y <span class="math inline">\(\sigma(Z)=1\)</span>.</p>
<p>La gráfica de la densidad de una variable aleatoria normal es la famosa <strong>campana de Gauss</strong> de la que ya hemos hablado varias veces:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>La distribución normal es una distribución teórica, no la encontraréis exacta en la vida real. Y pese a su nombre, no es más “normal” que otras distribuciones continuas.</p>
<p>Pero es muy importante, debido a que muchas distribuciones de la vida real son aproximadamente normales porque:</p>
<blockquote class="blockquote">
<p>Toda variable aleatoria que consista en tomar <span class="math inline">\(n\)</span> medidas independientes de una o varias variables aleatorias y sumarlas, tiene distribución aproximadamente normal <strong>cuando <span class="math inline">\(n\)</span> es muy grande</strong>, aunque las variables aleatorias de partida no sean normales.</p>
</blockquote>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Una variable binomial <span class="math inline">\(B(n,p)\)</span> se obtiene tomando <span class="math inline">\(n\)</span> medidas independientes de una variable Bernoulli <span class="math inline">\(Be(p)\)</span> y sumando los resultados. Por lo tanto, por la “regla” anterior, una <span class="math inline">\(B(n,p)\)</span> tendría que ser aproximadamente normal si <span class="math inline">\(n\)</span> es grande. Pues sí, si <span class="math inline">\(n\)</span> es grande (pongamos mayor que 40, aunque si <span class="math inline">\(p\)</span> está muy cerca de 0 o 1 el tamaño de las muestras tiene que ser mayor), la distribución de una variable <span class="math inline">\(X\)</span> binomial <span class="math inline">\(B(n,p)\)</span> se acerca mucho a la de una normal <span class="math inline">\(N(np,\sqrt{np(1-p)})\)</span>, donde, recordad que si <span class="math inline">\(X\)</span> es <span class="math inline">\(B(n,p)\)</span>, entonces <span class="math inline">\(\mu_X=np\)</span> y <span class="math inline">\(\sigma_X=\sqrt{np(1-p)}\)</span>.</p>
</div>
<p>Por ejemplo, el gráfico siguiente compara las funciones de distribución de una binomial <span class="math inline">\(B(40,0.3)\)</span> y una normal <span class="math inline">\(N(40\cdot 0.3,\sqrt{40\cdot 0.3\cdot 0.7})\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>En los próximos temas utilizaremos a menudo que una variable <span class="math inline">\(B(n,p)\)</span> con <span class="math inline">\(n\)</span> es grande es aproximadamente <span class="math inline">\(N(np,\sqrt{np(1-p)})\)</span>.</p>
</div>
</div>
<p>Para calcular probabilidades de una <span class="math inline">\(N(\mu,\sigma)\)</span>, podéis usar JAMOVI o alguna aplicación para móvil o tablet.</p>
<center>
<img src="Figuras/jamovi_normal-1.png" class="img-fluid">
</center>
<p>Así, por ejemplo, si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(1,2)\)</span></p>
<center>
<img src="Figuras/jamovi_normal-2.png" class="img-fluid">
</center>
<ul>
<li>El 0.4-cuantil de <span class="math inline">\(X\)</span>, es decir, el valor <span class="math inline">\(q\)</span> tal que <span class="math inline">\(P(X\leqslant q)=0.4\)</span> es</li>
</ul>
<center>
<img src="Figuras/jamovi_normal-3.png" class="img-fluid">
</center>
<ul>
<li><span class="math inline">\(P(X=1.5)\)</span> es</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Advertencia
</div>
</div>
<div class="callout-body-container callout-body">
<p>¡No! Como <span class="math inline">\(X\)</span> es continua, <span class="math inline">\(P(X=1.5)=0\)</span>. Lo que os da <code>dnorm(1.5,1,2)</code> es el valor de la función de densidad de <span class="math inline">\(X\)</span> en 1.5.</p>
</div>
</div>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>La presión sistólica, medida en mm Hg, es una variable aleatoria aproximadamente normal con valor medio <span class="math inline">\(\mu\)</span> y desviación típica <span class="math inline">\(\sigma\)</span> que dependen del sexo y la edad. Para la franja de edad 16-24 años, estos valores son:</p>
<ul>
<li>Para hombres, <span class="math inline">\(\mu=124\)</span> y <span class="math inline">\(\sigma=13.7\)</span></li>
<li>Para mujeres, <span class="math inline">\(\mu=117\)</span> y <span class="math inline">\(\sigma=13.7\)</span></li>
</ul>
<p>El modelo de hipertensión-hipotensión aceptado es el descrito en la Figura anterior. Queremos calcular los límites de cada clase para cada sexo en este grupo de edad.</p>
<center>
<img src="Figuras/modelo-hipertension.png" class="img-fluid">
</center>
<p>Veamos:</p>
<ul>
<li>El límite superior del grupo de hipotensión será el valor que deja a la izquierda un 5% de las tensiones: el 0.05-cuantil de la distribución.</li>
<li>El límite superior del grupo de riesgo de hipotensión será el valor que deja a la izquierda un 10% de las tensiones: el 0.1-cuantil de la distribución.</li>
<li>El límite inferior del grupo de riesgo de hipertensión será el valor que deja a la izquierda un 90% de las tensiones: el 0.9-cuantil de la distribución.</li>
<li>El límite inferior del grupo de hipertensión será el valor que deja a la izquierda un 95% de las tensiones: el 0.95-cuantil de la distribución.</li>
</ul>
<p>En los hombres, la tensión sistólica es una variable aleatoria <span class="math inline">\(N(124,13.7)\)</span>. Si calculamos estos cuantiles, dan:</p>
<ul>
<li><p>El 0.05-cuantil es 101.5</p></li>
<li><p>El 0.1-cuantil es 106.4</p></li>
<li><p>El 0.9-cuantil es 141.6</p></li>
<li><p>El 0.95-cuantil es 146.5</p></li>
</ul>
En resumen, para los hombres de 16 a 24 años:
<center>
<img src="Figuras/resumen.png" class="img-fluid">
</center>
</div>
<p><strong>Ejercicio:</strong> Calculad estos límites para las mujeres de 16 a 24 años.</p>
</section>
<section id="propiedades-básicas" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="propiedades-básicas"><span class="header-section-number">5.4.3</span> Propiedades básicas</h3>
<p>Una de las propiedades clave de la distribución normal es la simetría de la campana de Gauss:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span>, su densidad <span class="math inline">\(f_X\)</span> es simétrica respecto de <span class="math inline">\(\mu\)</span>, es decir, <span class="math display">\[
f_{X}(\mu-x)=f_{X}(\mu+x),
\]</span> y tiene el máximo en <span class="math inline">\(x=\mu\)</span>. Decimos entonces que <span class="math inline">\(\mu\)</span> es la <strong>moda</strong> de <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recordad que no tiene sentido definir la moda de una variable continua <span class="math inline">\(X\)</span> como el valor <span class="math inline">\(x_0\)</span> tal que <span class="math inline">\(P(X=x_0)\)</span> sea máximo, porque <span class="math inline">\(P(X=x)=0\)</span> para todo <span class="math inline">\(x\in \mathbb{R}\)</span>. Se define entonces la <strong>moda</strong> de una variable continua <span class="math inline">\(X\)</span> como el valor (o los valores) <span class="math inline">\(x_0\)</span> tal que <span class="math inline">\(f_X(x_0)\)</span> es máximo. Así, como <span class="math inline">\(f_X(x_0)\)</span> mide la probabilidad de que <span class="math inline">\(X\)</span> valga aproximadamente <span class="math inline">\(x_0\)</span>, la moda de <span class="math inline">\(X\)</span> es el valor cerca del cual es más probable que caiga el valor de <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<p>En particular, si <span class="math inline">\(Z\)</span> es <span class="math inline">\(N(0,1)\)</span>, entonces <span class="math inline">\(f_Z\)</span> es simétrica alrededor de 0, es decir, <span class="math inline">\(f_{Z}(-x)=f_{Z}(x)\)</span>, y la moda de <span class="math inline">\(Z\)</span> es <span class="math inline">\(x=0\)</span>.</p>
<p>Recordad que la función de distribución de una variable aleatoria continua <span class="math inline">\(X\)</span>, <span class="math display">\[
F_X(x)=P(X\leqslant x)
\]</span> es el área comprendida entre la densidad <span class="math inline">\(y=f_X(x)\)</span> y el eje de abscisas a la izquierda de <span class="math inline">\(x\)</span>.</p>
<center>
<img src="Figuras/area-Fx.png" class="img-fluid">
</center>
<p>Entonces, la simetría de <span class="math inline">\(f_X\)</span> alrededor de <span class="math inline">\(\mu\)</span> hace que, para todo <span class="math inline">\(x\geqslant 0\)</span>, las áreas a la izquierda de <span class="math inline">\(\mu-x\)</span> y a la derecha de <span class="math inline">\(\mu+x\)</span> sean iguales.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>Es decir, <span class="math display">\[
P(X\leqslant \mu-x)=P(X\geqslant \mu+x)=1-P(X\leqslant \mu+x)
\]</span></p>
<p>En particular (tomando <span class="math inline">\(x=0\)</span>) <span class="math display">\[
P(X\leqslant \mu)=1-P(X\leqslant \mu)\Rightarrow P(X\leqslant \mu)=0.5
\]</span> y por lo tanto, <span class="math inline">\(\mu\)</span> es también la <strong>mediana</strong> de <span class="math inline">\(X\)</span>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span>, <span class="math inline">\(\mu\)</span> es la media, la mediana y la moda de <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<p>En el caso concreto de la normal estándar <span class="math inline">\(Z\)</span>, para cualquier <span class="math inline">\(z\geqslant 0\)</span> se tiene que las áreas a la izquierda de <span class="math inline">\(-z\)</span> y a la derecha de <span class="math inline">\(z\)</span> son iguales <span class="math display">\[
P(Z\leqslant -z)=P(Z\geqslant z)=1-P(Z\leqslant z)
\]</span> y la mediana de <span class="math inline">\(Z\)</span> es 0.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ahora que sabemos más cosas de la normal, en el Ejemplo anterior nos hubiéramos podido ahorrar la mitad del trabajo. Llamemos <span class="math inline">\(X\)</span> a la variable aleatoria que nos da la presión arterial, en mm Hg, de un hombre de entre 16 y 24 años. Nos dicen que <span class="math inline">\(X\)</span> es <span class="math inline">\(N(124,13.7)\)</span>.</p>
<p>Por la simetría de <span class="math inline">\(X\)</span> alrededor de <span class="math inline">\(\mu=124\)</span>, si escribimos el 0.05-cuantil como <span class="math inline">\(124-x\)</span>, entonces <span class="math inline">\(P(X\geqslant 124+x)=P(X\leqslant 124-x)=0.05\)</span> y por lo tanto <span class="math inline">\(P(X\leqslant 124+x)=1-P(X\geqslant 124+x)=0.95\)</span>, es decir, <span class="math inline">\(124+x\)</span> será el 0.95-cuantil de <span class="math inline">\(X\)</span>.</p>
<p>El 0.05-cuantil ha sido 101.5. Escribiendo <span class="math inline">\(101.5=124-x\)</span>, obtenemos <span class="math inline">\(x=22.5\)</span>. Por lo tanto, el 0.95-cuantil tiene que ser <span class="math inline">\(124+22.5=146.5\)</span>.</p>
<p>Lo mismo pasa con el 0.9-cuantil y el 0.1-cuantil, razonadlo y comprobadlo.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>El argumento que hemos desarrollado en la nota anterior muestra en general que si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span> y su <span class="math inline">\(q\)</span>-cuantil es <span class="math inline">\(\mu-x\)</span>, entonces su <span class="math inline">\((1-q)\)</span>-cuantil es <span class="math inline">\(\mu+x\)</span>.</p>
</div>
</div>
<center>
<img src="Figuras/cuantiles-normal.png" class="img-fluid">
</center>
<p>Si <span class="math inline">\(\mu\)</span> crece, desplaza a la derecha el máximo de la densidad, y con él toda la curva.</p>
<center>
<img src="Figuras/traslado-normal.png" class="img-fluid">
</center>
<p>Si <span class="math inline">\(\sigma\)</span> crece, la curva se aplana: al aumentar la desviación típica, los valores se dispersan y se alejan más del valor medio.</p>
<center>
<img src="Figuras/cambio-varianza-normal.png" class="img-fluid">
</center>
<p>El gráfico siguiente muestra el efecto combinado:</p>
<center>
<img src="Figuras/efecto-combinado-normal.png" class="img-fluid">
</center>
<p>Denotaremos por <span class="math inline">\(z_q\)</span> el <strong><span class="math inline">\(q\)</span>-cuantil</strong> de una variable normal estándar <span class="math inline">\(Z\)</span>. Es decir, <span class="math inline">\(z_q\)</span> es el valor tal que <span class="math inline">\(P(Z\leqslant z_q)=q\)</span>.</p>
<p>Aparte de que <span class="math inline">\(z_{0.5}=0\)</span> (la mediana de <span class="math inline">\(Z\)</span> es 0), hay dos cuantiles más de la normal estándar <span class="math inline">\(Z\)</span> que os conviene recordar:</p>
<ul>
<li><p><span class="math inline">\(z_{0.95}=1.64\)</span>; es decir, <span class="math inline">\(P(Z\leqslant 1.64)=0.95\)</span> y por lo tanto <span class="math inline">\(P(Z\leqslant -1.64)=P(Z\geqslant 1.64)=0.05\)</span> y <span class="math display">\[
P(-1.64\leqslant Z\leqslant 1.64)=0.9.
\]</span></p></li>
<li><p><span class="math inline">\(z_{0.975}=1.96\)</span>; es decir, <span class="math inline">\(P(Z\leqslant 1.96)=0.975\)</span> y por lo tanto <span class="math inline">\(P(Z\leqslant -1.96)=P(Z\geqslant 1.96)=0.025\)</span> y <span class="math display">\[
P(-1.96\leqslant Z\leqslant 1.96)=0.95.
\]</span></p></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Muy a menudo el valor 1.96 de <span class="math inline">\(z_{0.975}\)</span> se aproxima por 2. Tenéis permiso para hacerlo cuando no dispongáis de medios (R, aplis de móvil) para calcular cuantiles o cuando tengáis que hacer algún cálculo “a ojo” que involucre este cuantil.</p>
</div>
</div>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Supongamos que la concentración de un cierto metabolito es una variable aleatoria de distribución normal, pero cuyos parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span> dependen de si la medimos en personas sanas o en personas con una cierta enfermedad. Sean:</p>
</div>
<ul>
<li><p><span class="math inline">\(X_E\)</span> la variable aleatoria “Tomo una persona enferma y mido su concentración de este metabolito”, y supongamos que es <span class="math inline">\(N(\mu_E, \sigma_E)\)</span>.</p></li>
<li><p><span class="math inline">\(X_S\)</span> la variable aleatoria “Tomo una persona sana y mido su concentración de este metabolito”, y supongamos que es <span class="math inline">\(N(\mu_S, \sigma_S)\)</span>.</p></li>
<li><p>Supongamos, para fijar ideas, que <span class="math inline">\(\mu_E&gt;\mu_S\)</span>: la concentración media de este metabolito en los enfermos es más alta que en las personas sanas.</p></li>
</ul>
<p>Podríamos usar como prueba diagnóstica de la enfermedad la concentración del metabolito. Para cada valor de referencia <span class="math inline">\(x_0\)</span>, nuestra prueba dará:</p>
<ul>
<li><p><strong>Positivo</strong>, si la concentración es mayor o igual que <span class="math inline">\(x_0\)</span>.</p></li>
<li><p><strong>Negativo</strong>, si la concentración es menor que <span class="math inline">\(x_0\)</span>.</p></li>
</ul>
<p>Entonces:</p>
<ul>
<li><p>La <strong>sensibilidad</strong> de esta prueba es <span class="math display">\[
P(+|E)  =P(X_E\geqslant x_0)=1-P(X_E&lt; x_0)=1-F_{X_E}(x_0)
\]</span></p></li>
<li><p>Su <strong>especificidad</strong> es <span class="math display">\[
P(-|S)=P(X_S&lt; x_0)=F_{X_S}(x_0)
\]</span></p></li>
<li><p>Su <strong>tasa de falsos positivos</strong> es <span class="math display">\[
P(+|S)=P(X_S\geqslant  x_0)=1-F_{X_S}(x_0)
\]</span></p></li>
</ul>
<p>Al variar <span class="math inline">\(x_0\)</span>, tenemos valores diferentes de la sensibilidad y la tasa de falsos positivos. Entonces, podemos dibujar su curva ROC y escoger el umbral con algún criterio o valorar su capacidad diagnóstica global con su AUC.</p>
<p>Por ejemplo, imaginad que la densidad de <span class="math inline">\(X_E\)</span> es la línea discontinua del gráfico de la izquierda de la figura siguiente y la de <span class="math inline">\(X_S\)</span> la línea continua. Ambas son normales y <span class="math inline">\(\mu_E&gt;\mu_S\)</span>, porque el pico de la densidad de <span class="math inline">\(X_E\)</span> está a la derecha del de <span class="math inline">\(X_S\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="t5_variables_aleatorias_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
<p>Si para cada <span class="math inline">\(x\)</span> dibujamos los puntos <span class="math inline">\((1-F_{X_S}(x),1-F_{X_E}(x))\)</span>, obtenemos la curva ROC de la derecha de dicha figura.</p>
<p><strong>Ejercicio:</strong> Del gráfico de las densidades de <span class="math inline">\(X_E\)</span> i <span class="math inline">\(X_S\)</span>, ¿podéis deducir cuál tiene mayor desviación típica?</p>
<p>Tenemos también el resultado siguiente:</p>
<p><strong>Teorema:</strong> Las variables normales tienen coeficientes de asimetría y de curtosis 0.</p>
<p>Una de las propiedades de la distribución normal que nos facilitan mucho la vida es que <strong>toda combinación lineal de variables aleatorias normales independientes es normal</strong>. En concreto, tenemos los resultados siguientes:</p>
<p><strong>Teorema:</strong> Sea <span class="math inline">\(X\)</span> una variable <span class="math inline">\(N(\mu,\sigma)\)</span>.</p>
<ol type="1">
<li><p>Para todos <span class="math inline">\(a,b\in \mathbb{R}\)</span>, <span class="math inline">\(aX+b\)</span> es <span class="math inline">\(N(a\mu+b,|a|\cdot\sigma)\)</span>.</p></li>
<li><p>En particular, la <strong>tipificada</strong> de <span class="math inline">\(X\)</span> <span class="math display">\[
Z=\dfrac{X-\mu}{\sigma}
\]</span> es <span class="math inline">\(N(0,1)\)</span>.</p></li>
</ol>
<p>Más en general:</p>
<p><strong>Teorema:</strong> Si <span class="math inline">\(X_1,\ldots,X_n\)</span> son variables aleatorias normales <strong>independientes</strong>, cada <span class="math inline">\(X_i\)</span> de tipo <span class="math inline">\(N(\mu_i,\sigma_i)\)</span>, y <span class="math inline">\(a_1,\ldots,a_n,b\in \mathbb{R}\)</span>, entonces <span class="math inline">\(a_1X_1+\cdots +a_nX_n+b\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span> con <span class="math display">\[
\mu=a_1\mu_1+\cdots +a_n\mu_n+b,\
\sigma=\sqrt{a_1^2\sigma^2_1+\cdots +a_n^2\sigma^2_n}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Que toda combinación lineal de variables normales vuelva a ser del mismo tipo, es decir, normal, es una propiedad muy útil de las variables normales que pocas familias de distribuciones comparten. Por ejemplo, si <span class="math inline">\(X\)</span> es una variable binomial <span class="math inline">\(B(n,p)\)</span> con <span class="math inline">\(p\neq 0\)</span>, la variable <span class="math inline">\(2X\)</span> no es binomial, porque solo toma valores pares, mientras que una variable binomial <span class="math inline">\(B(m,q)\)</span> ha de poder tomar todos los valores entre 0 y <span class="math inline">\(m\)</span>.</p>
</div>
</div>
<p>Las probabilidades de la normal tipificada determinan las de la normal original, porque si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span>: <span class="math display">\[
\begin{array}{rl}
P(a\leqslant X\leqslant b)\!\!\!\!\! &amp; \displaystyle  =P\Big( \frac{a-\mu}{\sigma}\leqslant \frac{X-\mu}{\sigma}\leqslant \frac{b-\mu}{\sigma}\Big)\\ &amp; \displaystyle =P\Big(\frac{a-\mu}{\sigma}\leqslant Z\leqslant \frac{b-\mu}{\sigma}\Big)
\end{array}
\]</span> Esto sirve para deducir fórmulas, y vuestros padres lo usaban para calcular probabilidades (con tablas de probabilidades de la normal estándar); ahora es más cómodo usar una aplicación del móvil.</p>
</section>
<section id="intervalos-de-referencia" class="level3" data-number="5.4.4">
<h3 data-number="5.4.4" class="anchored" data-anchor-id="intervalos-de-referencia"><span class="header-section-number">5.4.4</span> Intervalos de referencia</h3>
<p>Un <strong>intervalo de referencia</strong> del <span class="math inline">\(Q\%\)</span> para una variable aleatoria <span class="math inline">\(X\)</span> es un intervalo <span class="math inline">\([a,b]\)</span> tal que <span class="math display">\[
P(a\leqslant X\leqslant b)=Q\%(=Q/100).
\]</span> Es decir, un intervalo de referencia del <span class="math inline">\(Q\%\)</span> para <span class="math inline">\(X\)</span> es un intervalo que contiene los valores de <span class="math inline">\(X\)</span> del <span class="math inline">\(Q\%\)</span> de los sujetos de la población.</p>
<p>Por ejemplo, hemos visto en la sección anterior que [-1.64,1.64] y [-1.96,1.96] son intervalos de referencia del 90% y del 95%, respectivamente, para una variable normal estándar <span class="math inline">\(Z\)</span>. Y en el Ejemplo @ref(exm:exhiperhipo) hemos visto que un intervalo de referencia del 90% para la presión sistólica de los hombres de 16 a 24 años, medida en mm Hg, es [101.5,146.5].</p>
<p>Los más comunes son los intervalos de referencia del 95%, que satisfacen que <span class="math display">\[
P(a\leqslant X\leqslant b)=0.95
\]</span> y son los, que por ejemplo, os dan como valores de referencia en las analíticas:</p>
<center>
<img src="Figuras/resultados-labo.png" class="img-fluid">
</center>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Cuando se habla de un <strong>intervalo de referencia</strong> sin dar la probabilidad, se sobreentiende siempre que es el intervalo de referencia del 95%.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Importante
</div>
</div>
<div class="callout-body-container callout-body">
<p>Un 5% de la población está fuera del intervalo de referencia del 95%, por definición.</p>
</div>
</div>
<p>Cuando <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span>, estos intervalos de referencia se toman siempre <strong>centrados en la media</strong> <span class="math inline">\(\mu\)</span>, es decir, de la forma <span class="math inline">\([\mu-\text{algo},\mu+\text{algo}]\)</span>. Para calcularlos se usa el resultado siguiente:</p>
<p><strong>Teorema:</strong> Si <span class="math inline">\(X\)</span> es <span class="math inline">\(N(\mu,\sigma)\)</span>, un intervalo de referencia del <span class="math inline">\(Q\%\)</span> para <span class="math inline">\(X\)</span> es <span class="math display">\[
[\mu- z_{(1+q)/2}\cdot \sigma, \mu+ z_{(1+q)/2}\cdot \sigma]
\]</span> donde <span class="math inline">\(q=Q/100\)</span> y <span class="math inline">\(z_{(1+q)/2}\)</span> denota el <span class="math inline">\((1+q)/2\)</span>-cuantil de la normal estándar <span class="math inline">\(Z\)</span>. Se suele escribir <span class="math display">\[
\mu\pm z_{(1+q)/2}\cdot \sigma.
\]</span></p>
<p>En efecto: <span class="math display">\[
\begin{array}{l}
P(\mu-x\leqslant X\leqslant \mu+x)=q\\
\qquad \Longleftrightarrow \displaystyle P\Big(\frac{\mu-x-\mu}{\sigma}\leqslant \frac{X-\mu}{\sigma}\leqslant \frac{\mu+x-\mu}{\sigma}\Big)=q\\
\qquad \Longleftrightarrow \displaystyle P(-x/{\sigma}\leqslant Z\leqslant {x}/{\sigma})=q\\
\qquad \Longleftrightarrow \displaystyle P(Z\leqslant {x}/{\sigma})-P(Z\leqslant -{x}/{\sigma})=q\\
\qquad \Longleftrightarrow \displaystyle P(Z\leqslant {x}/{\sigma})-P(Z\geqslant {x}/{\sigma})=q\\
\qquad \text{(por la simetría de $f_Z$ alrededor de 0)}\\
\qquad \Longleftrightarrow \displaystyle P(Z\leqslant {x}/{\sigma})-(1-P(Z\leqslant {x}/{\sigma}))=q\\
\qquad \Longleftrightarrow \displaystyle 2P(Z\leqslant {x}/{\sigma})=q+1\\
\qquad \Longleftrightarrow P(Z\leqslant {x}/{\sigma})=(1+q)/2\\
\qquad \Longleftrightarrow x/\sigma=
z_{(1+q)/2}\\
\qquad \Longleftrightarrow x=z_{(1+q)/2}\cdot \sigma
\end{array}
\]</span></p>
<p>Si <span class="math inline">\(q=0.95\)</span>, entonces <span class="math inline">\((1+q)/2=0.975\)</span> y <span class="math inline">\(z_{0.975}=1.96\)</span>. Por lo tanto, el intervalo de referencia del 95% para una variable <span class="math inline">\(X\)</span> normal <span class="math inline">\(N(\mu,\sigma)\)</span> es <span class="math display">\[
\mu\pm 1.96\sigma.
\]</span> Y como este 1.96 a menudo se aproxima por 2, el intervalo de referencia del 95% se simplifica a <span class="math display">\[
\mu\pm 2\sigma.
\]</span> Esto dice, básicamente, que</p>
<blockquote class="blockquote">
<p>si una población sigue una distribución normal <span class="math inline">\(N(\mu,\sigma)\)</span>, alrededor del 95% de sus individuos tienen su valor de <span class="math inline">\(X\)</span> a distancia como máximo <span class="math inline">\(2\sigma\)</span> (“a dos sigmas”) de <span class="math inline">\(\mu\)</span>. El 5% restante de distribuye a partes iguales a ambos lados del intervalo: un 2.5% por encima de su extremo superior y un 2.5% por debajo de su extremo inferior.</p>
</blockquote>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Según la OMS, las alturas (en cm) de las mujeres europeas de 18 años siguen una ley <span class="math inline">\(N(163.1,18.53)\)</span>. ¿Cuál es el intervalo de alturas centrado en la media que contiene a la mitad las europeas de 18 años?</p>
<p>Fijaos en que, si llamamos <span class="math inline">\(X\)</span> a la variable aleatoria “Tomo una mujer europea de 18 años y mido su altura en cm”, lo que queremos saber es el intervalo centrado en su media tal que la probabilidad de que la altura de una europea de 18 años escogida al azar pertenezca a este intervalo sea 0.5. Es decir, el intervalo de referencia del 50% para <span class="math inline">\(X\)</span>.</p>
<p>Nos dicen que <span class="math inline">\(X\)</span> es <span class="math inline">\(N(163.1,18.53)\)</span>. Si <span class="math inline">\(q=0.5\)</span>, entonces <span class="math inline">\((1+q)/2=0.75\)</span> y si calculamos el 0.75-cuantil de una normal estándar, da <span class="math inline">\(z_{0.75}=0.6745\)</span>.</p>
<p>Por lo tanto, es el intervalo <span class="math inline">\(163.1\pm 0.6745\cdot 18.53\)</span>. Redondeando a mm, <span class="math inline">\([150.6, 175.6]\)</span>. Esto nos dice que la mitad de las mujeres europeas de 18 años miden entre 150.6 y 175.6 cm. De la otra mitad, la mitad (es decir un cuarto del total) miden menos de 150.6 cm y la otra más de 175.6 cm.</p>
</div>
<p>El <strong>z-score</strong> (<strong>z-valor</strong>, <strong>z-puntuación</strong>, <strong>z-puntaje</strong>…) de un valor <span class="math inline">\(x_0\in \mathbb{R}\)</span> respecto de una distribución <span class="math inline">\(N(\mu,\sigma)\)</span> es <span class="math display">\[
\frac{x_0-\mu}{\sigma}
\]</span></p>
<p>Es decir, el z-score de <span class="math inline">\(x_0\)</span> es el resultado de “tipificar” <span class="math inline">\(x_0\)</span> en el sentido del Teorema @ref(thm:comblinnormals).</p>
<p>Si la variable poblacional es normal, cuanto mayor es el valor absoluto del z-score de <span class="math inline">\(x_0\)</span>, más “raro” es <span class="math inline">\(x_0\)</span>; el signo nos dice si es más grande o más pequeño que el valor esperado <span class="math inline">\(\mu\)</span>.</p>
<strong>Ejemplo:</strong>
<div style="border-left: 4px solid #f0ad4e; background-color: #fcf8e3; padding: 10px; margin: 10px 0;">
<p>Recordad que, según la OMS, las alturas de las mujeres europeas de 18 años siguen una ley <span class="math inline">\(N(163.1,18.53)\)</span>. ¿Cuál sería el z-score de una jugadora de baloncesto de 18 años que midiera 191 cm?</p>
<p>Sería <span class="math display">\[
\frac{191-163.1}{18.53}=1.5
\]</span></p>
<p>Esto se suele leer diciendo que la altura de esta jugadora está <em>1.5 sigmas por encima de la media</em> (donde, recordad, “sigma” es una abreviatura de “desviación típica poblacional”).</p>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/Cruzalirio\.github\.io\/Farmacia");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./t4_probabilidades.html" class="pagination-link" aria-label="Probabilidades">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probabilidades</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./t6_estimacion.html" class="pagination-link" aria-label="Estimadores">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Estimadores</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Matématicas y Estadística para Farmacia</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Cruzalirio/Farmacia/edit/main/t5_variables_aleatorias.qmd" class="toc-action"><i class="bi bi-github"></i>Editar esta página</a></li><li><a href="https://github.com/Cruzalirio/Farmacia/issues/new" class="toc-action"><i class="bi empty"></i>Informar de un problema</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Este libro se ha creado con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>